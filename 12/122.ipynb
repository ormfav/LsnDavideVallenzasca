{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d40b579c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4fe505eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=0\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7d07d2f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (60000, 28, 28)\n",
      "Y_train shape: (60000,)\n",
      "\n",
      "X_test shape: (10000, 28, 28)\n",
      "Y_test shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28 # number of pixels \n",
    "# output\n",
    "num_classes = 10 # 10 digits\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "print('X_train shape:', x_train.shape)\n",
    "print('Y_train shape:', y_train.shape)\n",
    "print()\n",
    "print('X_test shape:', x_test.shape)\n",
    "print('Y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3a2aeb0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (60000, 28, 28, 1)\n",
      "Y_train shape: (60000, 10)\n",
      "\n",
      "X_test shape: (10000, 28, 28, 1)\n",
      "Y_test shape: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# you will need the following for Convolutional Neural Networks\n",
    "from keras.layers import Flatten, Conv2D, MaxPooling2D\n",
    "\n",
    "# reshape data, depending on Keras backend\n",
    "if keras.backend.image_data_format() == 'channels_first':\n",
    "    X_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    X_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    X_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    X_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "    \n",
    "Y_train = keras.utils.to_categorical(y_train, num_classes) #inizialmente le label sono la cifra, lo voglio trasformare in vettore di bit di cui quello acceso è quello con indice la cifra (cioè quello che sarà output rete)\n",
    "Y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('Y_train shape:', Y_train.shape)\n",
    "print()\n",
    "print('X_test shape:', X_test.shape)\n",
    "print('Y_test shape:', Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "dbe70172",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout #Dropout per limitare overfitting\n",
    "from keras.layers import Flatten, Conv2D, AveragePooling2D\n",
    "\n",
    "\n",
    "def create_model():\n",
    "    #instantiate model\n",
    "    model = Sequential()\n",
    "    #Convolutional\n",
    "    ##in: 28x28x1\n",
    "    model.add(Conv2D(10, kernel_size=(5, 5), activation='relu', input_shape=input_shape))\n",
    "    ##out: 24x24x10, in:\n",
    "    model.add(AveragePooling2D(pool_size=(2,2)))\n",
    "    ##out: 12x12x10, in:\n",
    "    model.add(Conv2D(16, kernel_size=(5,5),strides=2))\n",
    "    ##out: 4x4x16, in:\n",
    "    #Deep\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "73bf2690",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD, RMSprop, Adam, Nadam, Adagrad, Adadelta, Adamax\n",
    "\n",
    "def compile_model(opt_function):\n",
    "    # create the model\n",
    "    model=create_model()\n",
    "    # compile the model\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=opt_function,\n",
    "                  metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "79742cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_21 (Conv2D)          (None, 24, 24, 10)        260       \n",
      "                                                                 \n",
      " average_pooling2d_10 (Avera  (None, 12, 12, 10)       0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 4, 4, 16)          4016      \n",
      "                                                                 \n",
      " flatten_10 (Flatten)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 64)                16448     \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,374\n",
      "Trainable params: 21,374\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_CNN=compile_model(SGD())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "50e01090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1875/1875 [==============================] - 36s 19ms/step - loss: 2.6151 - acc: 0.1079 - val_loss: 2.3007 - val_acc: 0.1135\n",
      "Epoch 2/20\n",
      "1875/1875 [==============================] - 36s 19ms/step - loss: 2.3015 - acc: 0.1152 - val_loss: 2.2845 - val_acc: 0.1587\n",
      "Epoch 3/20\n",
      "1875/1875 [==============================] - 35s 19ms/step - loss: 2.2778 - acc: 0.1317 - val_loss: 2.3017 - val_acc: 0.1135\n",
      "Epoch 4/20\n",
      "1875/1875 [==============================] - 39s 21ms/step - loss: 2.3019 - acc: 0.1107 - val_loss: 2.3013 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "1875/1875 [==============================] - 40s 21ms/step - loss: 2.3014 - acc: 0.1124 - val_loss: 2.3012 - val_acc: 0.1135\n",
      "Epoch 6/20\n",
      "1875/1875 [==============================] - 41s 22ms/step - loss: 2.3013 - acc: 0.1124 - val_loss: 2.3010 - val_acc: 0.1135\n",
      "Epoch 7/20\n",
      "1875/1875 [==============================] - 41s 22ms/step - loss: 2.3013 - acc: 0.1123 - val_loss: 2.3010 - val_acc: 0.1135\n",
      "Epoch 8/20\n",
      "1875/1875 [==============================] - 38s 20ms/step - loss: 2.3013 - acc: 0.1124 - val_loss: 2.3010 - val_acc: 0.1135\n",
      "Epoch 9/20\n",
      "1875/1875 [==============================] - 38s 20ms/step - loss: 2.3014 - acc: 0.1124 - val_loss: 2.3010 - val_acc: 0.1135\n",
      "Epoch 10/20\n",
      "1875/1875 [==============================] - 38s 20ms/step - loss: 2.3013 - acc: 0.1124 - val_loss: 2.3011 - val_acc: 0.1135\n",
      "Epoch 11/20\n",
      "1875/1875 [==============================] - 38s 20ms/step - loss: 2.3013 - acc: 0.1124 - val_loss: 2.3010 - val_acc: 0.1135\n",
      "Epoch 12/20\n",
      "1875/1875 [==============================] - 39s 21ms/step - loss: 2.3013 - acc: 0.1124 - val_loss: 2.3011 - val_acc: 0.1135\n",
      "Epoch 13/20\n",
      "1875/1875 [==============================] - 38s 20ms/step - loss: 2.3013 - acc: 0.1124 - val_loss: 2.3011 - val_acc: 0.1135\n",
      "Epoch 14/20\n",
      "1875/1875 [==============================] - 39s 21ms/step - loss: 2.3013 - acc: 0.1124 - val_loss: 2.3010 - val_acc: 0.1135\n",
      "Epoch 15/20\n",
      "1875/1875 [==============================] - 31s 16ms/step - loss: 2.3013 - acc: 0.1123 - val_loss: 2.3011 - val_acc: 0.1135\n",
      "Epoch 16/20\n",
      "1875/1875 [==============================] - 35s 19ms/step - loss: 2.3013 - acc: 0.1124 - val_loss: 2.3010 - val_acc: 0.1135\n",
      "Epoch 17/20\n",
      "1875/1875 [==============================] - 39s 21ms/step - loss: 2.3013 - acc: 0.1124 - val_loss: 2.3013 - val_acc: 0.1135\n",
      "Epoch 18/20\n",
      "1875/1875 [==============================] - 32s 17ms/step - loss: 2.3013 - acc: 0.1124 - val_loss: 2.3011 - val_acc: 0.1135\n",
      "Epoch 19/20\n",
      "1875/1875 [==============================] - 35s 19ms/step - loss: 2.3013 - acc: 0.1123 - val_loss: 2.3010 - val_acc: 0.1135\n",
      "Epoch 20/20\n",
      "1875/1875 [==============================] - 34s 18ms/step - loss: 2.3013 - acc: 0.1121 - val_loss: 2.3010 - val_acc: 0.1135\n",
      "Storing model and history\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: store/122-model.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: store/122-model.tf/assets\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [70]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m path_model \u001b[38;5;241m=\u001b[39m path\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel.tf\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     16\u001b[0m model_DNN\u001b[38;5;241m.\u001b[39msave(filepath\u001b[38;5;241m=\u001b[39mpath_model, include_optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \n\u001b[0;32m---> 17\u001b[0m df  \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mDataFrame(history\u001b[38;5;241m.\u001b[39mhistory) \n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(path_history, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m     19\u001b[0m     df\u001b[38;5;241m.\u001b[39mto_csv(file)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "RERUN=True\n",
    "epochs = 20\n",
    "\n",
    "if(RERUN):\n",
    "    batch_size = 32 \n",
    "    history = model_CNN.fit(X_train, Y_train,\n",
    "                            batch_size=batch_size,\n",
    "                            epochs=epochs,\n",
    "                            verbose=1,\n",
    "                            validation_data=(X_test, Y_test))\n",
    "    import pandas as pd\n",
    "    print(\"Storing model and history\")\n",
    "    path = \"store/122-\"\n",
    "    path_history = path+\"history.csv\"\n",
    "    path_model = path+\"model.tf\"\n",
    "        \n",
    "    model_DNN.save(filepath=path_model, include_optimizer=True)  \n",
    "    df  = pd.DataFrame(history.history) \n",
    "    with open(path_history, mode='w') as file:\n",
    "        df.to_csv(file)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18f0dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "path = \"store/122-\"\n",
    "model_DNN=load_model(path+\"model.tf\")\n",
    "history = pd.read_csv(path+\"history.csv\")\n",
    "    \n",
    "score = model_DNN.evaluate(X_test, Y_test, verbose=1)\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(range(0, Nepochs), history.loc[:,\"loss\"], label=label)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('model loss')\n",
    "plt.title('Loss - train')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(range(0, Nepochs), history.loc[:,\"val_loss\"], label=label)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('model loss')\n",
    "plt.title('Loss - test')\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(range(0, Nepochs), history.loc[:,\"acc\"], label=label)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('model loss')\n",
    "plt.title('Accuracy - train')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.plot(range(0, Nepochs), history.loc[:,\"val_acc\"], label=label)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('model loss')\n",
    "plt.title('Accuracy - test')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
