{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eec349fa",
   "metadata": {},
   "source": [
    "# $11^{th}$ excercises - 11.1: Linear regression\n",
    "## Notebook setup\n",
    "#### Used libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4c67f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import get_custom_objects\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310b0d28",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "742ba95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TestParameters():\n",
    "    deltaepochss=np.ones(len(epochss))*epochss[0]\n",
    "    for i in range(len(epochss)-1):\n",
    "        deltaepochss[i+1]=epochss[i+1]-epochss[i] \n",
    "    print(\"Epochs delta: \",deltaepochss)\n",
    "        \n",
    "    # open and clear output files\n",
    "    fout_m = open(\"out/111-m_diff.csv\",\"a\")\n",
    "    fout_b = open(\"out/111-b_diff.csv\",\"a\")\n",
    "    fout_m.truncate(0)\n",
    "    fout_b.truncate(0)\n",
    "\n",
    "    for ntrain in ntrains:\n",
    "        nvalid = ntrain // 10\n",
    "        np.random.seed(0)\n",
    "        tf.random.set_seed(0)\n",
    "        #creating training and validation datasets\n",
    "        x_train = np.random.uniform(-1, 1, ntrain)\n",
    "        x_valid = np.random.uniform(-1, 1, nvalid)\n",
    "        x_valid.sort()\n",
    "        \n",
    "\n",
    "        for sigma in sigmas:\n",
    "            np.random.seed(0)\n",
    "            tf.random.set_seed(0)\n",
    "            y_train = np.random.normal(m * x_train + b, sigma) \n",
    "            y_valid = np.random.normal(m * x_valid + b, sigma) \n",
    "            #creating and compiling the model\n",
    "            model = tf.keras.Sequential()\n",
    "            model.add(Dense(1, input_shape=(1,)))\n",
    "            model.compile(optimizer='sgd', loss='mse', metrics=['mse'])\n",
    "            \n",
    "            df=pd.DataFrame()\n",
    "            \n",
    "            for epochs in epochss:\n",
    "                #optimizing the model\n",
    "                ## model.fit(epochs=20)=four calls of\n",
    "                ## model.fit(epochs=5)\n",
    "                history = model.fit(x=x_train, y=y_train, \n",
    "                                    batch_size=32, \n",
    "                                    epochs=epochs,\n",
    "                                    shuffle=True, \n",
    "                                    validation_data=(x_valid, y_valid))        \n",
    "                df=pd.concat([df,pd.DataFrame(history.history)])\n",
    "                \n",
    "                # output\n",
    "                mb = model.get_weights()\n",
    "\n",
    "                printm=str(mb[0])[2:-2]\n",
    "                printb=str(mb[1])[1:-1] #don't want brackets in final string\n",
    "                fout_m.write(printm+\"\\n\")\n",
    "                fout_b.write(printb+\"\\n\")\n",
    "                \n",
    "                path_model=\"out/111-model-ntrain=\"+str(ntrain)+\"-sigma=\"+str(sigma)+\"-epochs=\"+str(epochs)+\".tf\"\n",
    "                model.save(filepath=path_model, include_optimizer=True) \n",
    "            \n",
    "            path_history=\"out/111-history-ntrain=\"+str(ntrain)+\"-sigma=\"+str(sigma)+\".csv\"\n",
    "            with open(path_history, mode='w') as file:\n",
    "                df.to_csv(file)\n",
    "            print()\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed0a0cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_results(model, history, npredict, epochs):\n",
    "    plt.figure(figsize=(16,8))\n",
    "    \n",
    "    plt.subplot(121)\n",
    "    plt.plot(history[\"loss\"].iloc[:epochs], label=\"Training\")\n",
    "    plt.plot(history[\"val_loss\"].iloc[:epochs], label=\"Validation\")\n",
    "    plt.title(\"Model loss\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.subplot(122)\n",
    "    x_predict = np.random.uniform(-1, 1, npredict)\n",
    "    y_predict = model.predict(x_predict)\n",
    "    x_target=np.sort(x_predict)\n",
    "    y_target = m * x_target + b \n",
    "    plt.scatter(x_predict, y_predict, label='Predicted')\n",
    "    plt.plot(x_target, y_target, label='Target')   \n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c3bae6",
   "metadata": {},
   "source": [
    "## The excercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29d9267",
   "metadata": {},
   "source": [
    "Neural networks (NN) are a technique to perform supervised learning, that is building an algorithm able to learn from labelled data how to label never-seen-before data. Assigning labels to data is exactly what a function in a mathematical sense does, hence NN can be used to fit a function.\n",
    "\n",
    "A neural network made of a sequence of layers, each layers constitued by a certain number of basic units which we will call neurons. In their basic form each neuron receives some input values and gives a value as output. Calling $x_i$ the input values received in input by a neuron and $y$ its output, we can simply write the neuron behaviour as\n",
    "\\begin{equation}\n",
    "y=f\\Bigl(\\sum_i w_i x_i + b\\Bigr)\n",
    "\\end{equation}\n",
    "Where the weight $w_i$ and the bias $b$ are parameters that the neural network tries to optimize (this is the core of the learning process) and $f$ is a function called *activation fuction* of the neuron. Thus the simplest neural network, a neural network composed by:\n",
    "- one layer of\n",
    "- one neuron that\n",
    "- takes one input value and \n",
    "- outputs one value\n",
    "- having $f=id$\n",
    "\n",
    "performs a linear regression. \n",
    "\n",
    "We want to take this simple neural network and explore its behaviour trying to fit the line $mx+b$, where:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe275f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target parameters of f(x) = m*x + b\n",
    "m = 2 \n",
    "b = 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b572697",
   "metadata": {},
   "source": [
    "We want to see how the fitting procedure changes in function of:\n",
    "- the noise on training data\n",
    "- the number of training data\n",
    "- the number of epochs of the training (how long we let the NN train)\n",
    "\n",
    "The following cell is used to set the parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ffcadbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmas = np.array([0., 1, 10])\n",
    "ntrains = np.linspace(100, 1000, 3,dtype=int)\n",
    "epochss = np.linspace(10, 100, 3,dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7641f3",
   "metadata": {},
   "source": [
    "In order to make the tests for all the possible combinations of parameters we write a python function that for each combination creates a model, trains it and then saves the results on some files. Since the procedure takes a while to finish, we disable the execution of the test procedure by default. To run it again, set `RERUN` to `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "18965dcf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs delta:  [10. 45. 45.]\n",
      "Epoch 1/10\n",
      "4/4 [==============================] - 1s 103ms/step - loss: 3.1255 - mse: 3.1255 - val_loss: 3.6132 - val_mse: 3.6132\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 2.8571 - mse: 2.8571 - val_loss: 3.3385 - val_mse: 3.3385\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 2.6667 - mse: 2.6667 - val_loss: 3.0423 - val_mse: 3.0423\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 2.4662 - mse: 2.4662 - val_loss: 2.8359 - val_mse: 2.8359\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 2.3248 - mse: 2.3248 - val_loss: 2.6702 - val_mse: 2.6702\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 2.2055 - mse: 2.2055 - val_loss: 2.5157 - val_mse: 2.5157\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 2.0822 - mse: 2.0822 - val_loss: 2.2644 - val_mse: 2.2644\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 1.9113 - mse: 1.9113 - val_loss: 2.1061 - val_mse: 2.1061\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1.7998 - mse: 1.7998 - val_loss: 1.9873 - val_mse: 1.9873\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.7037 - mse: 1.7037 - val_loss: 1.8452 - val_mse: 1.8452\n",
      "INFO:tensorflow:Assets written to: out/111-model-ntrain=100-sigma=0.0-epochs=10.tf/assets\n",
      "Epoch 1/55\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 1.5991 - mse: 1.5991 - val_loss: 1.6920 - val_mse: 1.6920\n",
      "Epoch 2/55\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.4908 - mse: 1.4908 - val_loss: 1.5875 - val_mse: 1.5875\n",
      "Epoch 3/55\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 1.4118 - mse: 1.4118 - val_loss: 1.4692 - val_mse: 1.4692\n",
      "Epoch 4/55\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.3270 - mse: 1.3270 - val_loss: 1.3886 - val_mse: 1.3886\n",
      "Epoch 5/55\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 1.2652 - mse: 1.2652 - val_loss: 1.3236 - val_mse: 1.3236\n",
      "Epoch 6/55\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.2100 - mse: 1.2100 - val_loss: 1.2584 - val_mse: 1.2584\n",
      "Epoch 7/55\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.1474 - mse: 1.1474 - val_loss: 1.1476 - val_mse: 1.1476\n",
      "Epoch 8/55\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.0683 - mse: 1.0683 - val_loss: 1.0795 - val_mse: 1.0795\n",
      "Epoch 9/55\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.0149 - mse: 1.0149 - val_loss: 1.0270 - val_mse: 1.0270\n",
      "Epoch 10/55\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.9641 - mse: 0.9641 - val_loss: 0.9624 - val_mse: 0.9624\n",
      "Epoch 11/55\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.9108 - mse: 0.9108 - val_loss: 0.9065 - val_mse: 0.9065\n",
      "Epoch 12/55\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.8656 - mse: 0.8656 - val_loss: 0.8236 - val_mse: 0.8236\n",
      "Epoch 13/55\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.8034 - mse: 0.8034 - val_loss: 0.7824 - val_mse: 0.7824\n",
      "Epoch 14/55\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.7629 - mse: 0.7629 - val_loss: 0.7512 - val_mse: 0.7512\n",
      "Epoch 15/55\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.7279 - mse: 0.7279 - val_loss: 0.7113 - val_mse: 0.7113\n",
      "Epoch 16/55\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6908 - mse: 0.6908 - val_loss: 0.6791 - val_mse: 0.6791\n",
      "Epoch 17/55\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.6565 - mse: 0.6565 - val_loss: 0.6389 - val_mse: 0.6389\n",
      "Epoch 18/55\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.6197 - mse: 0.6197 - val_loss: 0.6053 - val_mse: 0.6053\n",
      "Epoch 19/55\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.5900 - mse: 0.5900 - val_loss: 0.5657 - val_mse: 0.5657\n",
      "Epoch 20/55\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.5553 - mse: 0.5553 - val_loss: 0.5320 - val_mse: 0.5320\n",
      "Epoch 21/55\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.5239 - mse: 0.5239 - val_loss: 0.5049 - val_mse: 0.5049\n",
      "Epoch 22/55\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.4979 - mse: 0.4979 - val_loss: 0.4818 - val_mse: 0.4818\n",
      "Epoch 23/55\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.4763 - mse: 0.4763 - val_loss: 0.4587 - val_mse: 0.4587\n",
      "Epoch 24/55\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.4536 - mse: 0.4536 - val_loss: 0.4341 - val_mse: 0.4341\n",
      "Epoch 25/55\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.4277 - mse: 0.4277 - val_loss: 0.4106 - val_mse: 0.4106\n",
      "Epoch 26/55\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.4058 - mse: 0.4058 - val_loss: 0.3806 - val_mse: 0.3806\n",
      "Epoch 27/55\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.3800 - mse: 0.3800 - val_loss: 0.3593 - val_mse: 0.3593\n",
      "Epoch 28/55\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.3593 - mse: 0.3593 - val_loss: 0.3406 - val_mse: 0.3406\n",
      "Epoch 29/55\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.3417 - mse: 0.3417 - val_loss: 0.3169 - val_mse: 0.3169\n",
      "Epoch 30/55\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.3205 - mse: 0.3205 - val_loss: 0.2986 - val_mse: 0.2986\n",
      "Epoch 31/55\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.3015 - mse: 0.3015 - val_loss: 0.2829 - val_mse: 0.2829\n",
      "Epoch 32/55\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.2875 - mse: 0.2875 - val_loss: 0.2669 - val_mse: 0.2669\n",
      "Epoch 33/55\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.2726 - mse: 0.2726 - val_loss: 0.2552 - val_mse: 0.2552\n",
      "Epoch 34/55\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.2598 - mse: 0.2598 - val_loss: 0.2447 - val_mse: 0.2447\n",
      "Epoch 35/55\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.2469 - mse: 0.2469 - val_loss: 0.2331 - val_mse: 0.2331\n",
      "Epoch 36/55\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.2366 - mse: 0.2366 - val_loss: 0.2231 - val_mse: 0.2231\n",
      "Epoch 37/55\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.2254 - mse: 0.2254 - val_loss: 0.2112 - val_mse: 0.2112\n",
      "Epoch 38/55\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.2148 - mse: 0.2148 - val_loss: 0.1951 - val_mse: 0.1951\n",
      "Epoch 39/55\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.2020 - mse: 0.2020 - val_loss: 0.1831 - val_mse: 0.1831\n",
      "Epoch 40/55\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.1908 - mse: 0.1908 - val_loss: 0.1746 - val_mse: 0.1746\n",
      "Epoch 41/55\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.1820 - mse: 0.1820 - val_loss: 0.1638 - val_mse: 0.1638\n",
      "Epoch 42/55\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.1714 - mse: 0.1714 - val_loss: 0.1521 - val_mse: 0.1521\n",
      "Epoch 43/55\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.1612 - mse: 0.1612 - val_loss: 0.1431 - val_mse: 0.1431\n",
      "Epoch 44/55\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.1530 - mse: 0.1530 - val_loss: 0.1350 - val_mse: 0.1350\n",
      "Epoch 45/55\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.1442 - mse: 0.1442 - val_loss: 0.1287 - val_mse: 0.1287\n",
      "Epoch 46/55\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.1368 - mse: 0.1368 - val_loss: 0.1220 - val_mse: 0.1220\n",
      "Epoch 47/55\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.1296 - mse: 0.1296 - val_loss: 0.1171 - val_mse: 0.1171\n",
      "Epoch 48/55\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.1226 - mse: 0.1226 - val_loss: 0.1107 - val_mse: 0.1107\n",
      "Epoch 49/55\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.1157 - mse: 0.1157 - val_loss: 0.1059 - val_mse: 0.1059\n",
      "Epoch 50/55\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.1103 - mse: 0.1103 - val_loss: 0.1005 - val_mse: 0.1005\n",
      "Epoch 51/55\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.1043 - mse: 0.1043 - val_loss: 0.0948 - val_mse: 0.0948\n",
      "Epoch 52/55\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.0989 - mse: 0.0989 - val_loss: 0.0911 - val_mse: 0.0911\n",
      "Epoch 53/55\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.0942 - mse: 0.0942 - val_loss: 0.0866 - val_mse: 0.0866\n",
      "Epoch 54/55\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0896 - mse: 0.0896 - val_loss: 0.0828 - val_mse: 0.0828\n",
      "Epoch 55/55\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0853 - mse: 0.0853 - val_loss: 0.0778 - val_mse: 0.0778\n",
      "INFO:tensorflow:Assets written to: out/111-model-ntrain=100-sigma=0.0-epochs=55.tf/assets\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.0806 - mse: 0.0806 - val_loss: 0.0728 - val_mse: 0.0728\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.0763 - mse: 0.0763 - val_loss: 0.0693 - val_mse: 0.0693\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.0728 - mse: 0.0728 - val_loss: 0.0652 - val_mse: 0.0652\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.0692 - mse: 0.0692 - val_loss: 0.0624 - val_mse: 0.0624\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.0662 - mse: 0.0662 - val_loss: 0.0601 - val_mse: 0.0601\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.0634 - mse: 0.0634 - val_loss: 0.0574 - val_mse: 0.0574\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.0600 - mse: 0.0600 - val_loss: 0.0532 - val_mse: 0.0532\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.0565 - mse: 0.0565 - val_loss: 0.0505 - val_mse: 0.0505\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.0539 - mse: 0.0539 - val_loss: 0.0484 - val_mse: 0.0484\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.0511 - mse: 0.0511 - val_loss: 0.0457 - val_mse: 0.0457\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.0484 - mse: 0.0484 - val_loss: 0.0434 - val_mse: 0.0434\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.0462 - mse: 0.0462 - val_loss: 0.0399 - val_mse: 0.0399\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.0433 - mse: 0.0433 - val_loss: 0.0381 - val_mse: 0.0381\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.0410 - mse: 0.0410 - val_loss: 0.0367 - val_mse: 0.0367\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.0390 - mse: 0.0390 - val_loss: 0.0349 - val_mse: 0.0349\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.0370 - mse: 0.0370 - val_loss: 0.0334 - val_mse: 0.0334\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.0351 - mse: 0.0351 - val_loss: 0.0316 - val_mse: 0.0316\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.0331 - mse: 0.0331 - val_loss: 0.0301 - val_mse: 0.0301\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.0316 - mse: 0.0316 - val_loss: 0.0283 - val_mse: 0.0283\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.0298 - mse: 0.0298 - val_loss: 0.0267 - val_mse: 0.0267\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.0281 - mse: 0.0281 - val_loss: 0.0254 - val_mse: 0.0254\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.0267 - mse: 0.0267 - val_loss: 0.0244 - val_mse: 0.0244\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.0256 - mse: 0.0256 - val_loss: 0.0233 - val_mse: 0.0233\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.0243 - mse: 0.0243 - val_loss: 0.0221 - val_mse: 0.0221\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.0229 - mse: 0.0229 - val_loss: 0.0209 - val_mse: 0.0209\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0184 - val_mse: 0.0184\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0175 - val_mse: 0.0175\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0127 - val_mse: 0.0127\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0122 - val_mse: 0.0122\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0117 - val_mse: 0.0117\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.0121 - mse: 0.0121 - val_loss: 0.0111 - val_mse: 0.0111\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.0116 - mse: 0.0116 - val_loss: 0.0103 - val_mse: 0.0103\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.0109 - mse: 0.0109 - val_loss: 0.0096 - val_mse: 0.0096\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0092 - val_mse: 0.0092\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0080 - val_mse: 0.0080\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.0087 - mse: 0.0087 - val_loss: 0.0076 - val_mse: 0.0076\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.0083 - mse: 0.0083 - val_loss: 0.0072 - val_mse: 0.0072\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.0078 - mse: 0.0078 - val_loss: 0.0068 - val_mse: 0.0068\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0065 - val_mse: 0.0065\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0062 - val_mse: 0.0062\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0059 - val_mse: 0.0059\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0056 - val_mse: 0.0056\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0053 - val_mse: 0.0053\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0050 - val_mse: 0.0050\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0048 - val_mse: 0.0048\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0046 - val_mse: 0.0046\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.0048 - mse: 0.0048 - val_loss: 0.0044 - val_mse: 0.0044\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0041 - val_mse: 0.0041\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0040 - val_mse: 0.0040\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0037 - val_mse: 0.0037\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0035 - val_mse: 0.0035\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0033 - val_mse: 0.0033\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 25ms/step - loss: 0.0035 - mse: 0.0035 - val_loss: 0.0032 - val_mse: 0.0032\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.0033 - mse: 0.0033 - val_loss: 0.0030 - val_mse: 0.0030\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.0031 - mse: 0.0031 - val_loss: 0.0029 - val_mse: 0.0029\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.0030 - mse: 0.0030 - val_loss: 0.0028 - val_mse: 0.0028\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.0028 - mse: 0.0028 - val_loss: 0.0026 - val_mse: 0.0026\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 0.0024 - val_mse: 0.0024\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 0.0023 - val_mse: 0.0023\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 0.0022 - val_mse: 0.0022\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0021 - val_mse: 0.0021\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 0.0020 - val_mse: 0.0020\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0019 - val_mse: 0.0019\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0017 - val_mse: 0.0017\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0017 - val_mse: 0.0017\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0015 - val_mse: 0.0015\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0015 - val_mse: 0.0015\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0013 - val_mse: 0.0013\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0013 - val_mse: 0.0013\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0010 - val_mse: 0.0010\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 9.6990e-04 - val_mse: 9.6990e-04\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 9.2053e-04 - val_mse: 9.2053e-04\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 9.4974e-04 - mse: 9.4974e-04 - val_loss: 8.8502e-04 - val_mse: 8.8502e-04\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 8.9782e-04 - mse: 8.9782e-04 - val_loss: 8.3475e-04 - val_mse: 8.3475e-04\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 8.5033e-04 - mse: 8.5033e-04 - val_loss: 7.7758e-04 - val_mse: 7.7758e-04\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 7.9344e-04 - mse: 7.9344e-04 - val_loss: 7.4126e-04 - val_mse: 7.4126e-04\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 7.5367e-04 - mse: 7.5367e-04 - val_loss: 7.0839e-04 - val_mse: 7.0839e-04\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 7.1312e-04 - mse: 7.1312e-04 - val_loss: 6.7930e-04 - val_mse: 6.7930e-04\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 6.8093e-04 - mse: 6.8093e-04 - val_loss: 6.5117e-04 - val_mse: 6.5117e-04\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 6.5124e-04 - mse: 6.5124e-04 - val_loss: 6.1906e-04 - val_mse: 6.1906e-04\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 6.2146e-04 - mse: 6.2146e-04 - val_loss: 5.9211e-04 - val_mse: 5.9211e-04\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 5.9009e-04 - mse: 5.9009e-04 - val_loss: 5.5294e-04 - val_mse: 5.5294e-04\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 5.5861e-04 - mse: 5.5861e-04 - val_loss: 5.2204e-04 - val_mse: 5.2204e-04\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 5.3172e-04 - mse: 5.3172e-04 - val_loss: 4.9594e-04 - val_mse: 4.9594e-04\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 5.0343e-04 - mse: 5.0343e-04 - val_loss: 4.7150e-04 - val_mse: 4.7150e-04\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 4.7659e-04 - mse: 4.7659e-04 - val_loss: 4.5217e-04 - val_mse: 4.5217e-04\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 4.5214e-04 - mse: 4.5214e-04 - val_loss: 4.2951e-04 - val_mse: 4.2951e-04\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 4.2780e-04 - mse: 4.2780e-04 - val_loss: 4.0929e-04 - val_mse: 4.0929e-04\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 4.0497e-04 - mse: 4.0497e-04 - val_loss: 3.9066e-04 - val_mse: 3.9066e-04\n",
      "INFO:tensorflow:Assets written to: out/111-model-ntrain=100-sigma=0.0-epochs=100.tf/assets\n",
      "\n",
      "Epoch 1/10\n",
      "4/4 [==============================] - 1s 90ms/step - loss: 3.8336 - mse: 3.8336 - val_loss: 7.8146 - val_mse: 7.8146\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 3.5570 - mse: 3.5570 - val_loss: 7.4819 - val_mse: 7.4819\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 3.3799 - mse: 3.3799 - val_loss: 7.0930 - val_mse: 7.0930\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 3.1847 - mse: 3.1847 - val_loss: 6.8596 - val_mse: 6.8596\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 3.0651 - mse: 3.0651 - val_loss: 6.6436 - val_mse: 6.6436\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 2.9526 - mse: 2.9526 - val_loss: 6.4350 - val_mse: 6.4350\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 2.8420 - mse: 2.8420 - val_loss: 6.0758 - val_mse: 6.0758\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 2.6713 - mse: 2.6713 - val_loss: 5.8677 - val_mse: 5.8677\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 2.5684 - mse: 2.5684 - val_loss: 5.7128 - val_mse: 5.7128\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 2.4830 - mse: 2.4830 - val_loss: 5.5462 - val_mse: 5.5462\n",
      "INFO:tensorflow:Assets written to: out/111-model-ntrain=100-sigma=1.0-epochs=10.tf/assets\n",
      "Epoch 1/55\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 2.3975 - mse: 2.3975 - val_loss: 5.3066 - val_mse: 5.3066\n",
      "Epoch 2/55\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 2.2865 - mse: 2.2865 - val_loss: 5.1675 - val_mse: 5.1675\n",
      "Epoch 3/55\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 2.2174 - mse: 2.2174 - val_loss: 4.9899 - val_mse: 4.9899\n",
      "Epoch 4/55\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 2.1395 - mse: 2.1395 - val_loss: 4.8950 - val_mse: 4.8950\n",
      "Epoch 5/55\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 2.0910 - mse: 2.0910 - val_loss: 4.7995 - val_mse: 4.7995\n",
      "Epoch 6/55\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 2.0415 - mse: 2.0415 - val_loss: 4.7026 - val_mse: 4.7026\n",
      "Epoch 7/55\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.9919 - mse: 1.9919 - val_loss: 4.5153 - val_mse: 4.5153\n",
      "Epoch 8/55\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.9142 - mse: 1.9142 - val_loss: 4.4144 - val_mse: 4.4144\n",
      "Epoch 9/55\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.8657 - mse: 1.8657 - val_loss: 4.3383 - val_mse: 4.3383\n",
      "Epoch 10/55\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.8214 - mse: 1.8214 - val_loss: 4.2587 - val_mse: 4.2587\n",
      "Epoch 11/55\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.7819 - mse: 1.7819 - val_loss: 4.1976 - val_mse: 4.1976\n",
      "Epoch 12/55\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.7482 - mse: 1.7482 - val_loss: 4.0283 - val_mse: 4.0283\n",
      "Epoch 13/55\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.6797 - mse: 1.6797 - val_loss: 3.9714 - val_mse: 3.9714\n",
      "Epoch 14/55\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.6500 - mse: 1.6500 - val_loss: 3.9358 - val_mse: 3.9358\n",
      "Epoch 15/55\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.6190 - mse: 1.6190 - val_loss: 3.8736 - val_mse: 3.8736\n",
      "Epoch 16/55\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1.5896 - mse: 1.5896 - val_loss: 3.7920 - val_mse: 3.7920\n",
      "Epoch 17/55\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.5555 - mse: 1.5555 - val_loss: 3.7175 - val_mse: 3.7175\n",
      "Epoch 18/55\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1.5251 - mse: 1.5251 - val_loss: 3.6481 - val_mse: 3.6481\n",
      "Epoch 19/55\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.4951 - mse: 1.4951 - val_loss: 3.5570 - val_mse: 3.5570\n",
      "Epoch 20/55\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 1.4592 - mse: 1.4592 - val_loss: 3.4948 - val_mse: 3.4948\n",
      "Epoch 21/55\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1.4338 - mse: 1.4338 - val_loss: 3.4622 - val_mse: 3.4622\n",
      "Epoch 22/55\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1.4152 - mse: 1.4152 - val_loss: 3.4121 - val_mse: 3.4121\n",
      "Epoch 23/55\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 1.3948 - mse: 1.3948 - val_loss: 3.3801 - val_mse: 3.3801\n",
      "Epoch 24/55\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.3765 - mse: 1.3765 - val_loss: 3.3344 - val_mse: 3.3344\n",
      "Epoch 25/55\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.3594 - mse: 1.3594 - val_loss: 3.3006 - val_mse: 3.3006\n",
      "Epoch 26/55\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 1.3430 - mse: 1.3430 - val_loss: 3.2513 - val_mse: 3.2513\n",
      "Epoch 27/55\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.3257 - mse: 1.3257 - val_loss: 3.2024 - val_mse: 3.2024\n",
      "Epoch 28/55\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.3094 - mse: 1.3094 - val_loss: 3.1747 - val_mse: 3.1747\n",
      "Epoch 29/55\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.2971 - mse: 1.2971 - val_loss: 3.1162 - val_mse: 3.1162\n",
      "Epoch 30/55\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.2760 - mse: 1.2760 - val_loss: 3.0693 - val_mse: 3.0693\n",
      "Epoch 31/55\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.2575 - mse: 1.2575 - val_loss: 3.0314 - val_mse: 3.0314\n",
      "Epoch 32/55\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.2456 - mse: 1.2456 - val_loss: 3.0104 - val_mse: 3.0104\n",
      "Epoch 33/55\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.2383 - mse: 1.2383 - val_loss: 2.9835 - val_mse: 2.9835\n",
      "Epoch 34/55\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.2235 - mse: 1.2235 - val_loss: 2.9528 - val_mse: 2.9528\n",
      "Epoch 35/55\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.2100 - mse: 1.2100 - val_loss: 2.9282 - val_mse: 2.9282\n",
      "Epoch 36/55\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.2015 - mse: 1.2015 - val_loss: 2.8999 - val_mse: 2.8999\n",
      "Epoch 37/55\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.1934 - mse: 1.1934 - val_loss: 2.8537 - val_mse: 2.8537\n",
      "Epoch 38/55\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.1812 - mse: 1.1812 - val_loss: 2.8169 - val_mse: 2.8169\n",
      "Epoch 39/55\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.1697 - mse: 1.1697 - val_loss: 2.7998 - val_mse: 2.7998\n",
      "Epoch 40/55\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1.1632 - mse: 1.1632 - val_loss: 2.7804 - val_mse: 2.7804\n",
      "Epoch 41/55\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1.1553 - mse: 1.1553 - val_loss: 2.7778 - val_mse: 2.7778\n",
      "Epoch 42/55\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.1483 - mse: 1.1483 - val_loss: 2.7438 - val_mse: 2.7438\n",
      "Epoch 43/55\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.1391 - mse: 1.1391 - val_loss: 2.7152 - val_mse: 2.7152\n",
      "Epoch 44/55\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.1320 - mse: 1.1320 - val_loss: 2.6919 - val_mse: 2.6919\n",
      "Epoch 45/55\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1.1232 - mse: 1.1232 - val_loss: 2.6708 - val_mse: 2.6708\n",
      "Epoch 46/55\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1.1181 - mse: 1.1181 - val_loss: 2.6554 - val_mse: 2.6554\n",
      "Epoch 47/55\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.1127 - mse: 1.1127 - val_loss: 2.6365 - val_mse: 2.6365\n",
      "Epoch 48/55\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.1072 - mse: 1.1072 - val_loss: 2.6250 - val_mse: 2.6250\n",
      "Epoch 49/55\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1.1026 - mse: 1.1026 - val_loss: 2.6123 - val_mse: 2.6123\n",
      "Epoch 50/55\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1.0961 - mse: 1.0961 - val_loss: 2.6145 - val_mse: 2.6145\n",
      "Epoch 51/55\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.0938 - mse: 1.0938 - val_loss: 2.5935 - val_mse: 2.5935\n",
      "Epoch 52/55\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1.0917 - mse: 1.0917 - val_loss: 2.5905 - val_mse: 2.5905\n",
      "Epoch 53/55\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.0877 - mse: 1.0877 - val_loss: 2.5658 - val_mse: 2.5658\n",
      "Epoch 54/55\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.0812 - mse: 1.0812 - val_loss: 2.5519 - val_mse: 2.5519\n",
      "Epoch 55/55\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1.0770 - mse: 1.0770 - val_loss: 2.5324 - val_mse: 2.5324\n",
      "INFO:tensorflow:Assets written to: out/111-model-ntrain=100-sigma=1.0-epochs=55.tf/assets\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 1.0712 - mse: 1.0712 - val_loss: 2.5066 - val_mse: 2.5066\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.0659 - mse: 1.0659 - val_loss: 2.5007 - val_mse: 2.5007\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.0627 - mse: 1.0627 - val_loss: 2.4856 - val_mse: 2.4856\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.0604 - mse: 1.0604 - val_loss: 2.4870 - val_mse: 2.4870\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.0581 - mse: 1.0581 - val_loss: 2.4808 - val_mse: 2.4808\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1.0551 - mse: 1.0551 - val_loss: 2.4746 - val_mse: 2.4746\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.0537 - mse: 1.0537 - val_loss: 2.4488 - val_mse: 2.4488\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.0506 - mse: 1.0506 - val_loss: 2.4410 - val_mse: 2.4410\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.0470 - mse: 1.0470 - val_loss: 2.4357 - val_mse: 2.4357\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1.0439 - mse: 1.0439 - val_loss: 2.4365 - val_mse: 2.4365\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.0431 - mse: 1.0431 - val_loss: 2.4428 - val_mse: 2.4428\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.0419 - mse: 1.0419 - val_loss: 2.4088 - val_mse: 2.4088\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.0366 - mse: 1.0366 - val_loss: 2.4079 - val_mse: 2.4079\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.0358 - mse: 1.0358 - val_loss: 2.4108 - val_mse: 2.4108\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.0335 - mse: 1.0335 - val_loss: 2.4064 - val_mse: 2.4064\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 28ms/step - loss: 1.0329 - mse: 1.0329 - val_loss: 2.3853 - val_mse: 2.3853\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.0301 - mse: 1.0301 - val_loss: 2.3743 - val_mse: 2.3743\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.0283 - mse: 1.0283 - val_loss: 2.3608 - val_mse: 2.3608\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.0260 - mse: 1.0260 - val_loss: 2.3390 - val_mse: 2.3390\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.0234 - mse: 1.0234 - val_loss: 2.3299 - val_mse: 2.3299\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.0230 - mse: 1.0230 - val_loss: 2.3337 - val_mse: 2.3337\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.0215 - mse: 1.0215 - val_loss: 2.3234 - val_mse: 2.3234\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1.0201 - mse: 1.0201 - val_loss: 2.3243 - val_mse: 2.3243\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.0198 - mse: 1.0198 - val_loss: 2.3184 - val_mse: 2.3184\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.0192 - mse: 1.0192 - val_loss: 2.3191 - val_mse: 2.3191\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.0184 - mse: 1.0184 - val_loss: 2.3164 - val_mse: 2.3164\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.0188 - mse: 1.0188 - val_loss: 2.3061 - val_mse: 2.3061\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.0182 - mse: 1.0182 - val_loss: 2.3071 - val_mse: 2.3071\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.0182 - mse: 1.0182 - val_loss: 2.2929 - val_mse: 2.2929\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1.0161 - mse: 1.0161 - val_loss: 2.2810 - val_mse: 2.2810\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1.0144 - mse: 1.0144 - val_loss: 2.2727 - val_mse: 2.2727\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.0140 - mse: 1.0140 - val_loss: 2.2764 - val_mse: 2.2764\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.0147 - mse: 1.0147 - val_loss: 2.2714 - val_mse: 2.2714\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.0132 - mse: 1.0132 - val_loss: 2.2623 - val_mse: 2.2623\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.0117 - mse: 1.0117 - val_loss: 2.2591 - val_mse: 2.2591\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.0111 - mse: 1.0111 - val_loss: 2.2514 - val_mse: 2.2514\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.0120 - mse: 1.0120 - val_loss: 2.2337 - val_mse: 2.2337\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.0101 - mse: 1.0101 - val_loss: 2.2275 - val_mse: 2.2275\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.0093 - mse: 1.0093 - val_loss: 2.2309 - val_mse: 2.2309\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.0094 - mse: 1.0094 - val_loss: 2.2282 - val_mse: 2.2282\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1.0091 - mse: 1.0091 - val_loss: 2.2412 - val_mse: 2.2412\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.0083 - mse: 1.0083 - val_loss: 2.2329 - val_mse: 2.2329\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.0079 - mse: 1.0079 - val_loss: 2.2251 - val_mse: 2.2251\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.0079 - mse: 1.0079 - val_loss: 2.2197 - val_mse: 2.2197\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.0074 - mse: 1.0074 - val_loss: 2.2132 - val_mse: 2.2132\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1.0067 - mse: 1.0067 - val_loss: 2.2121 - val_mse: 2.2121\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.0064 - mse: 1.0064 - val_loss: 2.2055 - val_mse: 2.2055\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.0065 - mse: 1.0065 - val_loss: 2.2070 - val_mse: 2.2070\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.0063 - mse: 1.0063 - val_loss: 2.2052 - val_mse: 2.2052\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.0052 - mse: 1.0052 - val_loss: 2.2163 - val_mse: 2.2163\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.0056 - mse: 1.0056 - val_loss: 2.2100 - val_mse: 2.2100\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1.0067 - mse: 1.0067 - val_loss: 2.2143 - val_mse: 2.2143\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.0066 - mse: 1.0066 - val_loss: 2.2033 - val_mse: 2.2033\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.0051 - mse: 1.0051 - val_loss: 2.1993 - val_mse: 2.1993\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.0049 - mse: 1.0049 - val_loss: 2.1934 - val_mse: 2.1934\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.0038 - mse: 1.0038 - val_loss: 2.1879 - val_mse: 2.1879\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.0047 - mse: 1.0047 - val_loss: 2.1966 - val_mse: 2.1966\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.0045 - mse: 1.0045 - val_loss: 2.1802 - val_mse: 2.1802\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.0035 - mse: 1.0035 - val_loss: 2.1904 - val_mse: 2.1904\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.0033 - mse: 1.0033 - val_loss: 2.1880 - val_mse: 2.1880\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.0027 - mse: 1.0027 - val_loss: 2.1888 - val_mse: 2.1888\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 1.0033 - mse: 1.0033 - val_loss: 2.1944 - val_mse: 2.1944\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.0031 - mse: 1.0031 - val_loss: 2.1876 - val_mse: 2.1876\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.0025 - mse: 1.0025 - val_loss: 2.1744 - val_mse: 2.1744\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1.0027 - mse: 1.0027 - val_loss: 2.1709 - val_mse: 2.1709\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.0024 - mse: 1.0024 - val_loss: 2.1682 - val_mse: 2.1682\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1.0023 - mse: 1.0023 - val_loss: 2.1641 - val_mse: 2.1641\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1.0026 - mse: 1.0026 - val_loss: 2.1621 - val_mse: 2.1621\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.0012 - mse: 1.0012 - val_loss: 2.1554 - val_mse: 2.1554\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.0016 - mse: 1.0016 - val_loss: 2.1703 - val_mse: 2.1703\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.0015 - mse: 1.0015 - val_loss: 2.1722 - val_mse: 2.1722\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1.0011 - mse: 1.0011 - val_loss: 2.1662 - val_mse: 2.1662\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.0023 - mse: 1.0023 - val_loss: 2.1616 - val_mse: 2.1616\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.0006 - mse: 1.0006 - val_loss: 2.1536 - val_mse: 2.1536\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.0012 - mse: 1.0012 - val_loss: 2.1521 - val_mse: 2.1521\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.0018 - mse: 1.0018 - val_loss: 2.1478 - val_mse: 2.1478\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.0005 - mse: 1.0005 - val_loss: 2.1503 - val_mse: 2.1503\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.0001 - mse: 1.0001 - val_loss: 2.1549 - val_mse: 2.1549\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.0000 - mse: 1.0000 - val_loss: 2.1499 - val_mse: 2.1499\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.0000 - mse: 1.0000 - val_loss: 2.1474 - val_mse: 2.1474\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.9999 - mse: 0.9999 - val_loss: 2.1515 - val_mse: 2.1515\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.0012 - mse: 1.0012 - val_loss: 2.1562 - val_mse: 2.1562\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.0007 - mse: 1.0007 - val_loss: 2.1509 - val_mse: 2.1509\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.0007 - mse: 1.0007 - val_loss: 2.1495 - val_mse: 2.1495\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.0000 - mse: 1.0000 - val_loss: 2.1402 - val_mse: 2.1402\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.9995 - mse: 0.9995 - val_loss: 2.1232 - val_mse: 2.1232\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.9998 - mse: 0.9998 - val_loss: 2.1275 - val_mse: 2.1275\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.9993 - mse: 0.9993 - val_loss: 2.1278 - val_mse: 2.1278\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.9994 - mse: 0.9994 - val_loss: 2.1200 - val_mse: 2.1200\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.9989 - mse: 0.9989 - val_loss: 2.1208 - val_mse: 2.1208\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.9997 - mse: 0.9997 - val_loss: 2.1138 - val_mse: 2.1138\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.9987 - mse: 0.9987 - val_loss: 2.1201 - val_mse: 2.1201\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.9993 - mse: 0.9993 - val_loss: 2.1160 - val_mse: 2.1160\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.9995 - mse: 0.9995 - val_loss: 2.1230 - val_mse: 2.1230\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.9991 - mse: 0.9991 - val_loss: 2.1218 - val_mse: 2.1218\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.9989 - mse: 0.9989 - val_loss: 2.1197 - val_mse: 2.1197\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.9996 - mse: 0.9996 - val_loss: 2.1115 - val_mse: 2.1115\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.9989 - mse: 0.9989 - val_loss: 2.1161 - val_mse: 2.1161\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.9996 - mse: 0.9996 - val_loss: 2.1131 - val_mse: 2.1131\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.9993 - mse: 0.9993 - val_loss: 2.1167 - val_mse: 2.1167\n",
      "INFO:tensorflow:Assets written to: out/111-model-ntrain=100-sigma=1.0-epochs=100.tf/assets\n",
      "\n",
      "Epoch 1/10\n",
      "4/4 [==============================] - 1s 92ms/step - loss: 101.9755 - mse: 101.9755 - val_loss: 222.4313 - val_mse: 222.4313\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 101.5139 - mse: 101.5139 - val_loss: 222.0269 - val_mse: 222.0269\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 101.3854 - mse: 101.3854 - val_loss: 220.8467 - val_mse: 220.8467\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 101.0899 - mse: 101.0899 - val_loss: 221.2065 - val_mse: 221.2065\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 101.1969 - mse: 101.1969 - val_loss: 220.7112 - val_mse: 220.7112\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 101.0738 - mse: 101.0738 - val_loss: 220.2231 - val_mse: 220.2231\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 100.8095 - mse: 100.8095 - val_loss: 218.5506 - val_mse: 218.5506\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 100.6577 - mse: 100.6577 - val_loss: 218.1870 - val_mse: 218.1870\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 100.5180 - mse: 100.5180 - val_loss: 218.0412 - val_mse: 218.0412\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 100.5487 - mse: 100.5487 - val_loss: 218.6157 - val_mse: 218.6157\n",
      "INFO:tensorflow:Assets written to: out/111-model-ntrain=100-sigma=10.0-epochs=10.tf/assets\n",
      "Epoch 1/55\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 100.6738 - mse: 100.6738 - val_loss: 217.1265 - val_mse: 217.1265\n",
      "Epoch 2/55\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 100.4559 - mse: 100.4559 - val_loss: 217.1035 - val_mse: 217.1035\n",
      "Epoch 3/55\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 100.4356 - mse: 100.4356 - val_loss: 216.3938 - val_mse: 216.3938\n",
      "Epoch 4/55\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 100.3159 - mse: 100.3159 - val_loss: 216.9909 - val_mse: 216.9909\n",
      "Epoch 5/55\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 100.4364 - mse: 100.4364 - val_loss: 216.7792 - val_mse: 216.7792\n",
      "Epoch 6/55\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 100.3931 - mse: 100.3931 - val_loss: 216.5909 - val_mse: 216.5909\n",
      "Epoch 7/55\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 100.2540 - mse: 100.2540 - val_loss: 215.2899 - val_mse: 215.2899\n",
      "Epoch 8/55\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 100.2263 - mse: 100.2263 - val_loss: 215.1503 - val_mse: 215.1503\n",
      "Epoch 9/55\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 100.1269 - mse: 100.1269 - val_loss: 215.1687 - val_mse: 215.1687\n",
      "Epoch 10/55\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 100.1726 - mse: 100.1726 - val_loss: 215.8844 - val_mse: 215.8844\n",
      "Epoch 11/55\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 100.3309 - mse: 100.3309 - val_loss: 216.9709 - val_mse: 216.9709\n",
      "Epoch 12/55\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 100.3853 - mse: 100.3853 - val_loss: 214.9936 - val_mse: 214.9936\n",
      "Epoch 13/55\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 100.2148 - mse: 100.2148 - val_loss: 215.3469 - val_mse: 215.3469\n",
      "Epoch 14/55\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 100.2502 - mse: 100.2502 - val_loss: 216.0306 - val_mse: 216.0306\n",
      "Epoch 15/55\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 100.4405 - mse: 100.4405 - val_loss: 216.1193 - val_mse: 216.1193\n",
      "Epoch 16/55\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 100.5050 - mse: 100.5050 - val_loss: 214.5954 - val_mse: 214.5954\n",
      "Epoch 17/55\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 100.2664 - mse: 100.2664 - val_loss: 214.1301 - val_mse: 214.1301\n",
      "Epoch 18/55\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 100.0695 - mse: 100.0695 - val_loss: 213.4167 - val_mse: 213.4167\n",
      "Epoch 19/55\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 100.0451 - mse: 100.0451 - val_loss: 212.1247 - val_mse: 212.1247\n",
      "Epoch 20/55\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 100.0193 - mse: 100.0193 - val_loss: 211.8398 - val_mse: 211.8398\n",
      "Epoch 21/55\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 100.0865 - mse: 100.0865 - val_loss: 212.5782 - val_mse: 212.5782\n",
      "Epoch 22/55\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 99.9759 - mse: 99.9759 - val_loss: 212.0356 - val_mse: 212.0356\n",
      "Epoch 23/55\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 99.9612 - mse: 99.9612 - val_loss: 212.5166 - val_mse: 212.5166\n",
      "Epoch 24/55\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 100.0859 - mse: 100.0859 - val_loss: 212.4057 - val_mse: 212.4057\n",
      "Epoch 25/55\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 99.9559 - mse: 99.9559 - val_loss: 212.9015 - val_mse: 212.9015\n",
      "Epoch 26/55\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 99.9518 - mse: 99.9518 - val_loss: 213.2540 - val_mse: 213.2540\n",
      "Epoch 27/55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 23ms/step - loss: 99.9944 - mse: 99.9944 - val_loss: 212.7554 - val_mse: 212.7554\n",
      "Epoch 28/55\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 99.9574 - mse: 99.9574 - val_loss: 213.2334 - val_mse: 213.2334\n",
      "Epoch 29/55\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 100.0014 - mse: 100.0014 - val_loss: 212.5083 - val_mse: 212.5083\n",
      "Epoch 30/55\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 99.9283 - mse: 99.9283 - val_loss: 211.8820 - val_mse: 211.8820\n",
      "Epoch 31/55\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 99.8838 - mse: 99.8838 - val_loss: 211.5043 - val_mse: 211.5043\n",
      "Epoch 32/55\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 99.9065 - mse: 99.9065 - val_loss: 212.2136 - val_mse: 212.2136\n",
      "Epoch 33/55\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 99.9298 - mse: 99.9298 - val_loss: 212.0685 - val_mse: 212.0685\n",
      "Epoch 34/55\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 99.9659 - mse: 99.9659 - val_loss: 211.5256 - val_mse: 211.5256\n",
      "Epoch 35/55\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 99.9140 - mse: 99.9140 - val_loss: 211.5440 - val_mse: 211.5440\n",
      "Epoch 36/55\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 99.8946 - mse: 99.8946 - val_loss: 211.1140 - val_mse: 211.1140\n",
      "Epoch 37/55\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 100.0370 - mse: 100.0370 - val_loss: 209.8510 - val_mse: 209.8510\n",
      "Epoch 38/55\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 99.9142 - mse: 99.9142 - val_loss: 209.7775 - val_mse: 209.7775\n",
      "Epoch 39/55\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 99.9117 - mse: 99.9117 - val_loss: 210.4513 - val_mse: 210.4513\n",
      "Epoch 40/55\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 99.9292 - mse: 99.9292 - val_loss: 210.4706 - val_mse: 210.4706\n",
      "Epoch 41/55\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 99.9592 - mse: 99.9592 - val_loss: 212.0145 - val_mse: 212.0145\n",
      "Epoch 42/55\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 99.8901 - mse: 99.8901 - val_loss: 211.6632 - val_mse: 211.6632\n",
      "Epoch 43/55\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 99.9111 - mse: 99.9111 - val_loss: 211.2693 - val_mse: 211.2693\n",
      "Epoch 44/55\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 99.9642 - mse: 99.9642 - val_loss: 211.0781 - val_mse: 211.0781\n",
      "Epoch 45/55\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 99.9969 - mse: 99.9969 - val_loss: 210.7046 - val_mse: 210.7046\n",
      "Epoch 46/55\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 99.9049 - mse: 99.9049 - val_loss: 210.8601 - val_mse: 210.8601\n",
      "Epoch 47/55\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 99.9015 - mse: 99.9015 - val_loss: 210.4314 - val_mse: 210.4314\n",
      "Epoch 48/55\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 99.9406 - mse: 99.9406 - val_loss: 210.8328 - val_mse: 210.8328\n",
      "Epoch 49/55\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 99.9219 - mse: 99.9219 - val_loss: 210.8692 - val_mse: 210.8692\n",
      "Epoch 50/55\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 99.8827 - mse: 99.8827 - val_loss: 212.1195 - val_mse: 212.1195\n",
      "Epoch 51/55\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 99.9005 - mse: 99.9005 - val_loss: 211.7884 - val_mse: 211.7884\n",
      "Epoch 52/55\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 99.9937 - mse: 99.9937 - val_loss: 212.3624 - val_mse: 212.3624\n",
      "Epoch 53/55\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 100.0252 - mse: 100.0252 - val_loss: 211.5480 - val_mse: 211.5480\n",
      "Epoch 54/55\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 99.9330 - mse: 99.9330 - val_loss: 211.3588 - val_mse: 211.3588\n",
      "Epoch 55/55\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 99.9466 - mse: 99.9466 - val_loss: 211.0573 - val_mse: 211.0573\n",
      "INFO:tensorflow:Assets written to: out/111-model-ntrain=100-sigma=10.0-epochs=55.tf/assets\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 99.9226 - mse: 99.9226 - val_loss: 210.3234 - val_mse: 210.3234\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 99.8950 - mse: 99.8950 - val_loss: 210.7274 - val_mse: 210.7274\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 99.8780 - mse: 99.8780 - val_loss: 210.6090 - val_mse: 210.6090\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 99.8992 - mse: 99.8992 - val_loss: 211.4519 - val_mse: 211.4519\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 99.9157 - mse: 99.9157 - val_loss: 211.5836 - val_mse: 211.5836\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 99.8972 - mse: 99.8972 - val_loss: 211.7831 - val_mse: 211.7831\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 99.8792 - mse: 99.8792 - val_loss: 210.9771 - val_mse: 210.9771\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 99.9733 - mse: 99.9733 - val_loss: 211.1202 - val_mse: 211.1202\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 99.8729 - mse: 99.8729 - val_loss: 211.3384 - val_mse: 211.3384\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 99.8862 - mse: 99.8862 - val_loss: 212.2218 - val_mse: 212.2218\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 99.9819 - mse: 99.9819 - val_loss: 213.4581 - val_mse: 213.4581\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 99.9861 - mse: 99.9861 - val_loss: 211.8792 - val_mse: 211.8792\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 99.9397 - mse: 99.9397 - val_loss: 212.4003 - val_mse: 212.4003\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 99.9706 - mse: 99.9706 - val_loss: 213.1411 - val_mse: 213.1411\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 100.0745 - mse: 100.0745 - val_loss: 213.3964 - val_mse: 213.3964\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 100.1594 - mse: 100.1594 - val_loss: 212.1329 - val_mse: 212.1329\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 100.0386 - mse: 100.0386 - val_loss: 211.8757 - val_mse: 211.8757\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 99.9131 - mse: 99.9131 - val_loss: 211.3216 - val_mse: 211.3216\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 99.9150 - mse: 99.9150 - val_loss: 210.2082 - val_mse: 210.2082\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 99.9316 - mse: 99.9316 - val_loss: 210.0558 - val_mse: 210.0558\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 100.0193 - mse: 100.0193 - val_loss: 210.8728 - val_mse: 210.8728\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 99.8975 - mse: 99.8975 - val_loss: 210.4440 - val_mse: 210.4440\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 99.9008 - mse: 99.9008 - val_loss: 210.9814 - val_mse: 210.9814\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 100.0044 - mse: 100.0044 - val_loss: 210.9790 - val_mse: 210.9790\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 99.9042 - mse: 99.9042 - val_loss: 211.5389 - val_mse: 211.5389\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 99.8912 - mse: 99.8912 - val_loss: 211.9785 - val_mse: 211.9785\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 99.9439 - mse: 99.9439 - val_loss: 211.5745 - val_mse: 211.5745\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 99.9300 - mse: 99.9300 - val_loss: 212.1045 - val_mse: 212.1045\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 99.9669 - mse: 99.9669 - val_loss: 211.4627 - val_mse: 211.4627\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 99.9085 - mse: 99.9085 - val_loss: 210.9032 - val_mse: 210.9032\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 99.8743 - mse: 99.8743 - val_loss: 210.5869 - val_mse: 210.5869\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 99.9044 - mse: 99.9044 - val_loss: 211.3402 - val_mse: 211.3402\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 99.9249 - mse: 99.9249 - val_loss: 211.2262 - val_mse: 211.2262\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 99.9525 - mse: 99.9525 - val_loss: 210.7267 - val_mse: 210.7267\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 99.9072 - mse: 99.9072 - val_loss: 210.7834 - val_mse: 210.7834\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 99.8882 - mse: 99.8882 - val_loss: 210.3935 - val_mse: 210.3935\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 100.0364 - mse: 100.0364 - val_loss: 209.1871 - val_mse: 209.1871\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 99.9291 - mse: 99.9291 - val_loss: 209.1511 - val_mse: 209.1511\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 99.9239 - mse: 99.9239 - val_loss: 209.8488 - val_mse: 209.8488\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 99.9346 - mse: 99.9346 - val_loss: 209.8933 - val_mse: 209.8933\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 99.9627 - mse: 99.9627 - val_loss: 211.4472 - val_mse: 211.4472\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 99.8800 - mse: 99.8800 - val_loss: 211.1302 - val_mse: 211.1302\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 99.9042 - mse: 99.9042 - val_loss: 210.7665 - val_mse: 210.7665\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 99.9601 - mse: 99.9601 - val_loss: 210.5970 - val_mse: 210.5970\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 99.9923 - mse: 99.9923 - val_loss: 210.2489 - val_mse: 210.2489\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 99.9048 - mse: 99.9048 - val_loss: 210.4229 - val_mse: 210.4229\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 99.9009 - mse: 99.9009 - val_loss: 210.0131 - val_mse: 210.0131\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 99.9429 - mse: 99.9429 - val_loss: 210.4292 - val_mse: 210.4292\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 99.9217 - mse: 99.9217 - val_loss: 210.4778 - val_mse: 210.4778\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 99.8809 - mse: 99.8809 - val_loss: 211.7357 - val_mse: 211.7357\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 99.8937 - mse: 99.8937 - val_loss: 211.4248 - val_mse: 211.4248\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 99.9894 - mse: 99.9894 - val_loss: 212.0059 - val_mse: 212.0059\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 100.0183 - mse: 100.0183 - val_loss: 211.2088 - val_mse: 211.2088\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 99.9289 - mse: 99.9289 - val_loss: 211.0313 - val_mse: 211.0313\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 99.9430 - mse: 99.9430 - val_loss: 210.7440 - val_mse: 210.7440\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 99.8865 - mse: 99.8865 - val_loss: 210.4281 - val_mse: 210.4281\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 99.9589 - mse: 99.9589 - val_loss: 211.4991 - val_mse: 211.4991\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 99.9569 - mse: 99.9569 - val_loss: 210.2065 - val_mse: 210.2065\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 99.9201 - mse: 99.9201 - val_loss: 211.3560 - val_mse: 211.3560\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 99.9144 - mse: 99.9144 - val_loss: 211.2750 - val_mse: 211.2750\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 99.8775 - mse: 99.8775 - val_loss: 211.5061 - val_mse: 211.5061\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 99.9210 - mse: 99.9210 - val_loss: 212.2308 - val_mse: 212.2308\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 99.9065 - mse: 99.9065 - val_loss: 211.7378 - val_mse: 211.7378\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 99.8945 - mse: 99.8945 - val_loss: 210.7072 - val_mse: 210.7072\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 99.9449 - mse: 99.9449 - val_loss: 210.5676 - val_mse: 210.5676\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 99.9229 - mse: 99.9229 - val_loss: 210.4859 - val_mse: 210.4859\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 99.9110 - mse: 99.9110 - val_loss: 210.3145 - val_mse: 210.3145\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 99.9686 - mse: 99.9686 - val_loss: 210.2487 - val_mse: 210.2487\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 99.8897 - mse: 99.8897 - val_loss: 209.7523 - val_mse: 209.7523\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 99.9377 - mse: 99.9377 - val_loss: 211.3098 - val_mse: 211.3098\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 99.9318 - mse: 99.9318 - val_loss: 211.6674 - val_mse: 211.6674\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 99.8866 - mse: 99.8866 - val_loss: 211.2329 - val_mse: 211.2329\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 100.0372 - mse: 100.0372 - val_loss: 210.9751 - val_mse: 210.9751\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 99.8768 - mse: 99.8768 - val_loss: 210.3717 - val_mse: 210.3717\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 99.9470 - mse: 99.9470 - val_loss: 210.3518 - val_mse: 210.3518\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 99.9940 - mse: 99.9940 - val_loss: 210.0737 - val_mse: 210.0737\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 99.8979 - mse: 99.8979 - val_loss: 210.3960 - val_mse: 210.3960\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 99.8813 - mse: 99.8813 - val_loss: 210.9751 - val_mse: 210.9751\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 99.8707 - mse: 99.8707 - val_loss: 210.5967 - val_mse: 210.5967\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 99.8873 - mse: 99.8873 - val_loss: 210.4462 - val_mse: 210.4462\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 99.8996 - mse: 99.8996 - val_loss: 210.9574 - val_mse: 210.9574\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 100.0268 - mse: 100.0268 - val_loss: 211.5223 - val_mse: 211.5223\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 99.9815 - mse: 99.9815 - val_loss: 211.1156 - val_mse: 211.1156\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 99.9841 - mse: 99.9841 - val_loss: 211.0558 - val_mse: 211.0558\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 99.9236 - mse: 99.9236 - val_loss: 210.2658 - val_mse: 210.2658\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 99.8951 - mse: 99.8951 - val_loss: 208.7572 - val_mse: 208.7572\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 99.9741 - mse: 99.9741 - val_loss: 209.2512 - val_mse: 209.2512\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 99.9200 - mse: 99.9200 - val_loss: 209.3618 - val_mse: 209.3618\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 99.9310 - mse: 99.9310 - val_loss: 208.6697 - val_mse: 208.6697\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 99.8999 - mse: 99.8999 - val_loss: 208.8185 - val_mse: 208.8185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 99.9800 - mse: 99.9800 - val_loss: 208.2216 - val_mse: 208.2216\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 99.8814 - mse: 99.8814 - val_loss: 208.8996 - val_mse: 208.8996\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 99.9244 - mse: 99.9244 - val_loss: 208.6004 - val_mse: 208.6004\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 99.9456 - mse: 99.9456 - val_loss: 209.3732 - val_mse: 209.3732\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 99.9042 - mse: 99.9042 - val_loss: 209.3219 - val_mse: 209.3219\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 99.8803 - mse: 99.8803 - val_loss: 209.1927 - val_mse: 209.1927\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 99.9530 - mse: 99.9530 - val_loss: 208.4512 - val_mse: 208.4512\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 99.8793 - mse: 99.8793 - val_loss: 208.9666 - val_mse: 208.9666\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 99.9353 - mse: 99.9353 - val_loss: 208.7383 - val_mse: 208.7383\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 99.9013 - mse: 99.9013 - val_loss: 209.1449 - val_mse: 209.1449\n",
      "INFO:tensorflow:Assets written to: out/111-model-ntrain=100-sigma=10.0-epochs=100.tf/assets\n",
      "\n",
      "Epoch 1/10\n",
      "18/18 [==============================] - 1s 19ms/step - loss: 2.9446 - mse: 2.9446 - val_loss: 2.9579 - val_mse: 2.9579\n",
      "Epoch 2/10\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 2.1058 - mse: 2.1058 - val_loss: 2.1363 - val_mse: 2.1363\n",
      "Epoch 3/10\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.5390 - mse: 1.5390 - val_loss: 1.5969 - val_mse: 1.5969\n",
      "Epoch 4/10\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.1626 - mse: 1.1626 - val_loss: 1.2156 - val_mse: 1.2156\n",
      "Epoch 5/10\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.8912 - mse: 0.8912 - val_loss: 0.9356 - val_mse: 0.9356\n",
      "Epoch 6/10\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.6905 - mse: 0.6905 - val_loss: 0.7170 - val_mse: 0.7170\n",
      "Epoch 7/10\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5334 - mse: 0.5334 - val_loss: 0.5496 - val_mse: 0.5496\n",
      "Epoch 8/10\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4112 - mse: 0.4112 - val_loss: 0.4298 - val_mse: 0.4298\n",
      "Epoch 9/10\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.3229 - mse: 0.3229 - val_loss: 0.3362 - val_mse: 0.3362\n",
      "Epoch 10/10\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.2534 - mse: 0.2534 - val_loss: 0.2610 - val_mse: 0.2610\n",
      "INFO:tensorflow:Assets written to: out/111-model-ntrain=550-sigma=0.0-epochs=10.tf/assets\n",
      "Epoch 1/55\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.1971 - mse: 0.1971 - val_loss: 0.2039 - val_mse: 0.2039\n",
      "Epoch 2/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1544 - mse: 0.1544 - val_loss: 0.1589 - val_mse: 0.1589\n",
      "Epoch 3/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1206 - mse: 0.1206 - val_loss: 0.1244 - val_mse: 0.1244\n",
      "Epoch 4/55\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0944 - mse: 0.0944 - val_loss: 0.0972 - val_mse: 0.0972\n",
      "Epoch 5/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0737 - mse: 0.0737 - val_loss: 0.0765 - val_mse: 0.0765\n",
      "Epoch 6/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0580 - mse: 0.0580 - val_loss: 0.0597 - val_mse: 0.0597\n",
      "Epoch 7/55\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0454 - mse: 0.0454 - val_loss: 0.0463 - val_mse: 0.0463\n",
      "Epoch 8/55\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0353 - mse: 0.0353 - val_loss: 0.0365 - val_mse: 0.0365\n",
      "Epoch 9/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0278 - mse: 0.0278 - val_loss: 0.0287 - val_mse: 0.0287\n",
      "Epoch 10/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0224 - val_mse: 0.0224\n",
      "Epoch 11/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0175 - val_mse: 0.0175\n",
      "Epoch 12/55\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 13/55\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0105 - mse: 0.0105 - val_loss: 0.0109 - val_mse: 0.0109\n",
      "Epoch 14/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0083 - mse: 0.0083 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 15/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0067 - val_mse: 0.0067\n",
      "Epoch 16/55\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0053 - val_mse: 0.0053\n",
      "Epoch 17/55\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0042 - val_mse: 0.0042\n",
      "Epoch 18/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0032 - mse: 0.0032 - val_loss: 0.0033 - val_mse: 0.0033\n",
      "Epoch 19/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 0.0026 - val_mse: 0.0026\n",
      "Epoch 20/55\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0020 - val_mse: 0.0020\n",
      "Epoch 21/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0016 - val_mse: 0.0016\n",
      "Epoch 22/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 23/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9.2742e-04 - mse: 9.2742e-04 - val_loss: 9.4765e-04 - val_mse: 9.4765e-04\n",
      "Epoch 24/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 7.2325e-04 - mse: 7.2325e-04 - val_loss: 7.4001e-04 - val_mse: 7.4001e-04\n",
      "Epoch 25/55\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 5.6622e-04 - mse: 5.6622e-04 - val_loss: 5.8203e-04 - val_mse: 5.8203e-04\n",
      "Epoch 26/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 4.4506e-04 - mse: 4.4506e-04 - val_loss: 4.6026e-04 - val_mse: 4.6026e-04\n",
      "Epoch 27/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 3.5142e-04 - mse: 3.5142e-04 - val_loss: 3.5875e-04 - val_mse: 3.5875e-04\n",
      "Epoch 28/55\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 2.7403e-04 - mse: 2.7403e-04 - val_loss: 2.8182e-04 - val_mse: 2.8182e-04\n",
      "Epoch 29/55\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 2.1476e-04 - mse: 2.1476e-04 - val_loss: 2.1968e-04 - val_mse: 2.1968e-04\n",
      "Epoch 30/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.6713e-04 - mse: 1.6713e-04 - val_loss: 1.7234e-04 - val_mse: 1.7234e-04\n",
      "Epoch 31/55\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.3105e-04 - mse: 1.3105e-04 - val_loss: 1.3459e-04 - val_mse: 1.3459e-04\n",
      "Epoch 32/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0242e-04 - mse: 1.0242e-04 - val_loss: 1.0554e-04 - val_mse: 1.0554e-04\n",
      "Epoch 33/55\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 8.0299e-05 - mse: 8.0299e-05 - val_loss: 8.2954e-05 - val_mse: 8.2954e-05\n",
      "Epoch 34/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 6.3091e-05 - mse: 6.3091e-05 - val_loss: 6.4470e-05 - val_mse: 6.4470e-05\n",
      "Epoch 35/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 4.9107e-05 - mse: 4.9107e-05 - val_loss: 5.0560e-05 - val_mse: 5.0560e-05\n",
      "Epoch 36/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 3.8548e-05 - mse: 3.8548e-05 - val_loss: 3.9609e-05 - val_mse: 3.9609e-05\n",
      "Epoch 37/55\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 3.0168e-05 - mse: 3.0168e-05 - val_loss: 3.1024e-05 - val_mse: 3.1024e-05\n",
      "Epoch 38/55\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.3605e-05 - mse: 2.3605e-05 - val_loss: 2.4383e-05 - val_mse: 2.4383e-05\n",
      "Epoch 39/55\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.8562e-05 - mse: 1.8562e-05 - val_loss: 1.9030e-05 - val_mse: 1.9030e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/55\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.4439e-05 - mse: 1.4439e-05 - val_loss: 1.4895e-05 - val_mse: 1.4895e-05\n",
      "Epoch 41/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.1307e-05 - mse: 1.1307e-05 - val_loss: 1.1620e-05 - val_mse: 1.1620e-05\n",
      "Epoch 42/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 8.8309e-06 - mse: 8.8309e-06 - val_loss: 9.0704e-06 - val_mse: 9.0704e-06\n",
      "Epoch 43/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 6.9059e-06 - mse: 6.9059e-06 - val_loss: 7.1452e-06 - val_mse: 7.1452e-06\n",
      "Epoch 44/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 5.4389e-06 - mse: 5.4389e-06 - val_loss: 5.6238e-06 - val_mse: 5.6238e-06\n",
      "Epoch 45/55\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 4.2706e-06 - mse: 4.2706e-06 - val_loss: 4.4235e-06 - val_mse: 4.4235e-06\n",
      "Epoch 46/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 3.3571e-06 - mse: 3.3571e-06 - val_loss: 3.4519e-06 - val_mse: 3.4519e-06\n",
      "Epoch 47/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.6230e-06 - mse: 2.6230e-06 - val_loss: 2.6928e-06 - val_mse: 2.6928e-06\n",
      "Epoch 48/55\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 2.0440e-06 - mse: 2.0440e-06 - val_loss: 2.1246e-06 - val_mse: 2.1246e-06\n",
      "Epoch 49/55\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.6127e-06 - mse: 1.6127e-06 - val_loss: 1.6476e-06 - val_mse: 1.6476e-06\n",
      "Epoch 50/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.2542e-06 - mse: 1.2542e-06 - val_loss: 1.2946e-06 - val_mse: 1.2946e-06\n",
      "Epoch 51/55\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9.8401e-07 - mse: 9.8401e-07 - val_loss: 1.0095e-06 - val_mse: 1.0095e-06\n",
      "Epoch 52/55\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 7.6784e-07 - mse: 7.6784e-07 - val_loss: 7.8972e-07 - val_mse: 7.8972e-07\n",
      "Epoch 53/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 6.0068e-07 - mse: 6.0068e-07 - val_loss: 6.1752e-07 - val_mse: 6.1752e-07\n",
      "Epoch 54/55\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 4.6951e-07 - mse: 4.6951e-07 - val_loss: 4.8181e-07 - val_mse: 4.8181e-07\n",
      "Epoch 55/55\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 3.6679e-07 - mse: 3.6679e-07 - val_loss: 3.7951e-07 - val_mse: 3.7951e-07\n",
      "INFO:tensorflow:Assets written to: out/111-model-ntrain=550-sigma=0.0-epochs=55.tf/assets\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 2.8927e-07 - mse: 2.8927e-07 - val_loss: 2.9741e-07 - val_mse: 2.9741e-07\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.2697e-07 - mse: 2.2697e-07 - val_loss: 2.3247e-07 - val_mse: 2.3247e-07\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1.7741e-07 - mse: 1.7741e-07 - val_loss: 1.8205e-07 - val_mse: 1.8205e-07\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 1.3888e-07 - mse: 1.3888e-07 - val_loss: 1.4243e-07 - val_mse: 1.4243e-07\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 1.0835e-07 - mse: 1.0835e-07 - val_loss: 1.1217e-07 - val_mse: 1.1217e-07\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 8.5242e-08 - mse: 8.5242e-08 - val_loss: 8.7586e-08 - val_mse: 8.7586e-08\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 6.6690e-08 - mse: 6.6690e-08 - val_loss: 6.7974e-08 - val_mse: 6.7974e-08\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 5.1790e-08 - mse: 5.1790e-08 - val_loss: 5.3480e-08 - val_mse: 5.3480e-08\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 4.0737e-08 - mse: 4.0737e-08 - val_loss: 4.2039e-08 - val_mse: 4.2039e-08\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 3.2060e-08 - mse: 3.2060e-08 - val_loss: 3.2802e-08 - val_mse: 3.2802e-08\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 2.5004e-08 - mse: 2.5004e-08 - val_loss: 2.5705e-08 - val_mse: 2.5705e-08\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.9616e-08 - mse: 1.9616e-08 - val_loss: 2.0331e-08 - val_mse: 2.0331e-08\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1.5514e-08 - mse: 1.5514e-08 - val_loss: 1.6048e-08 - val_mse: 1.6048e-08\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1.2243e-08 - mse: 1.2243e-08 - val_loss: 1.2618e-08 - val_mse: 1.2618e-08\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 9.6076e-09 - mse: 9.6076e-09 - val_loss: 9.8917e-09 - val_mse: 9.8917e-09\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.5377e-09 - mse: 7.5377e-09 - val_loss: 7.7827e-09 - val_mse: 7.7827e-09\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 5.9193e-09 - mse: 5.9193e-09 - val_loss: 6.1169e-09 - val_mse: 6.1169e-09\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 4.6540e-09 - mse: 4.6540e-09 - val_loss: 4.7983e-09 - val_mse: 4.7983e-09\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 3.6573e-09 - mse: 3.6573e-09 - val_loss: 3.7949e-09 - val_mse: 3.7949e-09\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 2.8878e-09 - mse: 2.8878e-09 - val_loss: 2.9503e-09 - val_mse: 2.9503e-09\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 2.2430e-09 - mse: 2.2430e-09 - val_loss: 2.2928e-09 - val_mse: 2.2928e-09\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.7522e-09 - mse: 1.7522e-09 - val_loss: 1.8001e-09 - val_mse: 1.8001e-09\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.3695e-09 - mse: 1.3695e-09 - val_loss: 1.3963e-09 - val_mse: 1.3963e-09\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.0624e-09 - mse: 1.0624e-09 - val_loss: 1.0870e-09 - val_mse: 1.0870e-09\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 8.2553e-10 - mse: 8.2553e-10 - val_loss: 8.4601e-10 - val_mse: 8.4601e-10\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 6.4487e-10 - mse: 6.4487e-10 - val_loss: 6.6956e-10 - val_mse: 6.6956e-10\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 5.0965e-10 - mse: 5.0965e-10 - val_loss: 5.1886e-10 - val_mse: 5.1886e-10\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 3.9674e-10 - mse: 3.9674e-10 - val_loss: 4.0681e-10 - val_mse: 4.0681e-10\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 3.0972e-10 - mse: 3.0972e-10 - val_loss: 3.1291e-10 - val_mse: 3.1291e-10\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.3851e-10 - mse: 2.3851e-10 - val_loss: 2.5026e-10 - val_mse: 2.5026e-10\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.9151e-10 - mse: 1.9151e-10 - val_loss: 1.9598e-10 - val_mse: 1.9598e-10\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.5100e-10 - mse: 1.5100e-10 - val_loss: 1.5825e-10 - val_mse: 1.5825e-10\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.2141e-10 - mse: 1.2141e-10 - val_loss: 1.2587e-10 - val_mse: 1.2587e-10\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9.5458e-11 - mse: 9.5458e-11 - val_loss: 9.7038e-11 - val_mse: 9.7038e-11\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 7.2471e-11 - mse: 7.2471e-11 - val_loss: 7.2389e-11 - val_mse: 7.2389e-11\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 5.2960e-11 - mse: 5.2960e-11 - val_loss: 5.2010e-11 - val_mse: 5.2010e-11\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 3.7822e-11 - mse: 3.7822e-11 - val_loss: 3.6431e-11 - val_mse: 3.6431e-11\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 2.7321e-11 - mse: 2.7321e-11 - val_loss: 2.8793e-11 - val_mse: 2.8793e-11\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 2.2960e-11 - mse: 2.2960e-11 - val_loss: 2.4031e-11 - val_mse: 2.4031e-11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.0095e-11 - mse: 2.0095e-11 - val_loss: 2.3133e-11 - val_mse: 2.3133e-11\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.9270e-11 - mse: 1.9270e-11 - val_loss: 2.2026e-11 - val_mse: 2.2026e-11\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.7865e-11 - mse: 1.7865e-11 - val_loss: 2.0450e-11 - val_mse: 2.0450e-11\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.7033e-11 - mse: 1.7033e-11 - val_loss: 1.9882e-11 - val_mse: 1.9882e-11\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.6707e-11 - mse: 1.6707e-11 - val_loss: 1.9882e-11 - val_mse: 1.9882e-11\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.6698e-11 - mse: 1.6698e-11 - val_loss: 1.9882e-11 - val_mse: 1.9882e-11\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.6479e-11 - mse: 1.6479e-11 - val_loss: 1.9119e-11 - val_mse: 1.9119e-11\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.6139e-11 - mse: 1.6139e-11 - val_loss: 1.8432e-11 - val_mse: 1.8432e-11\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.5232e-11 - mse: 1.5232e-11 - val_loss: 1.7808e-11 - val_mse: 1.7808e-11\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.5029e-11 - mse: 1.5029e-11 - val_loss: 1.7115e-11 - val_mse: 1.7115e-11\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.4481e-11 - mse: 1.4481e-11 - val_loss: 1.7242e-11 - val_mse: 1.7242e-11\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.4499e-11 - mse: 1.4499e-11 - val_loss: 1.7242e-11 - val_mse: 1.7242e-11\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.4242e-11 - mse: 1.4242e-11 - val_loss: 1.6580e-11 - val_mse: 1.6580e-11\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.3985e-11 - mse: 1.3985e-11 - val_loss: 1.6580e-11 - val_mse: 1.6580e-11\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.4022e-11 - mse: 1.4022e-11 - val_loss: 1.6580e-11 - val_mse: 1.6580e-11\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.3985e-11 - mse: 1.3985e-11 - val_loss: 1.6623e-11 - val_mse: 1.6623e-11\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.3970e-11 - mse: 1.3970e-11 - val_loss: 1.6623e-11 - val_mse: 1.6623e-11\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.3970e-11 - mse: 1.3970e-11 - val_loss: 1.6623e-11 - val_mse: 1.6623e-11\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.3879e-11 - mse: 1.3879e-11 - val_loss: 1.5852e-11 - val_mse: 1.5852e-11\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.3439e-11 - mse: 1.3439e-11 - val_loss: 1.6003e-11 - val_mse: 1.6003e-11\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.3454e-11 - mse: 1.3454e-11 - val_loss: 1.5947e-11 - val_mse: 1.5947e-11\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.3433e-11 - mse: 1.3433e-11 - val_loss: 1.5947e-11 - val_mse: 1.5947e-11\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.3431e-11 - mse: 1.3431e-11 - val_loss: 1.5294e-11 - val_mse: 1.5294e-11\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.2968e-11 - mse: 1.2968e-11 - val_loss: 1.5294e-11 - val_mse: 1.5294e-11\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.2968e-11 - mse: 1.2968e-11 - val_loss: 1.5294e-11 - val_mse: 1.5294e-11\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.2968e-11 - mse: 1.2968e-11 - val_loss: 1.5398e-11 - val_mse: 1.5398e-11\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.2960e-11 - mse: 1.2960e-11 - val_loss: 1.5398e-11 - val_mse: 1.5398e-11\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.2960e-11 - mse: 1.2960e-11 - val_loss: 1.5398e-11 - val_mse: 1.5398e-11\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.2960e-11 - mse: 1.2960e-11 - val_loss: 1.5294e-11 - val_mse: 1.5294e-11\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.2968e-11 - mse: 1.2968e-11 - val_loss: 1.5294e-11 - val_mse: 1.5294e-11\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.2968e-11 - mse: 1.2968e-11 - val_loss: 1.5294e-11 - val_mse: 1.5294e-11\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.2961e-11 - mse: 1.2961e-11 - val_loss: 1.5294e-11 - val_mse: 1.5294e-11\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.2968e-11 - mse: 1.2968e-11 - val_loss: 1.4777e-11 - val_mse: 1.4777e-11\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.2486e-11 - mse: 1.2486e-11 - val_loss: 1.4858e-11 - val_mse: 1.4858e-11\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.2476e-11 - mse: 1.2476e-11 - val_loss: 1.4777e-11 - val_mse: 1.4777e-11\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.2412e-11 - mse: 1.2412e-11 - val_loss: 1.4276e-11 - val_mse: 1.4276e-11\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.2008e-11 - mse: 1.2008e-11 - val_loss: 1.3615e-11 - val_mse: 1.3615e-11\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.1444e-11 - mse: 1.1444e-11 - val_loss: 1.3608e-11 - val_mse: 1.3608e-11\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1.1442e-11 - mse: 1.1442e-11 - val_loss: 1.3608e-11 - val_mse: 1.3608e-11\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1.1442e-11 - mse: 1.1442e-11 - val_loss: 1.3608e-11 - val_mse: 1.3608e-11\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.1442e-11 - mse: 1.1442e-11 - val_loss: 1.3608e-11 - val_mse: 1.3608e-11\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.1442e-11 - mse: 1.1442e-11 - val_loss: 1.3066e-11 - val_mse: 1.3066e-11\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.1005e-11 - mse: 1.1005e-11 - val_loss: 1.2555e-11 - val_mse: 1.2555e-11\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0584e-11 - mse: 1.0584e-11 - val_loss: 1.2555e-11 - val_mse: 1.2555e-11\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.0584e-11 - mse: 1.0584e-11 - val_loss: 1.2555e-11 - val_mse: 1.2555e-11\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0584e-11 - mse: 1.0584e-11 - val_loss: 1.2555e-11 - val_mse: 1.2555e-11\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0584e-11 - mse: 1.0584e-11 - val_loss: 1.2555e-11 - val_mse: 1.2555e-11\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0584e-11 - mse: 1.0584e-11 - val_loss: 1.2555e-11 - val_mse: 1.2555e-11\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0584e-11 - mse: 1.0584e-11 - val_loss: 1.2469e-11 - val_mse: 1.2469e-11\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0596e-11 - mse: 1.0596e-11 - val_loss: 1.2469e-11 - val_mse: 1.2469e-11\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1.0596e-11 - mse: 1.0596e-11 - val_loss: 1.2469e-11 - val_mse: 1.2469e-11\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0602e-11 - mse: 1.0602e-11 - val_loss: 1.2450e-11 - val_mse: 1.2450e-11\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0596e-11 - mse: 1.0596e-11 - val_loss: 1.2450e-11 - val_mse: 1.2450e-11\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0621e-11 - mse: 1.0621e-11 - val_loss: 1.2425e-11 - val_mse: 1.2425e-11\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0629e-11 - mse: 1.0629e-11 - val_loss: 1.2425e-11 - val_mse: 1.2425e-11\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.0629e-11 - mse: 1.0629e-11 - val_loss: 1.2450e-11 - val_mse: 1.2450e-11\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0596e-11 - mse: 1.0596e-11 - val_loss: 1.2469e-11 - val_mse: 1.2469e-11\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0597e-11 - mse: 1.0597e-11 - val_loss: 1.2069e-11 - val_mse: 1.2069e-11\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.0144e-11 - mse: 1.0144e-11 - val_loss: 1.2026e-11 - val_mse: 1.2026e-11\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0120e-11 - mse: 1.0120e-11 - val_loss: 1.2026e-11 - val_mse: 1.2026e-11\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.0120e-11 - mse: 1.0120e-11 - val_loss: 1.2026e-11 - val_mse: 1.2026e-11\n",
      "INFO:tensorflow:Assets written to: out/111-model-ntrain=550-sigma=0.0-epochs=100.tf/assets\n",
      "\n",
      "Epoch 1/10\n",
      "18/18 [==============================] - 1s 20ms/step - loss: 3.9053 - mse: 3.9053 - val_loss: 3.0414 - val_mse: 3.0414\n",
      "Epoch 2/10\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 3.0824 - mse: 3.0824 - val_loss: 2.4048 - val_mse: 2.4048\n",
      "Epoch 3/10\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.5408 - mse: 2.5408 - val_loss: 1.9783 - val_mse: 1.9783\n",
      "Epoch 4/10\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1640 - mse: 2.1640 - val_loss: 1.6841 - val_mse: 1.6841\n",
      "Epoch 5/10\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.8956 - mse: 1.8956 - val_loss: 1.4767 - val_mse: 1.4767\n",
      "Epoch 6/10\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1.6983 - mse: 1.6983 - val_loss: 1.3212 - val_mse: 1.3212\n",
      "Epoch 7/10\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1.5440 - mse: 1.5440 - val_loss: 1.2085 - val_mse: 1.2085\n",
      "Epoch 8/10\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1.4260 - mse: 1.4260 - val_loss: 1.1254 - val_mse: 1.1254\n",
      "Epoch 9/10\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 1.3373 - mse: 1.3373 - val_loss: 1.0657 - val_mse: 1.0657\n",
      "Epoch 10/10\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 1.2676 - mse: 1.2676 - val_loss: 1.0226 - val_mse: 1.0226\n",
      "INFO:tensorflow:Assets written to: out/111-model-ntrain=550-sigma=1.0-epochs=10.tf/assets\n",
      "Epoch 1/55\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 1.2133 - mse: 1.2133 - val_loss: 0.9865 - val_mse: 0.9865\n",
      "Epoch 2/55\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.1676 - mse: 1.1676 - val_loss: 0.9588 - val_mse: 0.9588\n",
      "Epoch 3/55\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.1348 - mse: 1.1348 - val_loss: 0.9395 - val_mse: 0.9395\n",
      "Epoch 4/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.1075 - mse: 1.1075 - val_loss: 0.9269 - val_mse: 0.9269\n",
      "Epoch 5/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0870 - mse: 1.0870 - val_loss: 0.9161 - val_mse: 0.9161\n",
      "Epoch 6/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0716 - mse: 1.0716 - val_loss: 0.9104 - val_mse: 0.9104\n",
      "Epoch 7/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0593 - mse: 1.0593 - val_loss: 0.9094 - val_mse: 0.9094\n",
      "Epoch 8/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0507 - mse: 1.0507 - val_loss: 0.9078 - val_mse: 0.9078\n",
      "Epoch 9/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0430 - mse: 1.0430 - val_loss: 0.9101 - val_mse: 0.9101\n",
      "Epoch 10/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0370 - mse: 1.0370 - val_loss: 0.9139 - val_mse: 0.9139\n",
      "Epoch 11/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0328 - mse: 1.0328 - val_loss: 0.9163 - val_mse: 0.9163\n",
      "Epoch 12/55\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.0285 - mse: 1.0285 - val_loss: 0.9150 - val_mse: 0.9150\n",
      "Epoch 13/55\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.0253 - mse: 1.0253 - val_loss: 0.9160 - val_mse: 0.9160\n",
      "Epoch 14/55\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0235 - mse: 1.0235 - val_loss: 0.9178 - val_mse: 0.9178\n",
      "Epoch 15/55\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0216 - mse: 1.0216 - val_loss: 0.9186 - val_mse: 0.9186\n",
      "Epoch 16/55\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0204 - mse: 1.0204 - val_loss: 0.9228 - val_mse: 0.9228\n",
      "Epoch 17/55\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0197 - mse: 1.0197 - val_loss: 0.9258 - val_mse: 0.9258\n",
      "Epoch 18/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0187 - mse: 1.0187 - val_loss: 0.9247 - val_mse: 0.9247\n",
      "Epoch 19/55\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0179 - mse: 1.0179 - val_loss: 0.9286 - val_mse: 0.9286\n",
      "Epoch 20/55\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0176 - mse: 1.0176 - val_loss: 0.9207 - val_mse: 0.9207\n",
      "Epoch 21/55\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0174 - mse: 1.0174 - val_loss: 0.9236 - val_mse: 0.9236\n",
      "Epoch 22/55\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0170 - mse: 1.0170 - val_loss: 0.9247 - val_mse: 0.9247\n",
      "Epoch 23/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0167 - mse: 1.0167 - val_loss: 0.9227 - val_mse: 0.9227\n",
      "Epoch 24/55\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.0167 - mse: 1.0167 - val_loss: 0.9265 - val_mse: 0.9265\n",
      "Epoch 25/55\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0165 - mse: 1.0165 - val_loss: 0.9308 - val_mse: 0.9308\n",
      "Epoch 26/55\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0162 - mse: 1.0162 - val_loss: 0.9375 - val_mse: 0.9375\n",
      "Epoch 27/55\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0164 - mse: 1.0164 - val_loss: 0.9409 - val_mse: 0.9409\n",
      "Epoch 28/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0157 - mse: 1.0157 - val_loss: 0.9406 - val_mse: 0.9406\n",
      "Epoch 29/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0157 - mse: 1.0157 - val_loss: 0.9374 - val_mse: 0.9374\n",
      "Epoch 30/55\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0158 - mse: 1.0158 - val_loss: 0.9357 - val_mse: 0.9357\n",
      "Epoch 31/55\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0160 - mse: 1.0160 - val_loss: 0.9395 - val_mse: 0.9395\n",
      "Epoch 32/55\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0157 - mse: 1.0157 - val_loss: 0.9425 - val_mse: 0.9425\n",
      "Epoch 33/55\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.0156 - mse: 1.0156 - val_loss: 0.9346 - val_mse: 0.9346\n",
      "Epoch 34/55\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.0152 - mse: 1.0152 - val_loss: 0.9344 - val_mse: 0.9344\n",
      "Epoch 35/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0154 - mse: 1.0154 - val_loss: 0.9390 - val_mse: 0.9390\n",
      "Epoch 36/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0156 - mse: 1.0156 - val_loss: 0.9417 - val_mse: 0.9417\n",
      "Epoch 37/55\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0159 - mse: 1.0159 - val_loss: 0.9407 - val_mse: 0.9407\n",
      "Epoch 38/55\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0154 - mse: 1.0154 - val_loss: 0.9431 - val_mse: 0.9431\n",
      "Epoch 39/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0159 - mse: 1.0159 - val_loss: 0.9422 - val_mse: 0.9422\n",
      "Epoch 40/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0154 - mse: 1.0154 - val_loss: 0.9443 - val_mse: 0.9443\n",
      "Epoch 41/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0158 - mse: 1.0158 - val_loss: 0.9395 - val_mse: 0.9395\n",
      "Epoch 42/55\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.0157 - mse: 1.0157 - val_loss: 0.9379 - val_mse: 0.9379\n",
      "Epoch 43/55\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.0156 - mse: 1.0156 - val_loss: 0.9361 - val_mse: 0.9361\n",
      "Epoch 44/55\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.0154 - mse: 1.0154 - val_loss: 0.9381 - val_mse: 0.9381\n",
      "Epoch 45/55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 8ms/step - loss: 1.0154 - mse: 1.0154 - val_loss: 0.9406 - val_mse: 0.9406\n",
      "Epoch 46/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0157 - mse: 1.0157 - val_loss: 0.9429 - val_mse: 0.9429\n",
      "Epoch 47/55\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.0161 - mse: 1.0161 - val_loss: 0.9426 - val_mse: 0.9426\n",
      "Epoch 48/55\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0155 - mse: 1.0155 - val_loss: 0.9377 - val_mse: 0.9377\n",
      "Epoch 49/55\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0155 - mse: 1.0155 - val_loss: 0.9328 - val_mse: 0.9328\n",
      "Epoch 50/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0154 - mse: 1.0154 - val_loss: 0.9346 - val_mse: 0.9346\n",
      "Epoch 51/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0159 - mse: 1.0159 - val_loss: 0.9344 - val_mse: 0.9344\n",
      "Epoch 52/55\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0153 - mse: 1.0153 - val_loss: 0.9405 - val_mse: 0.9405\n",
      "Epoch 53/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0152 - mse: 1.0152 - val_loss: 0.9386 - val_mse: 0.9386\n",
      "Epoch 54/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0155 - mse: 1.0155 - val_loss: 0.9410 - val_mse: 0.9410\n",
      "Epoch 55/55\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.0156 - mse: 1.0156 - val_loss: 0.9374 - val_mse: 0.9374\n",
      "INFO:tensorflow:Assets written to: out/111-model-ntrain=550-sigma=1.0-epochs=55.tf/assets\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 1.0153 - mse: 1.0153 - val_loss: 0.9410 - val_mse: 0.9410\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0152 - mse: 1.0152 - val_loss: 0.9363 - val_mse: 0.9363\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0153 - mse: 1.0153 - val_loss: 0.9380 - val_mse: 0.9380\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0157 - mse: 1.0157 - val_loss: 0.9400 - val_mse: 0.9400\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0155 - mse: 1.0155 - val_loss: 0.9372 - val_mse: 0.9372\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0157 - mse: 1.0157 - val_loss: 0.9355 - val_mse: 0.9355\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0153 - mse: 1.0153 - val_loss: 0.9357 - val_mse: 0.9357\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.0156 - mse: 1.0156 - val_loss: 0.9360 - val_mse: 0.9360\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0155 - mse: 1.0155 - val_loss: 0.9388 - val_mse: 0.9388\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0153 - mse: 1.0153 - val_loss: 0.9415 - val_mse: 0.9415\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0153 - mse: 1.0153 - val_loss: 0.9437 - val_mse: 0.9437\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0155 - mse: 1.0155 - val_loss: 0.9417 - val_mse: 0.9417\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0154 - mse: 1.0154 - val_loss: 0.9410 - val_mse: 0.9410\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0159 - mse: 1.0159 - val_loss: 0.9415 - val_mse: 0.9415\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0157 - mse: 1.0157 - val_loss: 0.9395 - val_mse: 0.9395\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0154 - mse: 1.0154 - val_loss: 0.9425 - val_mse: 0.9425\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0158 - mse: 1.0158 - val_loss: 0.9437 - val_mse: 0.9437\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0157 - mse: 1.0157 - val_loss: 0.9410 - val_mse: 0.9410\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0156 - mse: 1.0156 - val_loss: 0.9435 - val_mse: 0.9435\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.0157 - mse: 1.0157 - val_loss: 0.9332 - val_mse: 0.9332\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0155 - mse: 1.0155 - val_loss: 0.9345 - val_mse: 0.9345\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0154 - mse: 1.0154 - val_loss: 0.9347 - val_mse: 0.9347\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0154 - mse: 1.0154 - val_loss: 0.9314 - val_mse: 0.9314\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0155 - mse: 1.0155 - val_loss: 0.9344 - val_mse: 0.9344\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0158 - mse: 1.0158 - val_loss: 0.9380 - val_mse: 0.9380\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0157 - mse: 1.0157 - val_loss: 0.9441 - val_mse: 0.9441\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0160 - mse: 1.0160 - val_loss: 0.9470 - val_mse: 0.9470\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0155 - mse: 1.0155 - val_loss: 0.9461 - val_mse: 0.9461\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0156 - mse: 1.0156 - val_loss: 0.9423 - val_mse: 0.9423\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0157 - mse: 1.0157 - val_loss: 0.9401 - val_mse: 0.9401\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.0159 - mse: 1.0159 - val_loss: 0.9435 - val_mse: 0.9435\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0157 - mse: 1.0157 - val_loss: 0.9460 - val_mse: 0.9460\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0156 - mse: 1.0156 - val_loss: 0.9377 - val_mse: 0.9377\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0152 - mse: 1.0152 - val_loss: 0.9371 - val_mse: 0.9371\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0154 - mse: 1.0154 - val_loss: 0.9414 - val_mse: 0.9414\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0156 - mse: 1.0156 - val_loss: 0.9439 - val_mse: 0.9439\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0159 - mse: 1.0159 - val_loss: 0.9426 - val_mse: 0.9426\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0154 - mse: 1.0154 - val_loss: 0.9448 - val_mse: 0.9448\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0160 - mse: 1.0160 - val_loss: 0.9437 - val_mse: 0.9437\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0154 - mse: 1.0154 - val_loss: 0.9456 - val_mse: 0.9456\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.0157 - mse: 1.0157 - val_loss: 0.9406 - val_mse: 0.9406\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.0157 - mse: 1.0157 - val_loss: 0.9389 - val_mse: 0.9389\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0155 - mse: 1.0155 - val_loss: 0.9370 - val_mse: 0.9370\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0153 - mse: 1.0153 - val_loss: 0.9389 - val_mse: 0.9389\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0154 - mse: 1.0154 - val_loss: 0.9413 - val_mse: 0.9413\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0156 - mse: 1.0156 - val_loss: 0.9435 - val_mse: 0.9435\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.0161 - mse: 1.0161 - val_loss: 0.9431 - val_mse: 0.9431\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1.0155 - mse: 1.0155 - val_loss: 0.9382 - val_mse: 0.9382\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0155 - mse: 1.0155 - val_loss: 0.9333 - val_mse: 0.9333\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0154 - mse: 1.0154 - val_loss: 0.9350 - val_mse: 0.9350\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.0159 - mse: 1.0159 - val_loss: 0.9347 - val_mse: 0.9347\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0153 - mse: 1.0153 - val_loss: 0.9408 - val_mse: 0.9408\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0152 - mse: 1.0152 - val_loss: 0.9389 - val_mse: 0.9389\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.0155 - mse: 1.0155 - val_loss: 0.9412 - val_mse: 0.9412\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0156 - mse: 1.0156 - val_loss: 0.9376 - val_mse: 0.9376\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0153 - mse: 1.0153 - val_loss: 0.9419 - val_mse: 0.9419\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0153 - mse: 1.0153 - val_loss: 0.9426 - val_mse: 0.9426\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0158 - mse: 1.0158 - val_loss: 0.9349 - val_mse: 0.9349\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.0155 - mse: 1.0155 - val_loss: 0.9414 - val_mse: 0.9414\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0156 - mse: 1.0156 - val_loss: 0.9370 - val_mse: 0.9370\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.0152 - mse: 1.0152 - val_loss: 0.9387 - val_mse: 0.9387\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0156 - mse: 1.0156 - val_loss: 0.9387 - val_mse: 0.9387\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0156 - mse: 1.0156 - val_loss: 0.9411 - val_mse: 0.9411\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0155 - mse: 1.0155 - val_loss: 0.9385 - val_mse: 0.9385\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1.0158 - mse: 1.0158 - val_loss: 0.9390 - val_mse: 0.9390\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1.0154 - mse: 1.0154 - val_loss: 0.9358 - val_mse: 0.9358\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 1.0152 - mse: 1.0152 - val_loss: 0.9320 - val_mse: 0.9320\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.0153 - mse: 1.0153 - val_loss: 0.9308 - val_mse: 0.9308\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0158 - mse: 1.0158 - val_loss: 0.9362 - val_mse: 0.9362\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0152 - mse: 1.0152 - val_loss: 0.9389 - val_mse: 0.9389\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.0155 - mse: 1.0155 - val_loss: 0.9368 - val_mse: 0.9368\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 1.0157 - mse: 1.0157 - val_loss: 0.9381 - val_mse: 0.9381\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 1.0153 - mse: 1.0153 - val_loss: 0.9363 - val_mse: 0.9363\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0151 - mse: 1.0151 - val_loss: 0.9305 - val_mse: 0.9305\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0156 - mse: 1.0156 - val_loss: 0.9338 - val_mse: 0.9338\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.0157 - mse: 1.0157 - val_loss: 0.9394 - val_mse: 0.9394\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0154 - mse: 1.0154 - val_loss: 0.9390 - val_mse: 0.9390\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0156 - mse: 1.0156 - val_loss: 0.9429 - val_mse: 0.9429\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0161 - mse: 1.0161 - val_loss: 0.9439 - val_mse: 0.9439\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0157 - mse: 1.0157 - val_loss: 0.9418 - val_mse: 0.9418\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0160 - mse: 1.0160 - val_loss: 0.9446 - val_mse: 0.9446\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 1.0156 - mse: 1.0156 - val_loss: 0.9404 - val_mse: 0.9404\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 1.0154 - mse: 1.0154 - val_loss: 0.9436 - val_mse: 0.9436\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0156 - mse: 1.0156 - val_loss: 0.9427 - val_mse: 0.9427\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0154 - mse: 1.0154 - val_loss: 0.9458 - val_mse: 0.9458\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0159 - mse: 1.0159 - val_loss: 0.9485 - val_mse: 0.9485\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0163 - mse: 1.0163 - val_loss: 0.9457 - val_mse: 0.9457\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.0157 - mse: 1.0157 - val_loss: 0.9379 - val_mse: 0.9379\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0154 - mse: 1.0154 - val_loss: 0.9388 - val_mse: 0.9388\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0155 - mse: 1.0155 - val_loss: 0.9365 - val_mse: 0.9365\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0157 - mse: 1.0157 - val_loss: 0.9285 - val_mse: 0.9285\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0154 - mse: 1.0154 - val_loss: 0.9309 - val_mse: 0.9309\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0154 - mse: 1.0154 - val_loss: 0.9327 - val_mse: 0.9327\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.0157 - mse: 1.0157 - val_loss: 0.9344 - val_mse: 0.9344\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0154 - mse: 1.0154 - val_loss: 0.9302 - val_mse: 0.9302\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0152 - mse: 1.0152 - val_loss: 0.9319 - val_mse: 0.9319\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0157 - mse: 1.0157 - val_loss: 0.9308 - val_mse: 0.9308\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0154 - mse: 1.0154 - val_loss: 0.9288 - val_mse: 0.9288\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0158 - mse: 1.0158 - val_loss: 0.9334 - val_mse: 0.9334\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0154 - mse: 1.0154 - val_loss: 0.9336 - val_mse: 0.9336\n",
      "INFO:tensorflow:Assets written to: out/111-model-ntrain=550-sigma=1.0-epochs=100.tf/assets\n",
      "\n",
      "Epoch 1/10\n",
      "18/18 [==============================] - 1s 19ms/step - loss: 104.0397 - mse: 104.0397 - val_loss: 89.6236 - val_mse: 89.6236\n",
      "Epoch 2/10\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 103.3043 - mse: 103.3043 - val_loss: 89.8114 - val_mse: 89.8114\n",
      "Epoch 3/10\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 102.9375 - mse: 102.9375 - val_loss: 90.3108 - val_mse: 90.3108\n",
      "Epoch 4/10\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 102.5899 - mse: 102.5899 - val_loss: 90.8218 - val_mse: 90.8218\n",
      "Epoch 5/10\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 102.3339 - mse: 102.3339 - val_loss: 90.8989 - val_mse: 90.8989\n",
      "Epoch 6/10\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 102.1730 - mse: 102.1730 - val_loss: 91.0764 - val_mse: 91.0764\n",
      "Epoch 7/10\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 102.0110 - mse: 102.0110 - val_loss: 91.4355 - val_mse: 91.4355\n",
      "Epoch 8/10\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 101.9588 - mse: 101.9588 - val_loss: 91.6749 - val_mse: 91.6749\n",
      "Epoch 9/10\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 101.8570 - mse: 101.8570 - val_loss: 92.1523 - val_mse: 92.1523\n",
      "Epoch 10/10\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 101.7770 - mse: 101.7770 - val_loss: 92.6252 - val_mse: 92.6252\n",
      "INFO:tensorflow:Assets written to: out/111-model-ntrain=550-sigma=10.0-epochs=10.tf/assets\n",
      "Epoch 1/55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 11ms/step - loss: 101.7468 - mse: 101.7468 - val_loss: 92.9645 - val_mse: 92.9645\n",
      "Epoch 2/55\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 101.6605 - mse: 101.6605 - val_loss: 92.5601 - val_mse: 92.5601\n",
      "Epoch 3/55\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 101.6318 - mse: 101.6318 - val_loss: 92.7656 - val_mse: 92.7656\n",
      "Epoch 4/55\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 101.6312 - mse: 101.6312 - val_loss: 93.0239 - val_mse: 93.0239\n",
      "Epoch 5/55\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 101.6003 - mse: 101.6003 - val_loss: 92.8244 - val_mse: 92.8244\n",
      "Epoch 6/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 101.5999 - mse: 101.5999 - val_loss: 92.7451 - val_mse: 92.7451\n",
      "Epoch 7/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 101.5587 - mse: 101.5587 - val_loss: 92.8746 - val_mse: 92.8746\n",
      "Epoch 8/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 101.5903 - mse: 101.5903 - val_loss: 92.9672 - val_mse: 92.9672\n",
      "Epoch 9/55\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 101.5704 - mse: 101.5704 - val_loss: 93.3120 - val_mse: 93.3120\n",
      "Epoch 10/55\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 101.5543 - mse: 101.5543 - val_loss: 93.6466 - val_mse: 93.6466\n",
      "Epoch 11/55\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 101.5528 - mse: 101.5528 - val_loss: 93.9130 - val_mse: 93.9130\n",
      "Epoch 12/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 101.5585 - mse: 101.5585 - val_loss: 93.7553 - val_mse: 93.7553\n",
      "Epoch 13/55\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 101.5439 - mse: 101.5439 - val_loss: 93.7310 - val_mse: 93.7310\n",
      "Epoch 14/55\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 101.5876 - mse: 101.5876 - val_loss: 93.8166 - val_mse: 93.8166\n",
      "Epoch 15/55\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 101.5696 - mse: 101.5696 - val_loss: 93.6630 - val_mse: 93.6630\n",
      "Epoch 16/55\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 101.5434 - mse: 101.5434 - val_loss: 93.9872 - val_mse: 93.9872\n",
      "Epoch 17/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 101.5835 - mse: 101.5835 - val_loss: 94.1408 - val_mse: 94.1408\n",
      "Epoch 18/55\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 101.5701 - mse: 101.5701 - val_loss: 93.8940 - val_mse: 93.8940\n",
      "Epoch 19/55\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 101.5578 - mse: 101.5578 - val_loss: 94.1618 - val_mse: 94.1618\n",
      "Epoch 20/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 101.5725 - mse: 101.5725 - val_loss: 93.1655 - val_mse: 93.1655\n",
      "Epoch 21/55\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 101.5591 - mse: 101.5591 - val_loss: 93.3170 - val_mse: 93.3170\n",
      "Epoch 22/55\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 101.5417 - mse: 101.5417 - val_loss: 93.3508 - val_mse: 93.3508\n",
      "Epoch 23/55\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 101.5431 - mse: 101.5431 - val_loss: 93.0347 - val_mse: 93.0347\n",
      "Epoch 24/55\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 101.5579 - mse: 101.5579 - val_loss: 93.3478 - val_mse: 93.3478\n",
      "Epoch 25/55\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 101.5816 - mse: 101.5816 - val_loss: 93.7193 - val_mse: 93.7193\n",
      "Epoch 26/55\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 101.5717 - mse: 101.5717 - val_loss: 94.3305 - val_mse: 94.3305\n",
      "Epoch 27/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 101.6007 - mse: 101.6007 - val_loss: 94.6293 - val_mse: 94.6293\n",
      "Epoch 28/55\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 101.5463 - mse: 101.5463 - val_loss: 94.5498 - val_mse: 94.5498\n",
      "Epoch 29/55\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 101.5608 - mse: 101.5608 - val_loss: 94.1775 - val_mse: 94.1775\n",
      "Epoch 30/55\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 101.5681 - mse: 101.5681 - val_loss: 93.9607 - val_mse: 93.9607\n",
      "Epoch 31/55\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 101.5860 - mse: 101.5860 - val_loss: 94.3014 - val_mse: 94.3014\n",
      "Epoch 32/55\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 101.5704 - mse: 101.5704 - val_loss: 94.5624 - val_mse: 94.5624\n",
      "Epoch 33/55\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 101.5583 - mse: 101.5583 - val_loss: 93.7362 - val_mse: 93.7362\n",
      "Epoch 34/55\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 101.5179 - mse: 101.5179 - val_loss: 93.6817 - val_mse: 93.6817\n",
      "Epoch 35/55\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 101.5441 - mse: 101.5441 - val_loss: 94.1157 - val_mse: 94.1157\n",
      "Epoch 36/55\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 101.5615 - mse: 101.5615 - val_loss: 94.3639 - val_mse: 94.3639\n",
      "Epoch 37/55\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 101.5881 - mse: 101.5881 - val_loss: 94.2434 - val_mse: 94.2434\n",
      "Epoch 38/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 101.5426 - mse: 101.5426 - val_loss: 94.4602 - val_mse: 94.4602\n",
      "Epoch 39/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 101.5951 - mse: 101.5951 - val_loss: 94.3539 - val_mse: 94.3539\n",
      "Epoch 40/55\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 101.5372 - mse: 101.5372 - val_loss: 94.5425 - val_mse: 94.5425\n",
      "Epoch 41/55\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 101.5747 - mse: 101.5747 - val_loss: 94.0515 - val_mse: 94.0515\n",
      "Epoch 42/55\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 101.5682 - mse: 101.5682 - val_loss: 93.8777 - val_mse: 93.8777\n",
      "Epoch 43/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 101.5541 - mse: 101.5541 - val_loss: 93.6898 - val_mse: 93.6898\n",
      "Epoch 44/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 101.5330 - mse: 101.5330 - val_loss: 93.8858 - val_mse: 93.8858\n",
      "Epoch 45/55\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 101.5365 - mse: 101.5365 - val_loss: 94.1241 - val_mse: 94.1241\n",
      "Epoch 46/55\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 101.5637 - mse: 101.5637 - val_loss: 94.3468 - val_mse: 94.3468\n",
      "Epoch 47/55\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 101.6071 - mse: 101.6071 - val_loss: 94.3072 - val_mse: 94.3072\n",
      "Epoch 48/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 101.5493 - mse: 101.5493 - val_loss: 93.8118 - val_mse: 93.8118\n",
      "Epoch 49/55\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 101.5462 - mse: 101.5462 - val_loss: 93.3206 - val_mse: 93.3206\n",
      "Epoch 50/55\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 101.5394 - mse: 101.5394 - val_loss: 93.4950 - val_mse: 93.4950\n",
      "Epoch 51/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 101.5856 - mse: 101.5856 - val_loss: 93.4678 - val_mse: 93.4678\n",
      "Epoch 52/55\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 101.5315 - mse: 101.5315 - val_loss: 94.0785 - val_mse: 94.0785\n",
      "Epoch 53/55\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 101.5222 - mse: 101.5222 - val_loss: 93.8853 - val_mse: 93.8853\n",
      "Epoch 54/55\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 101.5509 - mse: 101.5509 - val_loss: 94.1186 - val_mse: 94.1186\n",
      "Epoch 55/55\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 101.5603 - mse: 101.5603 - val_loss: 93.7595 - val_mse: 93.7595\n",
      "INFO:tensorflow:Assets written to: out/111-model-ntrain=550-sigma=10.0-epochs=55.tf/assets\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 101.5303 - mse: 101.5303 - val_loss: 94.1213 - val_mse: 94.1213\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 101.5195 - mse: 101.5195 - val_loss: 93.6456 - val_mse: 93.6456\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 101.5266 - mse: 101.5266 - val_loss: 93.8119 - val_mse: 93.8119\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 101.5663 - mse: 101.5663 - val_loss: 94.0094 - val_mse: 94.0094\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 101.5507 - mse: 101.5507 - val_loss: 93.7316 - val_mse: 93.7316\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 101.5659 - mse: 101.5659 - val_loss: 93.5545 - val_mse: 93.5545\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 101.5307 - mse: 101.5307 - val_loss: 93.5818 - val_mse: 93.5818\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 101.5573 - mse: 101.5573 - val_loss: 93.6096 - val_mse: 93.6096\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 101.5457 - mse: 101.5457 - val_loss: 93.8898 - val_mse: 93.8898\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 101.5346 - mse: 101.5346 - val_loss: 94.1552 - val_mse: 94.1552\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 101.5302 - mse: 101.5302 - val_loss: 94.3761 - val_mse: 94.3761\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 101.5491 - mse: 101.5491 - val_loss: 94.1766 - val_mse: 94.1766\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 101.5400 - mse: 101.5400 - val_loss: 94.1070 - val_mse: 94.1070\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 101.5863 - mse: 101.5863 - val_loss: 94.1574 - val_mse: 94.1574\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 101.5700 - mse: 101.5700 - val_loss: 93.9557 - val_mse: 93.9557\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 101.5398 - mse: 101.5398 - val_loss: 94.2523 - val_mse: 94.2523\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 101.5812 - mse: 101.5812 - val_loss: 94.3761 - val_mse: 94.3761\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 101.5685 - mse: 101.5685 - val_loss: 94.1036 - val_mse: 94.1036\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 101.5566 - mse: 101.5566 - val_loss: 94.3490 - val_mse: 94.3490\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 101.5717 - mse: 101.5717 - val_loss: 93.3218 - val_mse: 93.3218\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 101.5543 - mse: 101.5543 - val_loss: 93.4512 - val_mse: 93.4512\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 101.5353 - mse: 101.5353 - val_loss: 93.4723 - val_mse: 93.4723\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 101.5384 - mse: 101.5384 - val_loss: 93.1390 - val_mse: 93.1390\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 101.5526 - mse: 101.5526 - val_loss: 93.4409 - val_mse: 93.4409\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 101.5791 - mse: 101.5791 - val_loss: 93.8042 - val_mse: 93.8042\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 101.5705 - mse: 101.5705 - val_loss: 94.4072 - val_mse: 94.4072\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 101.5995 - mse: 101.5995 - val_loss: 94.6991 - val_mse: 94.6991\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 101.5470 - mse: 101.5470 - val_loss: 94.6129 - val_mse: 94.6129\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 101.5617 - mse: 101.5617 - val_loss: 94.2336 - val_mse: 94.2336\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 101.5687 - mse: 101.5687 - val_loss: 94.0098 - val_mse: 94.0098\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 101.5860 - mse: 101.5860 - val_loss: 94.3460 - val_mse: 94.3460\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 101.5713 - mse: 101.5713 - val_loss: 94.6018 - val_mse: 94.6018\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 101.5591 - mse: 101.5591 - val_loss: 93.7709 - val_mse: 93.7709\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 101.5186 - mse: 101.5186 - val_loss: 93.7120 - val_mse: 93.7120\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 101.5448 - mse: 101.5448 - val_loss: 94.1426 - val_mse: 94.1426\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 101.5622 - mse: 101.5622 - val_loss: 94.3879 - val_mse: 94.3879\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 101.5886 - mse: 101.5886 - val_loss: 94.2645 - val_mse: 94.2645\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 101.5429 - mse: 101.5429 - val_loss: 94.4789 - val_mse: 94.4789\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 101.5953 - mse: 101.5953 - val_loss: 94.3708 - val_mse: 94.3708\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 101.5374 - mse: 101.5374 - val_loss: 94.5569 - val_mse: 94.5569\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 101.5746 - mse: 101.5746 - val_loss: 94.0640 - val_mse: 94.0640\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 101.5679 - mse: 101.5679 - val_loss: 93.8885 - val_mse: 93.8885\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 101.5538 - mse: 101.5538 - val_loss: 93.6994 - val_mse: 93.6994\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 101.5328 - mse: 101.5328 - val_loss: 93.8946 - val_mse: 93.8946\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 101.5364 - mse: 101.5364 - val_loss: 94.1319 - val_mse: 94.1319\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 101.5635 - mse: 101.5635 - val_loss: 94.3536 - val_mse: 94.3536\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 101.6069 - mse: 101.6069 - val_loss: 94.3134 - val_mse: 94.3134\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 101.5493 - mse: 101.5493 - val_loss: 93.8173 - val_mse: 93.8173\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 101.5463 - mse: 101.5463 - val_loss: 93.3253 - val_mse: 93.3253\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 101.5394 - mse: 101.5394 - val_loss: 93.4993 - val_mse: 93.4993\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 101.5856 - mse: 101.5856 - val_loss: 93.4715 - val_mse: 93.4715\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 101.5315 - mse: 101.5315 - val_loss: 94.0819 - val_mse: 94.0819\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 101.5222 - mse: 101.5222 - val_loss: 93.8883 - val_mse: 93.8883\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 101.5509 - mse: 101.5509 - val_loss: 94.1212 - val_mse: 94.1212\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 101.5603 - mse: 101.5603 - val_loss: 93.7618 - val_mse: 93.7618\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 101.5312 - mse: 101.5312 - val_loss: 94.1943 - val_mse: 94.1943\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 101.5329 - mse: 101.5329 - val_loss: 94.2606 - val_mse: 94.2606\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 101.5849 - mse: 101.5849 - val_loss: 93.4949 - val_mse: 93.4949\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 101.5519 - mse: 101.5519 - val_loss: 94.1367 - val_mse: 94.1367\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 101.5605 - mse: 101.5605 - val_loss: 93.7016 - val_mse: 93.7016\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 101.5239 - mse: 101.5239 - val_loss: 93.8677 - val_mse: 93.8677\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 101.5585 - mse: 101.5585 - val_loss: 93.8677 - val_mse: 93.8677\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 101.5577 - mse: 101.5577 - val_loss: 94.1108 - val_mse: 94.1108\n",
      "Epoch 64/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 7ms/step - loss: 101.5522 - mse: 101.5522 - val_loss: 93.8526 - val_mse: 93.8526\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 101.5789 - mse: 101.5789 - val_loss: 93.9046 - val_mse: 93.9046\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 101.5387 - mse: 101.5387 - val_loss: 93.5832 - val_mse: 93.5832\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 101.5227 - mse: 101.5227 - val_loss: 93.2022 - val_mse: 93.2022\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 101.5288 - mse: 101.5288 - val_loss: 93.0772 - val_mse: 93.0772\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 101.5798 - mse: 101.5798 - val_loss: 93.6201 - val_mse: 93.6201\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 101.5222 - mse: 101.5222 - val_loss: 93.8883 - val_mse: 93.8883\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 101.5500 - mse: 101.5500 - val_loss: 93.6756 - val_mse: 93.6756\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 101.5672 - mse: 101.5672 - val_loss: 93.8095 - val_mse: 93.8095\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 101.5268 - mse: 101.5268 - val_loss: 93.6326 - val_mse: 93.6326\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 101.5100 - mse: 101.5100 - val_loss: 93.0486 - val_mse: 93.0486\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 101.5648 - mse: 101.5648 - val_loss: 93.3789 - val_mse: 93.3789\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 101.5748 - mse: 101.5748 - val_loss: 93.9392 - val_mse: 93.9392\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 101.5429 - mse: 101.5429 - val_loss: 93.8981 - val_mse: 93.8981\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 101.5643 - mse: 101.5643 - val_loss: 94.2854 - val_mse: 94.2854\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 101.6063 - mse: 101.6063 - val_loss: 94.3866 - val_mse: 94.3866\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 101.5682 - mse: 101.5682 - val_loss: 94.1825 - val_mse: 94.1825\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 101.5954 - mse: 101.5954 - val_loss: 94.4630 - val_mse: 94.4630\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 101.5626 - mse: 101.5626 - val_loss: 94.0412 - val_mse: 94.0412\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 101.5401 - mse: 101.5401 - val_loss: 94.3591 - val_mse: 94.3591\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 101.5646 - mse: 101.5646 - val_loss: 94.2699 - val_mse: 94.2699\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 101.5439 - mse: 101.5439 - val_loss: 94.5834 - val_mse: 94.5834\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 101.5910 - mse: 101.5910 - val_loss: 94.8505 - val_mse: 94.8505\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 101.6280 - mse: 101.6280 - val_loss: 94.5653 - val_mse: 94.5653\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 101.5744 - mse: 101.5744 - val_loss: 93.7949 - val_mse: 93.7949\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 101.5408 - mse: 101.5408 - val_loss: 93.8847 - val_mse: 93.8847\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 101.5546 - mse: 101.5546 - val_loss: 93.6518 - val_mse: 93.6518\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 101.5711 - mse: 101.5711 - val_loss: 92.8472 - val_mse: 92.8472\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 101.5368 - mse: 101.5368 - val_loss: 93.0874 - val_mse: 93.0874\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 101.5421 - mse: 101.5421 - val_loss: 93.2724 - val_mse: 93.2724\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 101.5655 - mse: 101.5655 - val_loss: 93.4362 - val_mse: 93.4362\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 101.5417 - mse: 101.5417 - val_loss: 93.0219 - val_mse: 93.0219\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 101.5176 - mse: 101.5176 - val_loss: 93.1925 - val_mse: 93.1925\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 101.5672 - mse: 101.5672 - val_loss: 93.0819 - val_mse: 93.0819\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 101.5356 - mse: 101.5356 - val_loss: 92.8790 - val_mse: 92.8790\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 101.5758 - mse: 101.5758 - val_loss: 93.3376 - val_mse: 93.3376\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 101.5444 - mse: 101.5444 - val_loss: 93.3558 - val_mse: 93.3558\n",
      "INFO:tensorflow:Assets written to: out/111-model-ntrain=550-sigma=10.0-epochs=100.tf/assets\n",
      "\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 2.6126 - mse: 2.6126 - val_loss: 2.0575 - val_mse: 2.0575\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.4898 - mse: 1.4898 - val_loss: 1.2609 - val_mse: 1.2609\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9154 - mse: 0.9154 - val_loss: 0.8010 - val_mse: 0.8010\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5806 - mse: 0.5806 - val_loss: 0.5134 - val_mse: 0.5134\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.3710 - mse: 0.3710 - val_loss: 0.3338 - val_mse: 0.3338\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.2407 - mse: 0.2407 - val_loss: 0.2166 - val_mse: 0.2166\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1558 - mse: 0.1558 - val_loss: 0.1396 - val_mse: 0.1396\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1003 - mse: 0.1003 - val_loss: 0.0909 - val_mse: 0.0909\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0652 - mse: 0.0652 - val_loss: 0.0590 - val_mse: 0.0590\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0423 - mse: 0.0423 - val_loss: 0.0381 - val_mse: 0.0381\n",
      "INFO:tensorflow:Assets written to: out/111-model-ntrain=1000-sigma=0.0-epochs=10.tf/assets\n",
      "Epoch 1/55\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0273 - mse: 0.0273 - val_loss: 0.0247 - val_mse: 0.0247\n",
      "Epoch 2/55\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 3/55\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0116 - mse: 0.0116 - val_loss: 0.0105 - val_mse: 0.0105\n",
      "Epoch 4/55\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0075 - mse: 0.0075 - val_loss: 0.0068 - val_mse: 0.0068\n",
      "Epoch 5/55\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0044 - val_mse: 0.0044\n",
      "Epoch 6/55\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0032 - mse: 0.0032 - val_loss: 0.0029 - val_mse: 0.0029\n",
      "Epoch 7/55\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 0.0018 - val_mse: 0.0018\n",
      "Epoch 8/55\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 9/55\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 8.6074e-04 - mse: 8.6074e-04 - val_loss: 7.7971e-04 - val_mse: 7.7971e-04\n",
      "Epoch 10/55\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.5808e-04 - mse: 5.5808e-04 - val_loss: 5.0339e-04 - val_mse: 5.0339e-04\n",
      "Epoch 11/55\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 3.6078e-04 - mse: 3.6078e-04 - val_loss: 3.2477e-04 - val_mse: 3.2477e-04\n",
      "Epoch 12/55\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 2.3287e-04 - mse: 2.3287e-04 - val_loss: 2.1158e-04 - val_mse: 2.1158e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/55\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.5160e-04 - mse: 1.5160e-04 - val_loss: 1.3648e-04 - val_mse: 1.3648e-04\n",
      "Epoch 14/55\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 9.7848e-05 - mse: 9.7848e-05 - val_loss: 8.8439e-05 - val_mse: 8.8439e-05\n",
      "Epoch 15/55\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.3420e-05 - mse: 6.3420e-05 - val_loss: 5.7259e-05 - val_mse: 5.7259e-05\n",
      "Epoch 16/55\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.1052e-05 - mse: 4.1052e-05 - val_loss: 3.7076e-05 - val_mse: 3.7076e-05\n",
      "Epoch 17/55\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 2.6579e-05 - mse: 2.6579e-05 - val_loss: 2.4100e-05 - val_mse: 2.4100e-05\n",
      "Epoch 18/55\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.7263e-05 - mse: 1.7263e-05 - val_loss: 1.5618e-05 - val_mse: 1.5618e-05\n",
      "Epoch 19/55\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.1182e-05 - mse: 1.1182e-05 - val_loss: 1.0133e-05 - val_mse: 1.0133e-05\n",
      "Epoch 20/55\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.2619e-06 - mse: 7.2619e-06 - val_loss: 6.5851e-06 - val_mse: 6.5851e-06\n",
      "Epoch 21/55\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.7135e-06 - mse: 4.7135e-06 - val_loss: 4.2654e-06 - val_mse: 4.2654e-06\n",
      "Epoch 22/55\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 3.0555e-06 - mse: 3.0555e-06 - val_loss: 2.7620e-06 - val_mse: 2.7620e-06\n",
      "Epoch 23/55\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.9811e-06 - mse: 1.9811e-06 - val_loss: 1.7826e-06 - val_mse: 1.7826e-06\n",
      "Epoch 24/55\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.2779e-06 - mse: 1.2779e-06 - val_loss: 1.1567e-06 - val_mse: 1.1567e-06\n",
      "Epoch 25/55\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.2894e-07 - mse: 8.2894e-07 - val_loss: 7.4996e-07 - val_mse: 7.4996e-07\n",
      "Epoch 26/55\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.3777e-07 - mse: 5.3777e-07 - val_loss: 4.8492e-07 - val_mse: 4.8492e-07\n",
      "Epoch 27/55\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 3.4775e-07 - mse: 3.4775e-07 - val_loss: 3.1595e-07 - val_mse: 3.1595e-07\n",
      "Epoch 28/55\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 2.2658e-07 - mse: 2.2658e-07 - val_loss: 2.0517e-07 - val_mse: 2.0517e-07\n",
      "Epoch 29/55\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.4701e-07 - mse: 1.4701e-07 - val_loss: 1.3247e-07 - val_mse: 1.3247e-07\n",
      "Epoch 30/55\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 9.4958e-08 - mse: 9.4958e-08 - val_loss: 8.5754e-08 - val_mse: 8.5754e-08\n",
      "Epoch 31/55\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 6.1469e-08 - mse: 6.1469e-08 - val_loss: 5.5331e-08 - val_mse: 5.5331e-08\n",
      "Epoch 32/55\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.9739e-08 - mse: 3.9739e-08 - val_loss: 3.5989e-08 - val_mse: 3.5989e-08\n",
      "Epoch 33/55\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 2.5817e-08 - mse: 2.5817e-08 - val_loss: 2.3413e-08 - val_mse: 2.3413e-08\n",
      "Epoch 34/55\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.6769e-08 - mse: 1.6769e-08 - val_loss: 1.5137e-08 - val_mse: 1.5137e-08\n",
      "Epoch 35/55\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0855e-08 - mse: 1.0855e-08 - val_loss: 9.8313e-09 - val_mse: 9.8313e-09\n",
      "Epoch 36/55\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 7.0347e-09 - mse: 7.0347e-09 - val_loss: 6.3902e-09 - val_mse: 6.3902e-09\n",
      "Epoch 37/55\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.5799e-09 - mse: 4.5799e-09 - val_loss: 4.1382e-09 - val_mse: 4.1382e-09\n",
      "Epoch 38/55\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 2.9732e-09 - mse: 2.9732e-09 - val_loss: 2.7126e-09 - val_mse: 2.7126e-09\n",
      "Epoch 39/55\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.9339e-09 - mse: 1.9339e-09 - val_loss: 1.7431e-09 - val_mse: 1.7431e-09\n",
      "Epoch 40/55\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.2515e-09 - mse: 1.2515e-09 - val_loss: 1.1394e-09 - val_mse: 1.1394e-09\n",
      "Epoch 41/55\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.1599e-10 - mse: 8.1599e-10 - val_loss: 7.3786e-10 - val_mse: 7.3786e-10\n",
      "Epoch 42/55\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.2875e-10 - mse: 5.2875e-10 - val_loss: 4.8004e-10 - val_mse: 4.8004e-10\n",
      "Epoch 43/55\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 3.3897e-10 - mse: 3.3897e-10 - val_loss: 2.9944e-10 - val_mse: 2.9944e-10\n",
      "Epoch 44/55\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.1596e-10 - mse: 2.1596e-10 - val_loss: 1.9852e-10 - val_mse: 1.9852e-10\n",
      "Epoch 45/55\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.4645e-10 - mse: 1.4645e-10 - val_loss: 1.3566e-10 - val_mse: 1.3566e-10\n",
      "Epoch 46/55\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 9.7297e-11 - mse: 9.7297e-11 - val_loss: 8.7596e-11 - val_mse: 8.7596e-11\n",
      "Epoch 47/55\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.9103e-11 - mse: 5.9103e-11 - val_loss: 4.8518e-11 - val_mse: 4.8518e-11\n",
      "Epoch 48/55\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 3.2708e-11 - mse: 3.2708e-11 - val_loss: 2.9423e-11 - val_mse: 2.9423e-11\n",
      "Epoch 49/55\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.2147e-11 - mse: 2.2147e-11 - val_loss: 2.1916e-11 - val_mse: 2.1916e-11\n",
      "Epoch 50/55\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.8474e-11 - mse: 1.8474e-11 - val_loss: 1.9849e-11 - val_mse: 1.9849e-11\n",
      "Epoch 51/55\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.6550e-11 - mse: 1.6550e-11 - val_loss: 1.7884e-11 - val_mse: 1.7884e-11\n",
      "Epoch 52/55\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.5418e-11 - mse: 1.5418e-11 - val_loss: 1.7352e-11 - val_mse: 1.7352e-11\n",
      "Epoch 53/55\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.5006e-11 - mse: 1.5006e-11 - val_loss: 1.6663e-11 - val_mse: 1.6663e-11\n",
      "Epoch 54/55\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.4417e-11 - mse: 1.4417e-11 - val_loss: 1.5507e-11 - val_mse: 1.5507e-11\n",
      "Epoch 55/55\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.3467e-11 - mse: 1.3467e-11 - val_loss: 1.5507e-11 - val_mse: 1.5507e-11\n",
      "INFO:tensorflow:Assets written to: out/111-model-ntrain=1000-sigma=0.0-epochs=55.tf/assets\n",
      "Epoch 1/100\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.3467e-11 - mse: 1.3467e-11 - val_loss: 1.5507e-11 - val_mse: 1.5507e-11\n",
      "Epoch 2/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.3467e-11 - mse: 1.3467e-11 - val_loss: 1.5507e-11 - val_mse: 1.5507e-11\n",
      "Epoch 3/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.3471e-11 - mse: 1.3471e-11 - val_loss: 1.5441e-11 - val_mse: 1.5441e-11\n",
      "Epoch 4/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.3493e-11 - mse: 1.3493e-11 - val_loss: 1.5414e-11 - val_mse: 1.5414e-11\n",
      "Epoch 5/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.3451e-11 - mse: 1.3451e-11 - val_loss: 1.5414e-11 - val_mse: 1.5414e-11\n",
      "Epoch 6/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.3451e-11 - mse: 1.3451e-11 - val_loss: 1.5414e-11 - val_mse: 1.5414e-11\n",
      "Epoch 7/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.3451e-11 - mse: 1.3451e-11 - val_loss: 1.4933e-11 - val_mse: 1.4933e-11\n",
      "Epoch 8/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.2972e-11 - mse: 1.2972e-11 - val_loss: 1.4933e-11 - val_mse: 1.4933e-11\n",
      "Epoch 9/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.2990e-11 - mse: 1.2990e-11 - val_loss: 1.4933e-11 - val_mse: 1.4933e-11\n",
      "Epoch 10/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.2972e-11 - mse: 1.2972e-11 - val_loss: 1.4880e-11 - val_mse: 1.4880e-11\n",
      "Epoch 11/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.2976e-11 - mse: 1.2976e-11 - val_loss: 1.4933e-11 - val_mse: 1.4933e-11\n",
      "Epoch 12/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.2973e-11 - mse: 1.2973e-11 - val_loss: 1.4972e-11 - val_mse: 1.4972e-11\n",
      "Epoch 13/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.2978e-11 - mse: 1.2978e-11 - val_loss: 1.4972e-11 - val_mse: 1.4972e-11\n",
      "Epoch 14/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.2978e-11 - mse: 1.2978e-11 - val_loss: 1.4972e-11 - val_mse: 1.4972e-11\n",
      "Epoch 15/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.2978e-11 - mse: 1.2978e-11 - val_loss: 1.4972e-11 - val_mse: 1.4972e-11\n",
      "Epoch 16/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.2978e-11 - mse: 1.2978e-11 - val_loss: 1.4972e-11 - val_mse: 1.4972e-11\n",
      "Epoch 17/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.2990e-11 - mse: 1.2990e-11 - val_loss: 1.4933e-11 - val_mse: 1.4933e-11\n",
      "Epoch 18/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.2972e-11 - mse: 1.2972e-11 - val_loss: 1.4933e-11 - val_mse: 1.4933e-11\n",
      "Epoch 19/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.2972e-11 - mse: 1.2972e-11 - val_loss: 1.4933e-11 - val_mse: 1.4933e-11\n",
      "Epoch 20/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.2992e-11 - mse: 1.2992e-11 - val_loss: 1.4933e-11 - val_mse: 1.4933e-11\n",
      "Epoch 21/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.2972e-11 - mse: 1.2972e-11 - val_loss: 1.4933e-11 - val_mse: 1.4933e-11\n",
      "Epoch 22/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.2965e-11 - mse: 1.2965e-11 - val_loss: 1.4880e-11 - val_mse: 1.4880e-11\n",
      "Epoch 23/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.2952e-11 - mse: 1.2952e-11 - val_loss: 1.4359e-11 - val_mse: 1.4359e-11\n",
      "Epoch 24/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.2502e-11 - mse: 1.2502e-11 - val_loss: 1.4359e-11 - val_mse: 1.4359e-11\n",
      "Epoch 25/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.2508e-11 - mse: 1.2508e-11 - val_loss: 1.4384e-11 - val_mse: 1.4384e-11\n",
      "Epoch 26/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.2519e-11 - mse: 1.2519e-11 - val_loss: 1.4384e-11 - val_mse: 1.4384e-11\n",
      "Epoch 27/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.2506e-11 - mse: 1.2506e-11 - val_loss: 1.4384e-11 - val_mse: 1.4384e-11\n",
      "Epoch 28/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.2516e-11 - mse: 1.2516e-11 - val_loss: 1.4384e-11 - val_mse: 1.4384e-11\n",
      "Epoch 29/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.2491e-11 - mse: 1.2491e-11 - val_loss: 1.4384e-11 - val_mse: 1.4384e-11\n",
      "Epoch 30/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.2506e-11 - mse: 1.2506e-11 - val_loss: 1.4384e-11 - val_mse: 1.4384e-11\n",
      "Epoch 31/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.2506e-11 - mse: 1.2506e-11 - val_loss: 1.4359e-11 - val_mse: 1.4359e-11\n",
      "Epoch 32/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.2502e-11 - mse: 1.2502e-11 - val_loss: 1.4359e-11 - val_mse: 1.4359e-11\n",
      "Epoch 33/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.2502e-11 - mse: 1.2502e-11 - val_loss: 1.4384e-11 - val_mse: 1.4384e-11\n",
      "Epoch 34/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.2506e-11 - mse: 1.2506e-11 - val_loss: 1.4384e-11 - val_mse: 1.4384e-11\n",
      "Epoch 35/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.2481e-11 - mse: 1.2481e-11 - val_loss: 1.4384e-11 - val_mse: 1.4384e-11\n",
      "Epoch 36/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.2472e-11 - mse: 1.2472e-11 - val_loss: 1.4384e-11 - val_mse: 1.4384e-11\n",
      "Epoch 37/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.2025e-11 - mse: 1.2025e-11 - val_loss: 1.3771e-11 - val_mse: 1.3771e-11\n",
      "Epoch 38/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.1960e-11 - mse: 1.1960e-11 - val_loss: 1.3771e-11 - val_mse: 1.3771e-11\n",
      "Epoch 39/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.1960e-11 - mse: 1.1960e-11 - val_loss: 1.3771e-11 - val_mse: 1.3771e-11\n",
      "Epoch 40/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.1960e-11 - mse: 1.1960e-11 - val_loss: 1.3771e-11 - val_mse: 1.3771e-11\n",
      "Epoch 41/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.1961e-11 - mse: 1.1961e-11 - val_loss: 1.3838e-11 - val_mse: 1.3838e-11\n",
      "Epoch 42/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.1985e-11 - mse: 1.1985e-11 - val_loss: 1.3838e-11 - val_mse: 1.3838e-11\n",
      "Epoch 43/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.2007e-11 - mse: 1.2007e-11 - val_loss: 1.3841e-11 - val_mse: 1.3841e-11\n",
      "Epoch 44/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.2002e-11 - mse: 1.2002e-11 - val_loss: 1.3749e-11 - val_mse: 1.3749e-11\n",
      "Epoch 45/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.1991e-11 - mse: 1.1991e-11 - val_loss: 1.3749e-11 - val_mse: 1.3749e-11\n",
      "Epoch 46/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.1977e-11 - mse: 1.1977e-11 - val_loss: 1.3771e-11 - val_mse: 1.3771e-11\n",
      "Epoch 47/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.1972e-11 - mse: 1.1972e-11 - val_loss: 1.3841e-11 - val_mse: 1.3841e-11\n",
      "Epoch 48/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.2002e-11 - mse: 1.2002e-11 - val_loss: 1.3841e-11 - val_mse: 1.3841e-11\n",
      "Epoch 49/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.1999e-11 - mse: 1.1999e-11 - val_loss: 1.3841e-11 - val_mse: 1.3841e-11\n",
      "Epoch 50/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.1999e-11 - mse: 1.1999e-11 - val_loss: 1.3841e-11 - val_mse: 1.3841e-11\n",
      "Epoch 51/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.1991e-11 - mse: 1.1991e-11 - val_loss: 1.3838e-11 - val_mse: 1.3838e-11\n",
      "Epoch 52/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.2001e-11 - mse: 1.2001e-11 - val_loss: 1.3841e-11 - val_mse: 1.3841e-11\n",
      "Epoch 53/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.1998e-11 - mse: 1.1998e-11 - val_loss: 1.3838e-11 - val_mse: 1.3838e-11\n",
      "Epoch 54/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.1980e-11 - mse: 1.1980e-11 - val_loss: 1.3207e-11 - val_mse: 1.3207e-11\n",
      "Epoch 55/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.1485e-11 - mse: 1.1485e-11 - val_loss: 1.3207e-11 - val_mse: 1.3207e-11\n",
      "Epoch 56/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.1485e-11 - mse: 1.1485e-11 - val_loss: 1.3207e-11 - val_mse: 1.3207e-11\n",
      "Epoch 57/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.1495e-11 - mse: 1.1495e-11 - val_loss: 1.3264e-11 - val_mse: 1.3264e-11\n",
      "Epoch 58/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.1493e-11 - mse: 1.1493e-11 - val_loss: 1.3207e-11 - val_mse: 1.3207e-11\n",
      "Epoch 59/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.1485e-11 - mse: 1.1485e-11 - val_loss: 1.2692e-11 - val_mse: 1.2692e-11\n",
      "Epoch 60/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.1054e-11 - mse: 1.1054e-11 - val_loss: 1.2656e-11 - val_mse: 1.2656e-11\n",
      "Epoch 61/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.1083e-11 - mse: 1.1083e-11 - val_loss: 1.2725e-11 - val_mse: 1.2725e-11\n",
      "Epoch 62/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.1084e-11 - mse: 1.1084e-11 - val_loss: 1.2725e-11 - val_mse: 1.2725e-11\n",
      "Epoch 63/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.1084e-11 - mse: 1.1084e-11 - val_loss: 1.2260e-11 - val_mse: 1.2260e-11\n",
      "Epoch 64/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0615e-11 - mse: 1.0615e-11 - val_loss: 1.2281e-11 - val_mse: 1.2281e-11\n",
      "Epoch 65/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0610e-11 - mse: 1.0610e-11 - val_loss: 1.2281e-11 - val_mse: 1.2281e-11\n",
      "Epoch 66/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0611e-11 - mse: 1.0611e-11 - val_loss: 1.2260e-11 - val_mse: 1.2260e-11\n",
      "Epoch 67/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0608e-11 - mse: 1.0608e-11 - val_loss: 1.2260e-11 - val_mse: 1.2260e-11\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 6ms/step - loss: 1.0608e-11 - mse: 1.0608e-11 - val_loss: 1.2260e-11 - val_mse: 1.2260e-11\n",
      "Epoch 69/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0608e-11 - mse: 1.0608e-11 - val_loss: 1.2237e-11 - val_mse: 1.2237e-11\n",
      "Epoch 70/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0611e-11 - mse: 1.0611e-11 - val_loss: 1.2260e-11 - val_mse: 1.2260e-11\n",
      "Epoch 71/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0608e-11 - mse: 1.0608e-11 - val_loss: 1.2260e-11 - val_mse: 1.2260e-11\n",
      "Epoch 72/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.0608e-11 - mse: 1.0608e-11 - val_loss: 1.2281e-11 - val_mse: 1.2281e-11\n",
      "Epoch 73/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.0618e-11 - mse: 1.0618e-11 - val_loss: 1.2281e-11 - val_mse: 1.2281e-11\n",
      "Epoch 74/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0610e-11 - mse: 1.0610e-11 - val_loss: 1.2281e-11 - val_mse: 1.2281e-11\n",
      "Epoch 75/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.0612e-11 - mse: 1.0612e-11 - val_loss: 1.2228e-11 - val_mse: 1.2228e-11\n",
      "Epoch 76/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0601e-11 - mse: 1.0601e-11 - val_loss: 1.2228e-11 - val_mse: 1.2228e-11\n",
      "Epoch 77/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0601e-11 - mse: 1.0601e-11 - val_loss: 1.2228e-11 - val_mse: 1.2228e-11\n",
      "Epoch 78/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.0601e-11 - mse: 1.0601e-11 - val_loss: 1.2228e-11 - val_mse: 1.2228e-11\n",
      "Epoch 79/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.0601e-11 - mse: 1.0601e-11 - val_loss: 1.2281e-11 - val_mse: 1.2281e-11\n",
      "Epoch 80/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.0610e-11 - mse: 1.0610e-11 - val_loss: 1.2260e-11 - val_mse: 1.2260e-11\n",
      "Epoch 81/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0608e-11 - mse: 1.0608e-11 - val_loss: 1.2260e-11 - val_mse: 1.2260e-11\n",
      "Epoch 82/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0608e-11 - mse: 1.0608e-11 - val_loss: 1.2260e-11 - val_mse: 1.2260e-11\n",
      "Epoch 83/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.0622e-11 - mse: 1.0622e-11 - val_loss: 1.2237e-11 - val_mse: 1.2237e-11\n",
      "Epoch 84/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.0608e-11 - mse: 1.0608e-11 - val_loss: 1.2237e-11 - val_mse: 1.2237e-11\n",
      "Epoch 85/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.0613e-11 - mse: 1.0613e-11 - val_loss: 1.2260e-11 - val_mse: 1.2260e-11\n",
      "Epoch 86/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0619e-11 - mse: 1.0619e-11 - val_loss: 1.2281e-11 - val_mse: 1.2281e-11\n",
      "Epoch 87/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0610e-11 - mse: 1.0610e-11 - val_loss: 1.2281e-11 - val_mse: 1.2281e-11\n",
      "Epoch 88/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0610e-11 - mse: 1.0610e-11 - val_loss: 1.2260e-11 - val_mse: 1.2260e-11\n",
      "Epoch 89/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0606e-11 - mse: 1.0606e-11 - val_loss: 1.2228e-11 - val_mse: 1.2228e-11\n",
      "Epoch 90/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.0615e-11 - mse: 1.0615e-11 - val_loss: 1.2298e-11 - val_mse: 1.2298e-11\n",
      "Epoch 91/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0615e-11 - mse: 1.0615e-11 - val_loss: 1.2298e-11 - val_mse: 1.2298e-11\n",
      "Epoch 92/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0615e-11 - mse: 1.0615e-11 - val_loss: 1.2298e-11 - val_mse: 1.2298e-11\n",
      "Epoch 93/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.0615e-11 - mse: 1.0615e-11 - val_loss: 1.2298e-11 - val_mse: 1.2298e-11\n",
      "Epoch 94/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0615e-11 - mse: 1.0615e-11 - val_loss: 1.2298e-11 - val_mse: 1.2298e-11\n",
      "Epoch 95/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.0615e-11 - mse: 1.0615e-11 - val_loss: 1.2298e-11 - val_mse: 1.2298e-11\n",
      "Epoch 96/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0615e-11 - mse: 1.0615e-11 - val_loss: 1.2298e-11 - val_mse: 1.2298e-11\n",
      "Epoch 97/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0615e-11 - mse: 1.0615e-11 - val_loss: 1.2298e-11 - val_mse: 1.2298e-11\n",
      "Epoch 98/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.0615e-11 - mse: 1.0615e-11 - val_loss: 1.2298e-11 - val_mse: 1.2298e-11\n",
      "Epoch 99/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.0615e-11 - mse: 1.0615e-11 - val_loss: 1.2298e-11 - val_mse: 1.2298e-11\n",
      "Epoch 100/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0615e-11 - mse: 1.0615e-11 - val_loss: 1.2298e-11 - val_mse: 1.2298e-11\n",
      "INFO:tensorflow:Assets written to: out/111-model-ntrain=1000-sigma=0.0-epochs=100.tf/assets\n",
      "\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 1s 13ms/step - loss: 3.4971 - mse: 3.4971 - val_loss: 2.6866 - val_mse: 2.6866\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.4232 - mse: 2.4232 - val_loss: 1.9336 - val_mse: 1.9336\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.8679 - mse: 1.8679 - val_loss: 1.5050 - val_mse: 1.5050\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.5417 - mse: 1.5417 - val_loss: 1.2422 - val_mse: 1.2422\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.3379 - mse: 1.3379 - val_loss: 1.0849 - val_mse: 1.0849\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.2120 - mse: 1.2120 - val_loss: 0.9815 - val_mse: 0.9815\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.1274 - mse: 1.1274 - val_loss: 0.9176 - val_mse: 0.9176\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.0734 - mse: 1.0734 - val_loss: 0.8802 - val_mse: 0.8802\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.0401 - mse: 1.0401 - val_loss: 0.8560 - val_mse: 0.8560\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.0168 - mse: 1.0168 - val_loss: 0.8413 - val_mse: 0.8413\n",
      "INFO:tensorflow:Assets written to: out/111-model-ntrain=1000-sigma=1.0-epochs=10.tf/assets\n",
      "Epoch 1/55\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.0014 - mse: 1.0014 - val_loss: 0.8324 - val_mse: 0.8324\n",
      "Epoch 2/55\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9917 - mse: 0.9917 - val_loss: 0.8279 - val_mse: 0.8279\n",
      "Epoch 3/55\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9859 - mse: 0.9859 - val_loss: 0.8257 - val_mse: 0.8257\n",
      "Epoch 4/55\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9819 - mse: 0.9819 - val_loss: 0.8247 - val_mse: 0.8247\n",
      "Epoch 5/55\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9793 - mse: 0.9793 - val_loss: 0.8254 - val_mse: 0.8254\n",
      "Epoch 6/55\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9782 - mse: 0.9782 - val_loss: 0.8254 - val_mse: 0.8254\n",
      "Epoch 7/55\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9768 - mse: 0.9768 - val_loss: 0.8256 - val_mse: 0.8256\n",
      "Epoch 8/55\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9762 - mse: 0.9762 - val_loss: 0.8262 - val_mse: 0.8262\n",
      "Epoch 9/55\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9758 - mse: 0.9758 - val_loss: 0.8267 - val_mse: 0.8267\n",
      "Epoch 10/55\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9753 - mse: 0.9753 - val_loss: 0.8275 - val_mse: 0.8275\n",
      "Epoch 11/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9752 - mse: 0.9752 - val_loss: 0.8276 - val_mse: 0.8276\n",
      "Epoch 12/55\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.9751 - mse: 0.9751 - val_loss: 0.8290 - val_mse: 0.8290\n",
      "Epoch 13/55\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9750 - mse: 0.9750 - val_loss: 0.8286 - val_mse: 0.8286\n",
      "Epoch 14/55\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9749 - mse: 0.9749 - val_loss: 0.8284 - val_mse: 0.8284\n",
      "Epoch 15/55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9748 - mse: 0.9748 - val_loss: 0.8301 - val_mse: 0.8301\n",
      "Epoch 16/55\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9750 - mse: 0.9750 - val_loss: 0.8290 - val_mse: 0.8290\n",
      "Epoch 17/55\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9749 - mse: 0.9749 - val_loss: 0.8292 - val_mse: 0.8292\n",
      "Epoch 18/55\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.9748 - mse: 0.9748 - val_loss: 0.8302 - val_mse: 0.8302\n",
      "Epoch 19/55\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.9748 - mse: 0.9748 - val_loss: 0.8285 - val_mse: 0.8285\n",
      "Epoch 20/55\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.9747 - mse: 0.9747 - val_loss: 0.8292 - val_mse: 0.8292\n",
      "Epoch 21/55\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.9746 - mse: 0.9746 - val_loss: 0.8295 - val_mse: 0.8295\n",
      "Epoch 22/55\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9748 - mse: 0.9748 - val_loss: 0.8289 - val_mse: 0.8289\n",
      "Epoch 23/55\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9751 - mse: 0.9751 - val_loss: 0.8294 - val_mse: 0.8294\n",
      "Epoch 24/55\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.9748 - mse: 0.9748 - val_loss: 0.8287 - val_mse: 0.8287\n",
      "Epoch 25/55\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.9750 - mse: 0.9750 - val_loss: 0.8283 - val_mse: 0.8283\n",
      "Epoch 26/55\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.9747 - mse: 0.9747 - val_loss: 0.8292 - val_mse: 0.8292\n",
      "Epoch 27/55\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.9745 - mse: 0.9745 - val_loss: 0.8284 - val_mse: 0.8284\n",
      "Epoch 28/55\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.9748 - mse: 0.9748 - val_loss: 0.8283 - val_mse: 0.8283\n",
      "Epoch 29/55\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.9752 - mse: 0.9752 - val_loss: 0.8290 - val_mse: 0.8290\n",
      "Epoch 30/55\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.9748 - mse: 0.9748 - val_loss: 0.8290 - val_mse: 0.8290\n",
      "Epoch 31/55\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.9752 - mse: 0.9752 - val_loss: 0.8282 - val_mse: 0.8282\n",
      "Epoch 32/55\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.9746 - mse: 0.9746 - val_loss: 0.8278 - val_mse: 0.8278\n",
      "Epoch 33/55\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.9749 - mse: 0.9749 - val_loss: 0.8283 - val_mse: 0.8283\n",
      "Epoch 34/55\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.9746 - mse: 0.9746 - val_loss: 0.8293 - val_mse: 0.8293\n",
      "Epoch 35/55\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.9748 - mse: 0.9748 - val_loss: 0.8284 - val_mse: 0.8284\n",
      "Epoch 36/55\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.9745 - mse: 0.9745 - val_loss: 0.8288 - val_mse: 0.8288\n",
      "Epoch 37/55\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.9746 - mse: 0.9746 - val_loss: 0.8294 - val_mse: 0.8294\n",
      "Epoch 38/55\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.9748 - mse: 0.9748 - val_loss: 0.8283 - val_mse: 0.8283\n",
      "Epoch 39/55\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.9748 - mse: 0.9748 - val_loss: 0.8283 - val_mse: 0.8283\n",
      "Epoch 40/55\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.9749 - mse: 0.9749 - val_loss: 0.8280 - val_mse: 0.8280\n",
      "Epoch 41/55\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.9748 - mse: 0.9748 - val_loss: 0.8278 - val_mse: 0.8278\n",
      "Epoch 42/55\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.9748 - mse: 0.9748 - val_loss: 0.8280 - val_mse: 0.8280\n",
      "Epoch 43/55\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.9749 - mse: 0.9749 - val_loss: 0.8279 - val_mse: 0.8279\n",
      "Epoch 44/55\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9749 - mse: 0.9749 - val_loss: 0.8275 - val_mse: 0.8275\n",
      "Epoch 45/55\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.9752 - mse: 0.9752 - val_loss: 0.8280 - val_mse: 0.8280\n",
      "Epoch 46/55\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.9751 - mse: 0.9751 - val_loss: 0.8278 - val_mse: 0.8278\n",
      "Epoch 47/55\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.9747 - mse: 0.9747 - val_loss: 0.8287 - val_mse: 0.8287\n",
      "Epoch 48/55\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.9748 - mse: 0.9748 - val_loss: 0.8294 - val_mse: 0.8294\n",
      "Epoch 49/55\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.9749 - mse: 0.9749 - val_loss: 0.8299 - val_mse: 0.8299\n",
      "Epoch 50/55\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.9748 - mse: 0.9748 - val_loss: 0.8300 - val_mse: 0.8300\n",
      "Epoch 51/55\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.9749 - mse: 0.9749 - val_loss: 0.8311 - val_mse: 0.8311\n",
      "Epoch 52/55\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.9747 - mse: 0.9747 - val_loss: 0.8304 - val_mse: 0.8304\n",
      "Epoch 53/55\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.9749 - mse: 0.9749 - val_loss: 0.8293 - val_mse: 0.8293\n",
      "Epoch 54/55\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.9748 - mse: 0.9748 - val_loss: 0.8289 - val_mse: 0.8289\n",
      "Epoch 55/55\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9749 - mse: 0.9749 - val_loss: 0.8296 - val_mse: 0.8296\n",
      "INFO:tensorflow:Assets written to: out/111-model-ntrain=1000-sigma=1.0-epochs=55.tf/assets\n",
      "Epoch 1/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.9746 - mse: 0.9746 - val_loss: 0.8292 - val_mse: 0.8292\n",
      "Epoch 2/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9747 - mse: 0.9747 - val_loss: 0.8292 - val_mse: 0.8292\n",
      "Epoch 3/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9748 - mse: 0.9748 - val_loss: 0.8291 - val_mse: 0.8291\n",
      "Epoch 4/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9748 - mse: 0.9748 - val_loss: 0.8291 - val_mse: 0.8291\n",
      "Epoch 5/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9747 - mse: 0.9747 - val_loss: 0.8298 - val_mse: 0.8298\n",
      "Epoch 6/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9750 - mse: 0.9750 - val_loss: 0.8298 - val_mse: 0.8298\n",
      "Epoch 7/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9748 - mse: 0.9748 - val_loss: 0.8295 - val_mse: 0.8295\n",
      "Epoch 8/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9749 - mse: 0.9749 - val_loss: 0.8294 - val_mse: 0.8294\n",
      "Epoch 9/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9749 - mse: 0.9749 - val_loss: 0.8296 - val_mse: 0.8296\n",
      "Epoch 10/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9747 - mse: 0.9747 - val_loss: 0.8300 - val_mse: 0.8300\n",
      "Epoch 11/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9749 - mse: 0.9749 - val_loss: 0.8297 - val_mse: 0.8297\n",
      "Epoch 12/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9749 - mse: 0.9749 - val_loss: 0.8308 - val_mse: 0.8308\n",
      "Epoch 13/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9749 - mse: 0.9749 - val_loss: 0.8301 - val_mse: 0.8301\n",
      "Epoch 14/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9748 - mse: 0.9748 - val_loss: 0.8296 - val_mse: 0.8296\n",
      "Epoch 15/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9748 - mse: 0.9748 - val_loss: 0.8310 - val_mse: 0.8310\n",
      "Epoch 16/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9749 - mse: 0.9749 - val_loss: 0.8297 - val_mse: 0.8297\n",
      "Epoch 17/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9749 - mse: 0.9749 - val_loss: 0.8298 - val_mse: 0.8298\n",
      "Epoch 18/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9748 - mse: 0.9748 - val_loss: 0.8307 - val_mse: 0.8307\n",
      "Epoch 19/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9748 - mse: 0.9748 - val_loss: 0.8289 - val_mse: 0.8289\n",
      "Epoch 20/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9747 - mse: 0.9747 - val_loss: 0.8296 - val_mse: 0.8296\n",
      "Epoch 21/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9746 - mse: 0.9746 - val_loss: 0.8297 - val_mse: 0.8297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9748 - mse: 0.9748 - val_loss: 0.8291 - val_mse: 0.8291\n",
      "Epoch 23/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9751 - mse: 0.9751 - val_loss: 0.8296 - val_mse: 0.8296\n",
      "Epoch 24/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9748 - mse: 0.9748 - val_loss: 0.8288 - val_mse: 0.8288\n",
      "Epoch 25/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9750 - mse: 0.9750 - val_loss: 0.8285 - val_mse: 0.8285\n",
      "Epoch 26/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9747 - mse: 0.9747 - val_loss: 0.8293 - val_mse: 0.8293\n",
      "Epoch 27/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9745 - mse: 0.9745 - val_loss: 0.8285 - val_mse: 0.8285\n",
      "Epoch 28/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9748 - mse: 0.9748 - val_loss: 0.8284 - val_mse: 0.8284\n",
      "Epoch 29/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9752 - mse: 0.9752 - val_loss: 0.8291 - val_mse: 0.8291\n",
      "Epoch 30/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9748 - mse: 0.9748 - val_loss: 0.8290 - val_mse: 0.8290\n",
      "Epoch 31/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9752 - mse: 0.9752 - val_loss: 0.8283 - val_mse: 0.8283\n",
      "Epoch 32/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9746 - mse: 0.9746 - val_loss: 0.8279 - val_mse: 0.8279\n",
      "Epoch 33/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9749 - mse: 0.9749 - val_loss: 0.8283 - val_mse: 0.8283\n",
      "Epoch 34/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9746 - mse: 0.9746 - val_loss: 0.8293 - val_mse: 0.8293\n",
      "Epoch 35/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9748 - mse: 0.9748 - val_loss: 0.8284 - val_mse: 0.8284\n",
      "Epoch 36/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9745 - mse: 0.9745 - val_loss: 0.8288 - val_mse: 0.8288\n",
      "Epoch 37/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9746 - mse: 0.9746 - val_loss: 0.8294 - val_mse: 0.8294\n",
      "Epoch 38/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9748 - mse: 0.9748 - val_loss: 0.8284 - val_mse: 0.8284\n",
      "Epoch 39/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9748 - mse: 0.9748 - val_loss: 0.8283 - val_mse: 0.8283\n",
      "Epoch 40/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9749 - mse: 0.9749 - val_loss: 0.8280 - val_mse: 0.8280\n",
      "Epoch 41/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9748 - mse: 0.9748 - val_loss: 0.8278 - val_mse: 0.8278\n",
      "Epoch 42/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9748 - mse: 0.9748 - val_loss: 0.8280 - val_mse: 0.8280\n",
      "Epoch 43/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9749 - mse: 0.9749 - val_loss: 0.8279 - val_mse: 0.8279\n",
      "Epoch 44/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9749 - mse: 0.9749 - val_loss: 0.8275 - val_mse: 0.8275\n",
      "Epoch 45/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9752 - mse: 0.9752 - val_loss: 0.8280 - val_mse: 0.8280\n",
      "Epoch 46/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9751 - mse: 0.9751 - val_loss: 0.8278 - val_mse: 0.8278\n",
      "Epoch 47/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9747 - mse: 0.9747 - val_loss: 0.8287 - val_mse: 0.8287\n",
      "Epoch 48/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9748 - mse: 0.9748 - val_loss: 0.8294 - val_mse: 0.8294\n",
      "Epoch 49/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9749 - mse: 0.9749 - val_loss: 0.8299 - val_mse: 0.8299\n",
      "Epoch 50/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9748 - mse: 0.9748 - val_loss: 0.8300 - val_mse: 0.8300\n",
      "Epoch 51/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9749 - mse: 0.9749 - val_loss: 0.8311 - val_mse: 0.8311\n",
      "Epoch 52/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9747 - mse: 0.9747 - val_loss: 0.8304 - val_mse: 0.8304\n",
      "Epoch 53/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9749 - mse: 0.9749 - val_loss: 0.8293 - val_mse: 0.8293\n",
      "Epoch 54/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9748 - mse: 0.9748 - val_loss: 0.8289 - val_mse: 0.8289\n",
      "Epoch 55/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9749 - mse: 0.9749 - val_loss: 0.8296 - val_mse: 0.8296\n",
      "Epoch 56/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9746 - mse: 0.9746 - val_loss: 0.8294 - val_mse: 0.8294\n",
      "Epoch 57/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9747 - mse: 0.9747 - val_loss: 0.8296 - val_mse: 0.8296\n",
      "Epoch 58/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9747 - mse: 0.9747 - val_loss: 0.8292 - val_mse: 0.8292\n",
      "Epoch 59/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9750 - mse: 0.9750 - val_loss: 0.8278 - val_mse: 0.8278\n",
      "Epoch 60/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9749 - mse: 0.9749 - val_loss: 0.8286 - val_mse: 0.8286\n",
      "Epoch 61/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9748 - mse: 0.9748 - val_loss: 0.8294 - val_mse: 0.8294\n",
      "Epoch 62/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9749 - mse: 0.9749 - val_loss: 0.8299 - val_mse: 0.8299\n",
      "Epoch 63/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9751 - mse: 0.9751 - val_loss: 0.8296 - val_mse: 0.8296\n",
      "Epoch 64/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9748 - mse: 0.9748 - val_loss: 0.8298 - val_mse: 0.8298\n",
      "Epoch 65/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9749 - mse: 0.9749 - val_loss: 0.8301 - val_mse: 0.8301\n",
      "Epoch 66/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9746 - mse: 0.9746 - val_loss: 0.8295 - val_mse: 0.8295\n",
      "Epoch 67/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9746 - mse: 0.9746 - val_loss: 0.8292 - val_mse: 0.8292\n",
      "Epoch 68/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9747 - mse: 0.9747 - val_loss: 0.8284 - val_mse: 0.8284\n",
      "Epoch 69/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9750 - mse: 0.9750 - val_loss: 0.8288 - val_mse: 0.8288\n",
      "Epoch 70/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9747 - mse: 0.9747 - val_loss: 0.8287 - val_mse: 0.8287\n",
      "Epoch 71/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9750 - mse: 0.9750 - val_loss: 0.8288 - val_mse: 0.8288\n",
      "Epoch 72/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9750 - mse: 0.9750 - val_loss: 0.8292 - val_mse: 0.8292\n",
      "Epoch 73/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9747 - mse: 0.9747 - val_loss: 0.8286 - val_mse: 0.8286\n",
      "Epoch 74/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9747 - mse: 0.9747 - val_loss: 0.8297 - val_mse: 0.8297\n",
      "Epoch 75/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9750 - mse: 0.9750 - val_loss: 0.8285 - val_mse: 0.8285\n",
      "Epoch 76/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9749 - mse: 0.9749 - val_loss: 0.8286 - val_mse: 0.8286\n",
      "Epoch 77/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9749 - mse: 0.9749 - val_loss: 0.8300 - val_mse: 0.8300\n",
      "Epoch 78/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9748 - mse: 0.9748 - val_loss: 0.8305 - val_mse: 0.8305\n",
      "Epoch 79/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9751 - mse: 0.9751 - val_loss: 0.8311 - val_mse: 0.8311\n",
      "Epoch 80/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9751 - mse: 0.9751 - val_loss: 0.8324 - val_mse: 0.8324\n",
      "Epoch 81/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9751 - mse: 0.9751 - val_loss: 0.8312 - val_mse: 0.8312\n",
      "Epoch 82/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9747 - mse: 0.9747 - val_loss: 0.8299 - val_mse: 0.8299\n",
      "Epoch 83/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9748 - mse: 0.9748 - val_loss: 0.8291 - val_mse: 0.8291\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9748 - mse: 0.9748 - val_loss: 0.8291 - val_mse: 0.8291\n",
      "Epoch 85/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9747 - mse: 0.9747 - val_loss: 0.8293 - val_mse: 0.8293\n",
      "Epoch 86/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9750 - mse: 0.9750 - val_loss: 0.8292 - val_mse: 0.8292\n",
      "Epoch 87/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9747 - mse: 0.9747 - val_loss: 0.8290 - val_mse: 0.8290\n",
      "Epoch 88/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9750 - mse: 0.9750 - val_loss: 0.8294 - val_mse: 0.8294\n",
      "Epoch 89/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9746 - mse: 0.9746 - val_loss: 0.8295 - val_mse: 0.8295\n",
      "Epoch 90/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9747 - mse: 0.9747 - val_loss: 0.8294 - val_mse: 0.8294\n",
      "Epoch 91/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9748 - mse: 0.9748 - val_loss: 0.8297 - val_mse: 0.8297\n",
      "Epoch 92/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9750 - mse: 0.9750 - val_loss: 0.8293 - val_mse: 0.8293\n",
      "Epoch 93/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9747 - mse: 0.9747 - val_loss: 0.8299 - val_mse: 0.8299\n",
      "Epoch 94/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9746 - mse: 0.9746 - val_loss: 0.8296 - val_mse: 0.8296\n",
      "Epoch 95/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9747 - mse: 0.9747 - val_loss: 0.8293 - val_mse: 0.8293\n",
      "Epoch 96/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9746 - mse: 0.9746 - val_loss: 0.8290 - val_mse: 0.8290\n",
      "Epoch 97/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9748 - mse: 0.9748 - val_loss: 0.8290 - val_mse: 0.8290\n",
      "Epoch 98/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9747 - mse: 0.9747 - val_loss: 0.8289 - val_mse: 0.8289\n",
      "Epoch 99/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9748 - mse: 0.9748 - val_loss: 0.8285 - val_mse: 0.8285\n",
      "Epoch 100/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9745 - mse: 0.9745 - val_loss: 0.8285 - val_mse: 0.8285\n",
      "INFO:tensorflow:Assets written to: out/111-model-ntrain=1000-sigma=1.0-epochs=100.tf/assets\n",
      "\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 1s 11ms/step - loss: 99.3098 - mse: 99.3098 - val_loss: 83.0102 - val_mse: 83.0102\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 98.5891 - mse: 98.5891 - val_loss: 82.6665 - val_mse: 82.6665\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 98.1891 - mse: 98.1891 - val_loss: 82.5206 - val_mse: 82.5206\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.9318 - mse: 97.9318 - val_loss: 82.4771 - val_mse: 82.4771\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.7661 - mse: 97.7661 - val_loss: 82.5742 - val_mse: 82.5742\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.7045 - mse: 97.7045 - val_loss: 82.5936 - val_mse: 82.5936\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.6088 - mse: 97.6088 - val_loss: 82.6169 - val_mse: 82.6169\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.5693 - mse: 97.5693 - val_loss: 82.6655 - val_mse: 82.6655\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.5514 - mse: 97.5514 - val_loss: 82.7185 - val_mse: 82.7185\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.5120 - mse: 97.5120 - val_loss: 82.7945 - val_mse: 82.7945\n",
      "INFO:tensorflow:Assets written to: out/111-model-ntrain=1000-sigma=10.0-epochs=10.tf/assets\n",
      "Epoch 1/55\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 97.4839 - mse: 97.4839 - val_loss: 82.7715 - val_mse: 82.7715\n",
      "Epoch 2/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4772 - mse: 97.4772 - val_loss: 82.7908 - val_mse: 82.7908\n",
      "Epoch 3/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4826 - mse: 97.4826 - val_loss: 82.8019 - val_mse: 82.8019\n",
      "Epoch 4/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4805 - mse: 97.4805 - val_loss: 82.8176 - val_mse: 82.8176\n",
      "Epoch 5/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4717 - mse: 97.4717 - val_loss: 82.9060 - val_mse: 82.9060\n",
      "Epoch 6/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.5034 - mse: 97.5034 - val_loss: 82.9199 - val_mse: 82.9199\n",
      "Epoch 7/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4860 - mse: 97.4860 - val_loss: 82.9052 - val_mse: 82.9052\n",
      "Epoch 8/55\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 97.4875 - mse: 97.4875 - val_loss: 82.9060 - val_mse: 82.9060\n",
      "Epoch 9/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4890 - mse: 97.4890 - val_loss: 82.9285 - val_mse: 82.9285\n",
      "Epoch 10/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4727 - mse: 97.4727 - val_loss: 82.9767 - val_mse: 82.9767\n",
      "Epoch 11/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4896 - mse: 97.4896 - val_loss: 82.9471 - val_mse: 82.9471\n",
      "Epoch 12/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4941 - mse: 97.4941 - val_loss: 83.0585 - val_mse: 83.0585\n",
      "Epoch 13/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4874 - mse: 97.4874 - val_loss: 82.9948 - val_mse: 82.9948\n",
      "Epoch 14/55\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 97.4787 - mse: 97.4787 - val_loss: 82.9510 - val_mse: 82.9510\n",
      "Epoch 15/55\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 97.4755 - mse: 97.4755 - val_loss: 83.0947 - val_mse: 83.0947\n",
      "Epoch 16/55\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 97.4929 - mse: 97.4929 - val_loss: 82.9650 - val_mse: 82.9650\n",
      "Epoch 17/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4872 - mse: 97.4872 - val_loss: 82.9786 - val_mse: 82.9786\n",
      "Epoch 18/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4834 - mse: 97.4834 - val_loss: 83.0644 - val_mse: 83.0644\n",
      "Epoch 19/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4764 - mse: 97.4764 - val_loss: 82.8861 - val_mse: 82.8861\n",
      "Epoch 20/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4719 - mse: 97.4719 - val_loss: 82.9533 - val_mse: 82.9533\n",
      "Epoch 21/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4562 - mse: 97.4562 - val_loss: 82.9707 - val_mse: 82.9707\n",
      "Epoch 22/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4759 - mse: 97.4759 - val_loss: 82.9108 - val_mse: 82.9108\n",
      "Epoch 23/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.5113 - mse: 97.5113 - val_loss: 82.9551 - val_mse: 82.9551\n",
      "Epoch 24/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4818 - mse: 97.4818 - val_loss: 82.8810 - val_mse: 82.8810\n",
      "Epoch 25/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4961 - mse: 97.4961 - val_loss: 82.8450 - val_mse: 82.8450\n",
      "Epoch 26/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4704 - mse: 97.4704 - val_loss: 82.9262 - val_mse: 82.9262\n",
      "Epoch 27/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4522 - mse: 97.4522 - val_loss: 82.8509 - val_mse: 82.8509\n",
      "Epoch 28/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4801 - mse: 97.4801 - val_loss: 82.8393 - val_mse: 82.8393\n",
      "Epoch 29/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.5195 - mse: 97.5195 - val_loss: 82.9046 - val_mse: 82.9046\n",
      "Epoch 30/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4772 - mse: 97.4772 - val_loss: 82.9007 - val_mse: 82.9007\n",
      "Epoch 31/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.5197 - mse: 97.5197 - val_loss: 82.8267 - val_mse: 82.8267\n",
      "Epoch 32/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4631 - mse: 97.4631 - val_loss: 82.7862 - val_mse: 82.7862\n",
      "Epoch 33/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4939 - mse: 97.4939 - val_loss: 82.8274 - val_mse: 82.8274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4575 - mse: 97.4575 - val_loss: 82.9282 - val_mse: 82.9282\n",
      "Epoch 35/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4755 - mse: 97.4755 - val_loss: 82.8372 - val_mse: 82.8372\n",
      "Epoch 36/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4546 - mse: 97.4546 - val_loss: 82.8825 - val_mse: 82.8825\n",
      "Epoch 37/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4644 - mse: 97.4644 - val_loss: 82.9384 - val_mse: 82.9384\n",
      "Epoch 38/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4827 - mse: 97.4827 - val_loss: 82.8352 - val_mse: 82.8352\n",
      "Epoch 39/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4765 - mse: 97.4765 - val_loss: 82.8303 - val_mse: 82.8303\n",
      "Epoch 40/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4908 - mse: 97.4908 - val_loss: 82.8019 - val_mse: 82.8019\n",
      "Epoch 41/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4822 - mse: 97.4822 - val_loss: 82.7795 - val_mse: 82.7795\n",
      "Epoch 42/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4830 - mse: 97.4830 - val_loss: 82.7988 - val_mse: 82.7988\n",
      "Epoch 43/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4869 - mse: 97.4869 - val_loss: 82.7884 - val_mse: 82.7884\n",
      "Epoch 44/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4919 - mse: 97.4919 - val_loss: 82.7505 - val_mse: 82.7505\n",
      "Epoch 45/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.5171 - mse: 97.5171 - val_loss: 82.7981 - val_mse: 82.7981\n",
      "Epoch 46/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.5105 - mse: 97.5105 - val_loss: 82.7771 - val_mse: 82.7771\n",
      "Epoch 47/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4699 - mse: 97.4699 - val_loss: 82.8669 - val_mse: 82.8669\n",
      "Epoch 48/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4806 - mse: 97.4806 - val_loss: 82.9441 - val_mse: 82.9441\n",
      "Epoch 49/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4911 - mse: 97.4911 - val_loss: 82.9895 - val_mse: 82.9895\n",
      "Epoch 50/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4801 - mse: 97.4801 - val_loss: 83.0041 - val_mse: 83.0041\n",
      "Epoch 51/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4899 - mse: 97.4899 - val_loss: 83.1115 - val_mse: 83.1115\n",
      "Epoch 52/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4745 - mse: 97.4745 - val_loss: 83.0365 - val_mse: 83.0365\n",
      "Epoch 53/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4905 - mse: 97.4905 - val_loss: 82.9273 - val_mse: 82.9273\n",
      "Epoch 54/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4752 - mse: 97.4752 - val_loss: 82.8855 - val_mse: 82.8855\n",
      "Epoch 55/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4864 - mse: 97.4864 - val_loss: 82.9577 - val_mse: 82.9577\n",
      "INFO:tensorflow:Assets written to: out/111-model-ntrain=1000-sigma=10.0-epochs=55.tf/assets\n",
      "Epoch 1/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 97.4603 - mse: 97.4603 - val_loss: 82.9222 - val_mse: 82.9222\n",
      "Epoch 2/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4650 - mse: 97.4650 - val_loss: 82.9213 - val_mse: 82.9213\n",
      "Epoch 3/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4753 - mse: 97.4753 - val_loss: 82.9108 - val_mse: 82.9108\n",
      "Epoch 4/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4763 - mse: 97.4763 - val_loss: 82.9075 - val_mse: 82.9075\n",
      "Epoch 5/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 97.4686 - mse: 97.4686 - val_loss: 82.9782 - val_mse: 82.9782\n",
      "Epoch 6/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.5003 - mse: 97.5003 - val_loss: 82.9806 - val_mse: 82.9806\n",
      "Epoch 7/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4849 - mse: 97.4849 - val_loss: 82.9540 - val_mse: 82.9540\n",
      "Epoch 8/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4865 - mse: 97.4865 - val_loss: 82.9443 - val_mse: 82.9443\n",
      "Epoch 9/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4871 - mse: 97.4871 - val_loss: 82.9600 - val_mse: 82.9600\n",
      "Epoch 10/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4717 - mse: 97.4717 - val_loss: 83.0029 - val_mse: 83.0029\n",
      "Epoch 11/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4895 - mse: 97.4895 - val_loss: 82.9684 - val_mse: 82.9684\n",
      "Epoch 12/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4943 - mse: 97.4943 - val_loss: 83.0761 - val_mse: 83.0761\n",
      "Epoch 13/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4878 - mse: 97.4878 - val_loss: 83.0088 - val_mse: 83.0088\n",
      "Epoch 14/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4789 - mse: 97.4789 - val_loss: 82.9621 - val_mse: 82.9621\n",
      "Epoch 15/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4755 - mse: 97.4755 - val_loss: 83.1035 - val_mse: 83.1035\n",
      "Epoch 16/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4928 - mse: 97.4928 - val_loss: 82.9719 - val_mse: 82.9719\n",
      "Epoch 17/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4870 - mse: 97.4870 - val_loss: 82.9844 - val_mse: 82.9844\n",
      "Epoch 18/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4834 - mse: 97.4834 - val_loss: 83.0692 - val_mse: 83.0692\n",
      "Epoch 19/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4764 - mse: 97.4764 - val_loss: 82.8898 - val_mse: 82.8898\n",
      "Epoch 20/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4719 - mse: 97.4719 - val_loss: 82.9563 - val_mse: 82.9563\n",
      "Epoch 21/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4562 - mse: 97.4562 - val_loss: 82.9733 - val_mse: 82.9733\n",
      "Epoch 22/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4760 - mse: 97.4760 - val_loss: 82.9127 - val_mse: 82.9127\n",
      "Epoch 23/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.5113 - mse: 97.5113 - val_loss: 82.9567 - val_mse: 82.9567\n",
      "Epoch 24/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4818 - mse: 97.4818 - val_loss: 82.8823 - val_mse: 82.8823\n",
      "Epoch 25/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4961 - mse: 97.4961 - val_loss: 82.8460 - val_mse: 82.8460\n",
      "Epoch 26/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4704 - mse: 97.4704 - val_loss: 82.9270 - val_mse: 82.9270\n",
      "Epoch 27/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4522 - mse: 97.4522 - val_loss: 82.8516 - val_mse: 82.8516\n",
      "Epoch 28/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4801 - mse: 97.4801 - val_loss: 82.8398 - val_mse: 82.8398\n",
      "Epoch 29/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.5195 - mse: 97.5195 - val_loss: 82.9050 - val_mse: 82.9050\n",
      "Epoch 30/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4772 - mse: 97.4772 - val_loss: 82.9010 - val_mse: 82.9010\n",
      "Epoch 31/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.5197 - mse: 97.5197 - val_loss: 82.8270 - val_mse: 82.8270\n",
      "Epoch 32/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4630 - mse: 97.4630 - val_loss: 82.7864 - val_mse: 82.7864\n",
      "Epoch 33/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4939 - mse: 97.4939 - val_loss: 82.8276 - val_mse: 82.8276\n",
      "Epoch 34/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4575 - mse: 97.4575 - val_loss: 82.9284 - val_mse: 82.9284\n",
      "Epoch 35/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4756 - mse: 97.4756 - val_loss: 82.8373 - val_mse: 82.8373\n",
      "Epoch 36/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 97.4545 - mse: 97.4545 - val_loss: 82.8826 - val_mse: 82.8826\n",
      "Epoch 37/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4644 - mse: 97.4644 - val_loss: 82.9384 - val_mse: 82.9384\n",
      "Epoch 38/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4827 - mse: 97.4827 - val_loss: 82.8352 - val_mse: 82.8352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4765 - mse: 97.4765 - val_loss: 82.8303 - val_mse: 82.8303\n",
      "Epoch 40/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4908 - mse: 97.4908 - val_loss: 82.8019 - val_mse: 82.8019\n",
      "Epoch 41/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4822 - mse: 97.4822 - val_loss: 82.7795 - val_mse: 82.7795\n",
      "Epoch 42/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4830 - mse: 97.4830 - val_loss: 82.7988 - val_mse: 82.7988\n",
      "Epoch 43/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4869 - mse: 97.4869 - val_loss: 82.7884 - val_mse: 82.7884\n",
      "Epoch 44/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4919 - mse: 97.4919 - val_loss: 82.7505 - val_mse: 82.7505\n",
      "Epoch 45/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.5171 - mse: 97.5171 - val_loss: 82.7981 - val_mse: 82.7981\n",
      "Epoch 46/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.5105 - mse: 97.5105 - val_loss: 82.7771 - val_mse: 82.7771\n",
      "Epoch 47/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4699 - mse: 97.4699 - val_loss: 82.8669 - val_mse: 82.8669\n",
      "Epoch 48/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4806 - mse: 97.4806 - val_loss: 82.9441 - val_mse: 82.9441\n",
      "Epoch 49/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4911 - mse: 97.4911 - val_loss: 82.9895 - val_mse: 82.9895\n",
      "Epoch 50/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4801 - mse: 97.4801 - val_loss: 83.0041 - val_mse: 83.0041\n",
      "Epoch 51/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4899 - mse: 97.4899 - val_loss: 83.1115 - val_mse: 83.1115\n",
      "Epoch 52/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4745 - mse: 97.4745 - val_loss: 83.0365 - val_mse: 83.0365\n",
      "Epoch 53/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4905 - mse: 97.4905 - val_loss: 82.9274 - val_mse: 82.9274\n",
      "Epoch 54/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 97.4752 - mse: 97.4752 - val_loss: 82.8855 - val_mse: 82.8855\n",
      "Epoch 55/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 97.4864 - mse: 97.4864 - val_loss: 82.9577 - val_mse: 82.9577\n",
      "Epoch 56/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4646 - mse: 97.4646 - val_loss: 82.9436 - val_mse: 82.9436\n",
      "Epoch 57/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4745 - mse: 97.4745 - val_loss: 82.9644 - val_mse: 82.9644\n",
      "Epoch 58/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4685 - mse: 97.4685 - val_loss: 82.9156 - val_mse: 82.9156\n",
      "Epoch 59/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 97.5044 - mse: 97.5044 - val_loss: 82.7805 - val_mse: 82.7805\n",
      "Epoch 60/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4931 - mse: 97.4931 - val_loss: 82.8609 - val_mse: 82.8609\n",
      "Epoch 61/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4828 - mse: 97.4828 - val_loss: 82.9379 - val_mse: 82.9379\n",
      "Epoch 62/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4873 - mse: 97.4873 - val_loss: 82.9899 - val_mse: 82.9899\n",
      "Epoch 63/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.5067 - mse: 97.5067 - val_loss: 82.9597 - val_mse: 82.9597\n",
      "Epoch 64/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4819 - mse: 97.4819 - val_loss: 82.9837 - val_mse: 82.9837\n",
      "Epoch 65/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 97.4909 - mse: 97.4909 - val_loss: 83.0083 - val_mse: 83.0083\n",
      "Epoch 66/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4616 - mse: 97.4616 - val_loss: 82.9466 - val_mse: 82.9466\n",
      "Epoch 67/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4573 - mse: 97.4573 - val_loss: 82.9169 - val_mse: 82.9169\n",
      "Epoch 68/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4673 - mse: 97.4673 - val_loss: 82.8356 - val_mse: 82.8356\n",
      "Epoch 69/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4979 - mse: 97.4979 - val_loss: 82.8845 - val_mse: 82.8845\n",
      "Epoch 70/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4723 - mse: 97.4723 - val_loss: 82.8738 - val_mse: 82.8738\n",
      "Epoch 71/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4957 - mse: 97.4957 - val_loss: 82.8788 - val_mse: 82.8788\n",
      "Epoch 72/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4970 - mse: 97.4970 - val_loss: 82.9201 - val_mse: 82.9201\n",
      "Epoch 73/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4724 - mse: 97.4724 - val_loss: 82.8585 - val_mse: 82.8585\n",
      "Epoch 74/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4727 - mse: 97.4727 - val_loss: 82.9671 - val_mse: 82.9671\n",
      "Epoch 75/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4960 - mse: 97.4960 - val_loss: 82.8537 - val_mse: 82.8537\n",
      "Epoch 76/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4926 - mse: 97.4926 - val_loss: 82.8559 - val_mse: 82.8559\n",
      "Epoch 77/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4942 - mse: 97.4942 - val_loss: 83.0038 - val_mse: 83.0038\n",
      "Epoch 78/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4769 - mse: 97.4769 - val_loss: 83.0506 - val_mse: 83.0506\n",
      "Epoch 79/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.5105 - mse: 97.5105 - val_loss: 83.1074 - val_mse: 83.1074\n",
      "Epoch 80/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.5080 - mse: 97.5080 - val_loss: 83.2363 - val_mse: 83.2363\n",
      "Epoch 81/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.5115 - mse: 97.5115 - val_loss: 83.1230 - val_mse: 83.1230\n",
      "Epoch 82/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4719 - mse: 97.4719 - val_loss: 82.9879 - val_mse: 82.9879\n",
      "Epoch 83/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 97.4819 - mse: 97.4819 - val_loss: 82.9089 - val_mse: 82.9089\n",
      "Epoch 84/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4839 - mse: 97.4839 - val_loss: 82.9143 - val_mse: 82.9143\n",
      "Epoch 85/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4729 - mse: 97.4729 - val_loss: 82.9291 - val_mse: 82.9291\n",
      "Epoch 86/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4960 - mse: 97.4960 - val_loss: 82.9248 - val_mse: 82.9248\n",
      "Epoch 87/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4692 - mse: 97.4692 - val_loss: 82.9033 - val_mse: 82.9033\n",
      "Epoch 88/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4987 - mse: 97.4987 - val_loss: 82.9440 - val_mse: 82.9440\n",
      "Epoch 89/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4594 - mse: 97.4594 - val_loss: 82.9524 - val_mse: 82.9524\n",
      "Epoch 90/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4728 - mse: 97.4728 - val_loss: 82.9402 - val_mse: 82.9402\n",
      "Epoch 91/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4821 - mse: 97.4821 - val_loss: 82.9678 - val_mse: 82.9678\n",
      "Epoch 92/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4968 - mse: 97.4968 - val_loss: 82.9291 - val_mse: 82.9291\n",
      "Epoch 93/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4730 - mse: 97.4730 - val_loss: 82.9914 - val_mse: 82.9914\n",
      "Epoch 94/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4563 - mse: 97.4563 - val_loss: 82.9602 - val_mse: 82.9602\n",
      "Epoch 95/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4668 - mse: 97.4668 - val_loss: 82.9304 - val_mse: 82.9304\n",
      "Epoch 96/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4630 - mse: 97.4630 - val_loss: 82.8995 - val_mse: 82.8995\n",
      "Epoch 97/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4850 - mse: 97.4850 - val_loss: 82.8992 - val_mse: 82.8992\n",
      "Epoch 98/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4746 - mse: 97.4746 - val_loss: 82.8856 - val_mse: 82.8856\n",
      "Epoch 99/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4783 - mse: 97.4783 - val_loss: 82.8531 - val_mse: 82.8531\n",
      "Epoch 100/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4540 - mse: 97.4540 - val_loss: 82.8512 - val_mse: 82.8512\n",
      "INFO:tensorflow:Assets written to: out/111-model-ntrain=1000-sigma=10.0-epochs=100.tf/assets\n",
      "\n"
     ]
    }
   ],
   "source": [
    "RERUN=False\n",
    "\n",
    "if(RERUN):\n",
    "    TestParameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245d70ce",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3ef8a50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig=plt.figure(figsize=(16, 8))\n",
    "plt.suptitle('Difference', weight='bold')\n",
    "\n",
    "m_out=np.loadtxt(\"out/111-m_diff.csv\", usecols=(0), unpack=True )\n",
    "b_out=np.loadtxt(\"out/111-b_diff.csv\", usecols=(0), unpack=True )\n",
    "x=np.arange(0,len(m_out))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.title(\"m\")\n",
    "plt.scatter(x,np.absolute((m-m_out)/m))\n",
    "for l in np.arange(2.5,len(m_out)-3,3):\n",
    "    plt.axvline(l,ls=\":\")\n",
    "for l in np.arange(8.5,len(m_out)-9,9):\n",
    "    plt.axvline(l,ls=\"--\")\n",
    "\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.title(\"b\")\n",
    "plt.scatter(x,np.absolute((b-b_out)/b))\n",
    "for l in np.arange(2.5,len(b_out)-3,3):\n",
    "    plt.axvline(l,ls=\":\")\n",
    "for l in np.arange(8.5,len(b_out)-9,9):\n",
    "    plt.axvline(l,ls=\"--\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e784f4",
   "metadata": {},
   "source": [
    "Here we plotted the module of the difference between the target $m$, $b$ and the weight and bias of the NN after the training. In each dotted box we have the results obtained from different number of epochs at fixed sigma. Each dashed box contains results with fixed number of training data.\n",
    "\n",
    "Some observations:\n",
    "1. fixed sigma and number of epochs, increasing the size of training dataset leads to better results\n",
    "2. Increasing the number of epochs leads to better results but the impact of this parameter lowers by increasing the training dataset size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c443636e",
   "metadata": {},
   "source": [
    "Let's now see how the models performs. The following script allows to view the error plots for train and test data. Parameters can be changed by changing the indices according to the table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a214550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sigma</th>\n",
       "      <th>N_train</th>\n",
       "      <th>N_epochs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>550</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sigma  N_train  N_epochs\n",
       "0    0.0      100        10\n",
       "1    1.0      550        55\n",
       "2   10.0     1000       100"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame({'sigma': sigmas, 'N_train':ntrains, 'N_epochs': epochss})\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fcd1ae34",
   "metadata": {},
   "outputs": [],
   "source": [
    "isigma=0\n",
    "itrain=2\n",
    "iepoch=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc4725aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_df=pd.read_csv(\"out/111-history-ntrain=\"+str(ntrains[itrain])+\"-sigma=\"+str(sigmas[isigma])+\".csv\")\n",
    "model=load_model(\"out/111-model-ntrain=\"+str(ntrains[itrain])+\"-sigma=\"+str(sigmas[isigma])+\"-epochs=\"+str(epochss[iepoch])+\".tf\")\n",
    "\n",
    "show_results(model,history_df,50, epochss[iepoch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f390c57e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
