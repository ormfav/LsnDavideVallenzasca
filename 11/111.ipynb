{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eec349fa",
   "metadata": {},
   "source": [
    "# $11^{th}$ excercise\n",
    "## 11.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f4c67f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import get_custom_objects\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "742ba95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TestParameters():\n",
    "    deltaepochss=np.ones(len(epochss))*epochss[0]\n",
    "    for i in range(len(epochss)-1):\n",
    "        deltaepochss[i+1]=epochss[i+1]-epochss[i] \n",
    "    print(\"Epochs delta: \",deltaepochss)\n",
    "        \n",
    "    # open and clear output files\n",
    "    fout_m = open(\"out/111-m_diff.csv\",\"a\")\n",
    "    fout_b = open(\"out/111-b_diff.csv\",\"a\")\n",
    "    fout_m.truncate(0)\n",
    "    fout_b.truncate(0)\n",
    "\n",
    "    for ntrain in ntrains:\n",
    "        nvalid = ntrain // 10\n",
    "        np.random.seed(0)\n",
    "        tf.random.set_seed(0)\n",
    "        #creating training and validation datasets\n",
    "        x_train = np.random.uniform(-1, 1, ntrain)\n",
    "        x_valid = np.random.uniform(-1, 1, nvalid)\n",
    "        x_valid.sort()\n",
    "        \n",
    "\n",
    "        for sigma in sigmas:\n",
    "            np.random.seed(0)\n",
    "            tf.random.set_seed(0)\n",
    "            y_train = np.random.normal(m * x_train + b, sigma) \n",
    "            y_valid = np.random.normal(m * x_valid + b, sigma) \n",
    "            #creating and compiling the model\n",
    "            model = tf.keras.Sequential()\n",
    "            model.add(Dense(1, input_shape=(1,)))\n",
    "            model.compile(optimizer='sgd', loss='mse', metrics=['mse'])\n",
    "            \n",
    "            df=pd.DataFrame()\n",
    "            \n",
    "            for epochs in epochss:\n",
    "                #optimizing the model\n",
    "                ## model.fit(epochs=20)=four calls of\n",
    "                ## model.fit(epochs=5)\n",
    "                history = model.fit(x=x_train, y=y_train, \n",
    "                                    batch_size=32, \n",
    "                                    epochs=epochs,\n",
    "                                    shuffle=True, \n",
    "                                    validation_data=(x_valid, y_valid))        \n",
    "                df=pd.concat([df,pd.DataFrame(history.history)])\n",
    "                \n",
    "                # output\n",
    "                mb = model.get_weights()\n",
    "\n",
    "                printm=str(mb[0])[2:-2]\n",
    "                printb=str(mb[1])[1:-1] #don't want brackets in final string\n",
    "                fout_m.write(printm+\"\\n\")\n",
    "                fout_b.write(printb+\"\\n\")\n",
    "                \n",
    "                path_model=\"out/111-model-ntrain=\"+str(ntrain)+\"-sigma=\"+str(sigma)+\"-epochs=\"+str(epochs)+\".tf\"\n",
    "                model.save(filepath=path_model, include_optimizer=True) \n",
    "            \n",
    "            path_history=\"out/111-history-ntrain=\"+str(ntrain)+\"-sigma=\"+str(sigma)+\".csv\"\n",
    "            with open(path_history, mode='w') as file:\n",
    "                df.to_csv(file)\n",
    "            print()\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ed0a0cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_results(model, history, npredict, epochs):\n",
    "    plt.figure(figsize=(16,8))\n",
    "    \n",
    "    plt.subplot(121)\n",
    "    plt.plot(history[\"loss\"].iloc[:epochs], label=\"Training\")\n",
    "    plt.plot(history[\"val_loss\"].iloc[:epochs], label=\"Validation\")\n",
    "    plt.title(\"Model loss\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.subplot(122)\n",
    "    x_predict = np.random.uniform(-1, 1, npredict)\n",
    "    y_predict = model.predict(x_predict)\n",
    "    x_target=np.sort(x_predict)\n",
    "    y_target = m * x_target + b \n",
    "    plt.scatter(x_predict, y_predict, label='Predicted')\n",
    "    plt.plot(x_target, y_target, label='Target')   \n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe275f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target parameters of f(x) = m*x + b\n",
    "m = 2 \n",
    "b = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ffcadbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmas = np.array([0.,1,10])\n",
    "ntrains = np.linspace(100,1000,3,dtype=int)\n",
    "epochss = np.linspace(10,100,3,dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "18965dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs delta:  [10. 45. 45.]\n",
      "Epoch 1/10\n",
      "4/4 [==============================] - 1s 103ms/step - loss: 3.1255 - mse: 3.1255 - val_loss: 3.6132 - val_mse: 3.6132\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 2.8571 - mse: 2.8571 - val_loss: 3.3385 - val_mse: 3.3385\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 2.6667 - mse: 2.6667 - val_loss: 3.0423 - val_mse: 3.0423\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 2.4662 - mse: 2.4662 - val_loss: 2.8359 - val_mse: 2.8359\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 2.3248 - mse: 2.3248 - val_loss: 2.6702 - val_mse: 2.6702\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 2.2055 - mse: 2.2055 - val_loss: 2.5157 - val_mse: 2.5157\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 2.0822 - mse: 2.0822 - val_loss: 2.2644 - val_mse: 2.2644\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 1.9113 - mse: 1.9113 - val_loss: 2.1061 - val_mse: 2.1061\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1.7998 - mse: 1.7998 - val_loss: 1.9873 - val_mse: 1.9873\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.7037 - mse: 1.7037 - val_loss: 1.8452 - val_mse: 1.8452\n",
      "INFO:tensorflow:Assets written to: out/111-model-ntrain=100-sigma=0.0-epochs=10.tf/assets\n",
      "Epoch 1/55\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 1.5991 - mse: 1.5991 - val_loss: 1.6920 - val_mse: 1.6920\n",
      "Epoch 2/55\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.4908 - mse: 1.4908 - val_loss: 1.5875 - val_mse: 1.5875\n",
      "Epoch 3/55\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 1.4118 - mse: 1.4118 - val_loss: 1.4692 - val_mse: 1.4692\n",
      "Epoch 4/55\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.3270 - mse: 1.3270 - val_loss: 1.3886 - val_mse: 1.3886\n",
      "Epoch 5/55\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 1.2652 - mse: 1.2652 - val_loss: 1.3236 - val_mse: 1.3236\n",
      "Epoch 6/55\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.2100 - mse: 1.2100 - val_loss: 1.2584 - val_mse: 1.2584\n",
      "Epoch 7/55\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.1474 - mse: 1.1474 - val_loss: 1.1476 - val_mse: 1.1476\n",
      "Epoch 8/55\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.0683 - mse: 1.0683 - val_loss: 1.0795 - val_mse: 1.0795\n",
      "Epoch 9/55\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.0149 - mse: 1.0149 - val_loss: 1.0270 - val_mse: 1.0270\n",
      "Epoch 10/55\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.9641 - mse: 0.9641 - val_loss: 0.9624 - val_mse: 0.9624\n",
      "Epoch 11/55\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.9108 - mse: 0.9108 - val_loss: 0.9065 - val_mse: 0.9065\n",
      "Epoch 12/55\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.8656 - mse: 0.8656 - val_loss: 0.8236 - val_mse: 0.8236\n",
      "Epoch 13/55\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.8034 - mse: 0.8034 - val_loss: 0.7824 - val_mse: 0.7824\n",
      "Epoch 14/55\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.7629 - mse: 0.7629 - val_loss: 0.7512 - val_mse: 0.7512\n",
      "Epoch 15/55\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.7279 - mse: 0.7279 - val_loss: 0.7113 - val_mse: 0.7113\n",
      "Epoch 16/55\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6908 - mse: 0.6908 - val_loss: 0.6791 - val_mse: 0.6791\n",
      "Epoch 17/55\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.6565 - mse: 0.6565 - val_loss: 0.6389 - val_mse: 0.6389\n",
      "Epoch 18/55\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.6197 - mse: 0.6197 - val_loss: 0.6053 - val_mse: 0.6053\n",
      "Epoch 19/55\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.5900 - mse: 0.5900 - val_loss: 0.5657 - val_mse: 0.5657\n",
      "Epoch 20/55\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.5553 - mse: 0.5553 - val_loss: 0.5320 - val_mse: 0.5320\n",
      "Epoch 21/55\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.5239 - mse: 0.5239 - val_loss: 0.5049 - val_mse: 0.5049\n",
      "Epoch 22/55\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.4979 - mse: 0.4979 - val_loss: 0.4818 - val_mse: 0.4818\n",
      "Epoch 23/55\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.4763 - mse: 0.4763 - val_loss: 0.4587 - val_mse: 0.4587\n",
      "Epoch 24/55\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.4536 - mse: 0.4536 - val_loss: 0.4341 - val_mse: 0.4341\n",
      "Epoch 25/55\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.4277 - mse: 0.4277 - val_loss: 0.4106 - val_mse: 0.4106\n",
      "Epoch 26/55\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.4058 - mse: 0.4058 - val_loss: 0.3806 - val_mse: 0.3806\n",
      "Epoch 27/55\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.3800 - mse: 0.3800 - val_loss: 0.3593 - val_mse: 0.3593\n",
      "Epoch 28/55\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.3593 - mse: 0.3593 - val_loss: 0.3406 - val_mse: 0.3406\n",
      "Epoch 29/55\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.3417 - mse: 0.3417 - val_loss: 0.3169 - val_mse: 0.3169\n",
      "Epoch 30/55\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.3205 - mse: 0.3205 - val_loss: 0.2986 - val_mse: 0.2986\n",
      "Epoch 31/55\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.3015 - mse: 0.3015 - val_loss: 0.2829 - val_mse: 0.2829\n",
      "Epoch 32/55\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.2875 - mse: 0.2875 - val_loss: 0.2669 - val_mse: 0.2669\n",
      "Epoch 33/55\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.2726 - mse: 0.2726 - val_loss: 0.2552 - val_mse: 0.2552\n",
      "Epoch 34/55\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.2598 - mse: 0.2598 - val_loss: 0.2447 - val_mse: 0.2447\n",
      "Epoch 35/55\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.2469 - mse: 0.2469 - val_loss: 0.2331 - val_mse: 0.2331\n",
      "Epoch 36/55\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.2366 - mse: 0.2366 - val_loss: 0.2231 - val_mse: 0.2231\n",
      "Epoch 37/55\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.2254 - mse: 0.2254 - val_loss: 0.2112 - val_mse: 0.2112\n",
      "Epoch 38/55\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.2148 - mse: 0.2148 - val_loss: 0.1951 - val_mse: 0.1951\n",
      "Epoch 39/55\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.2020 - mse: 0.2020 - val_loss: 0.1831 - val_mse: 0.1831\n",
      "Epoch 40/55\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.1908 - mse: 0.1908 - val_loss: 0.1746 - val_mse: 0.1746\n",
      "Epoch 41/55\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.1820 - mse: 0.1820 - val_loss: 0.1638 - val_mse: 0.1638\n",
      "Epoch 42/55\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.1714 - mse: 0.1714 - val_loss: 0.1521 - val_mse: 0.1521\n",
      "Epoch 43/55\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.1612 - mse: 0.1612 - val_loss: 0.1431 - val_mse: 0.1431\n",
      "Epoch 44/55\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.1530 - mse: 0.1530 - val_loss: 0.1350 - val_mse: 0.1350\n",
      "Epoch 45/55\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.1442 - mse: 0.1442 - val_loss: 0.1287 - val_mse: 0.1287\n",
      "Epoch 46/55\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.1368 - mse: 0.1368 - val_loss: 0.1220 - val_mse: 0.1220\n",
      "Epoch 47/55\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.1296 - mse: 0.1296 - val_loss: 0.1171 - val_mse: 0.1171\n",
      "Epoch 48/55\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.1226 - mse: 0.1226 - val_loss: 0.1107 - val_mse: 0.1107\n",
      "Epoch 49/55\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.1157 - mse: 0.1157 - val_loss: 0.1059 - val_mse: 0.1059\n",
      "Epoch 50/55\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.1103 - mse: 0.1103 - val_loss: 0.1005 - val_mse: 0.1005\n",
      "Epoch 51/55\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.1043 - mse: 0.1043 - val_loss: 0.0948 - val_mse: 0.0948\n",
      "Epoch 52/55\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.0989 - mse: 0.0989 - val_loss: 0.0911 - val_mse: 0.0911\n",
      "Epoch 53/55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 25ms/step - loss: 0.0942 - mse: 0.0942 - val_loss: 0.0866 - val_mse: 0.0866\n",
      "Epoch 54/55\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.0896 - mse: 0.0896 - val_loss: 0.0828 - val_mse: 0.0828\n",
      "Epoch 55/55\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0853 - mse: 0.0853 - val_loss: 0.0778 - val_mse: 0.0778\n",
      "INFO:tensorflow:Assets written to: out/111-model-ntrain=100-sigma=0.0-epochs=55.tf/assets\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.0806 - mse: 0.0806 - val_loss: 0.0728 - val_mse: 0.0728\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.0763 - mse: 0.0763 - val_loss: 0.0693 - val_mse: 0.0693\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.0728 - mse: 0.0728 - val_loss: 0.0652 - val_mse: 0.0652\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.0692 - mse: 0.0692 - val_loss: 0.0624 - val_mse: 0.0624\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.0662 - mse: 0.0662 - val_loss: 0.0601 - val_mse: 0.0601\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.0634 - mse: 0.0634 - val_loss: 0.0574 - val_mse: 0.0574\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.0600 - mse: 0.0600 - val_loss: 0.0532 - val_mse: 0.0532\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.0565 - mse: 0.0565 - val_loss: 0.0505 - val_mse: 0.0505\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.0539 - mse: 0.0539 - val_loss: 0.0484 - val_mse: 0.0484\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.0511 - mse: 0.0511 - val_loss: 0.0457 - val_mse: 0.0457\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.0484 - mse: 0.0484 - val_loss: 0.0434 - val_mse: 0.0434\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.0462 - mse: 0.0462 - val_loss: 0.0399 - val_mse: 0.0399\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.0433 - mse: 0.0433 - val_loss: 0.0381 - val_mse: 0.0381\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.0410 - mse: 0.0410 - val_loss: 0.0367 - val_mse: 0.0367\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.0390 - mse: 0.0390 - val_loss: 0.0349 - val_mse: 0.0349\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.0370 - mse: 0.0370 - val_loss: 0.0334 - val_mse: 0.0334\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.0351 - mse: 0.0351 - val_loss: 0.0316 - val_mse: 0.0316\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.0331 - mse: 0.0331 - val_loss: 0.0301 - val_mse: 0.0301\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.0316 - mse: 0.0316 - val_loss: 0.0283 - val_mse: 0.0283\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.0298 - mse: 0.0298 - val_loss: 0.0267 - val_mse: 0.0267\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.0281 - mse: 0.0281 - val_loss: 0.0254 - val_mse: 0.0254\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.0267 - mse: 0.0267 - val_loss: 0.0244 - val_mse: 0.0244\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.0256 - mse: 0.0256 - val_loss: 0.0233 - val_mse: 0.0233\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.0243 - mse: 0.0243 - val_loss: 0.0221 - val_mse: 0.0221\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.0229 - mse: 0.0229 - val_loss: 0.0209 - val_mse: 0.0209\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0184 - val_mse: 0.0184\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0175 - val_mse: 0.0175\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0127 - val_mse: 0.0127\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0122 - val_mse: 0.0122\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0117 - val_mse: 0.0117\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.0121 - mse: 0.0121 - val_loss: 0.0111 - val_mse: 0.0111\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.0116 - mse: 0.0116 - val_loss: 0.0103 - val_mse: 0.0103\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.0109 - mse: 0.0109 - val_loss: 0.0096 - val_mse: 0.0096\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0092 - val_mse: 0.0092\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0080 - val_mse: 0.0080\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.0087 - mse: 0.0087 - val_loss: 0.0076 - val_mse: 0.0076\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.0083 - mse: 0.0083 - val_loss: 0.0072 - val_mse: 0.0072\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.0078 - mse: 0.0078 - val_loss: 0.0068 - val_mse: 0.0068\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0065 - val_mse: 0.0065\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0062 - val_mse: 0.0062\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0059 - val_mse: 0.0059\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0056 - val_mse: 0.0056\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0053 - val_mse: 0.0053\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0050 - val_mse: 0.0050\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0048 - val_mse: 0.0048\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0046 - val_mse: 0.0046\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.0048 - mse: 0.0048 - val_loss: 0.0044 - val_mse: 0.0044\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0041 - val_mse: 0.0041\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0040 - val_mse: 0.0040\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0037 - val_mse: 0.0037\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0035 - val_mse: 0.0035\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0033 - val_mse: 0.0033\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 25ms/step - loss: 0.0035 - mse: 0.0035 - val_loss: 0.0032 - val_mse: 0.0032\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.0033 - mse: 0.0033 - val_loss: 0.0030 - val_mse: 0.0030\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.0031 - mse: 0.0031 - val_loss: 0.0029 - val_mse: 0.0029\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.0030 - mse: 0.0030 - val_loss: 0.0028 - val_mse: 0.0028\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.0028 - mse: 0.0028 - val_loss: 0.0026 - val_mse: 0.0026\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 0.0024 - val_mse: 0.0024\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 0.0023 - val_mse: 0.0023\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 0.0022 - val_mse: 0.0022\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0021 - val_mse: 0.0021\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 0.0020 - val_mse: 0.0020\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0019 - val_mse: 0.0019\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0017 - val_mse: 0.0017\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0017 - val_mse: 0.0017\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0015 - val_mse: 0.0015\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0015 - val_mse: 0.0015\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0013 - val_mse: 0.0013\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0013 - val_mse: 0.0013\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0010 - val_mse: 0.0010\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 9.6990e-04 - val_mse: 9.6990e-04\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.0010 - mse: 0.0010 - val_loss: 9.2053e-04 - val_mse: 9.2053e-04\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 9.4974e-04 - mse: 9.4974e-04 - val_loss: 8.8502e-04 - val_mse: 8.8502e-04\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 8.9782e-04 - mse: 8.9782e-04 - val_loss: 8.3475e-04 - val_mse: 8.3475e-04\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 8.5033e-04 - mse: 8.5033e-04 - val_loss: 7.7758e-04 - val_mse: 7.7758e-04\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 7.9344e-04 - mse: 7.9344e-04 - val_loss: 7.4126e-04 - val_mse: 7.4126e-04\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 7.5367e-04 - mse: 7.5367e-04 - val_loss: 7.0839e-04 - val_mse: 7.0839e-04\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 7.1312e-04 - mse: 7.1312e-04 - val_loss: 6.7930e-04 - val_mse: 6.7930e-04\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 6.8093e-04 - mse: 6.8093e-04 - val_loss: 6.5117e-04 - val_mse: 6.5117e-04\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 6.5124e-04 - mse: 6.5124e-04 - val_loss: 6.1906e-04 - val_mse: 6.1906e-04\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 6.2146e-04 - mse: 6.2146e-04 - val_loss: 5.9211e-04 - val_mse: 5.9211e-04\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 5.9009e-04 - mse: 5.9009e-04 - val_loss: 5.5294e-04 - val_mse: 5.5294e-04\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 5.5861e-04 - mse: 5.5861e-04 - val_loss: 5.2204e-04 - val_mse: 5.2204e-04\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 5.3172e-04 - mse: 5.3172e-04 - val_loss: 4.9594e-04 - val_mse: 4.9594e-04\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 5.0343e-04 - mse: 5.0343e-04 - val_loss: 4.7150e-04 - val_mse: 4.7150e-04\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 4.7659e-04 - mse: 4.7659e-04 - val_loss: 4.5217e-04 - val_mse: 4.5217e-04\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 4.5214e-04 - mse: 4.5214e-04 - val_loss: 4.2951e-04 - val_mse: 4.2951e-04\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 4.2780e-04 - mse: 4.2780e-04 - val_loss: 4.0929e-04 - val_mse: 4.0929e-04\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 4.0497e-04 - mse: 4.0497e-04 - val_loss: 3.9066e-04 - val_mse: 3.9066e-04\n",
      "INFO:tensorflow:Assets written to: out/111-model-ntrain=100-sigma=0.0-epochs=100.tf/assets\n",
      "\n",
      "Epoch 1/10\n",
      "4/4 [==============================] - 1s 90ms/step - loss: 3.8336 - mse: 3.8336 - val_loss: 7.8146 - val_mse: 7.8146\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 3.5570 - mse: 3.5570 - val_loss: 7.4819 - val_mse: 7.4819\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 3.3799 - mse: 3.3799 - val_loss: 7.0930 - val_mse: 7.0930\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 3.1847 - mse: 3.1847 - val_loss: 6.8596 - val_mse: 6.8596\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 3.0651 - mse: 3.0651 - val_loss: 6.6436 - val_mse: 6.6436\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 2.9526 - mse: 2.9526 - val_loss: 6.4350 - val_mse: 6.4350\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 2.8420 - mse: 2.8420 - val_loss: 6.0758 - val_mse: 6.0758\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 2.6713 - mse: 2.6713 - val_loss: 5.8677 - val_mse: 5.8677\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 2.5684 - mse: 2.5684 - val_loss: 5.7128 - val_mse: 5.7128\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 2.4830 - mse: 2.4830 - val_loss: 5.5462 - val_mse: 5.5462\n",
      "INFO:tensorflow:Assets written to: out/111-model-ntrain=100-sigma=1.0-epochs=10.tf/assets\n",
      "Epoch 1/55\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 2.3975 - mse: 2.3975 - val_loss: 5.3066 - val_mse: 5.3066\n",
      "Epoch 2/55\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 2.2865 - mse: 2.2865 - val_loss: 5.1675 - val_mse: 5.1675\n",
      "Epoch 3/55\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 2.2174 - mse: 2.2174 - val_loss: 4.9899 - val_mse: 4.9899\n",
      "Epoch 4/55\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 2.1395 - mse: 2.1395 - val_loss: 4.8950 - val_mse: 4.8950\n",
      "Epoch 5/55\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 2.0910 - mse: 2.0910 - val_loss: 4.7995 - val_mse: 4.7995\n",
      "Epoch 6/55\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 2.0415 - mse: 2.0415 - val_loss: 4.7026 - val_mse: 4.7026\n",
      "Epoch 7/55\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.9919 - mse: 1.9919 - val_loss: 4.5153 - val_mse: 4.5153\n",
      "Epoch 8/55\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.9142 - mse: 1.9142 - val_loss: 4.4144 - val_mse: 4.4144\n",
      "Epoch 9/55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 24ms/step - loss: 1.8657 - mse: 1.8657 - val_loss: 4.3383 - val_mse: 4.3383\n",
      "Epoch 10/55\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.8214 - mse: 1.8214 - val_loss: 4.2587 - val_mse: 4.2587\n",
      "Epoch 11/55\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.7819 - mse: 1.7819 - val_loss: 4.1976 - val_mse: 4.1976\n",
      "Epoch 12/55\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.7482 - mse: 1.7482 - val_loss: 4.0283 - val_mse: 4.0283\n",
      "Epoch 13/55\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.6797 - mse: 1.6797 - val_loss: 3.9714 - val_mse: 3.9714\n",
      "Epoch 14/55\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.6500 - mse: 1.6500 - val_loss: 3.9358 - val_mse: 3.9358\n",
      "Epoch 15/55\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.6190 - mse: 1.6190 - val_loss: 3.8736 - val_mse: 3.8736\n",
      "Epoch 16/55\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1.5896 - mse: 1.5896 - val_loss: 3.7920 - val_mse: 3.7920\n",
      "Epoch 17/55\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.5555 - mse: 1.5555 - val_loss: 3.7175 - val_mse: 3.7175\n",
      "Epoch 18/55\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1.5251 - mse: 1.5251 - val_loss: 3.6481 - val_mse: 3.6481\n",
      "Epoch 19/55\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.4951 - mse: 1.4951 - val_loss: 3.5570 - val_mse: 3.5570\n",
      "Epoch 20/55\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 1.4592 - mse: 1.4592 - val_loss: 3.4948 - val_mse: 3.4948\n",
      "Epoch 21/55\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1.4338 - mse: 1.4338 - val_loss: 3.4622 - val_mse: 3.4622\n",
      "Epoch 22/55\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1.4152 - mse: 1.4152 - val_loss: 3.4121 - val_mse: 3.4121\n",
      "Epoch 23/55\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 1.3948 - mse: 1.3948 - val_loss: 3.3801 - val_mse: 3.3801\n",
      "Epoch 24/55\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.3765 - mse: 1.3765 - val_loss: 3.3344 - val_mse: 3.3344\n",
      "Epoch 25/55\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.3594 - mse: 1.3594 - val_loss: 3.3006 - val_mse: 3.3006\n",
      "Epoch 26/55\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 1.3430 - mse: 1.3430 - val_loss: 3.2513 - val_mse: 3.2513\n",
      "Epoch 27/55\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.3257 - mse: 1.3257 - val_loss: 3.2024 - val_mse: 3.2024\n",
      "Epoch 28/55\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.3094 - mse: 1.3094 - val_loss: 3.1747 - val_mse: 3.1747\n",
      "Epoch 29/55\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.2971 - mse: 1.2971 - val_loss: 3.1162 - val_mse: 3.1162\n",
      "Epoch 30/55\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.2760 - mse: 1.2760 - val_loss: 3.0693 - val_mse: 3.0693\n",
      "Epoch 31/55\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.2575 - mse: 1.2575 - val_loss: 3.0314 - val_mse: 3.0314\n",
      "Epoch 32/55\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.2456 - mse: 1.2456 - val_loss: 3.0104 - val_mse: 3.0104\n",
      "Epoch 33/55\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.2383 - mse: 1.2383 - val_loss: 2.9835 - val_mse: 2.9835\n",
      "Epoch 34/55\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.2235 - mse: 1.2235 - val_loss: 2.9528 - val_mse: 2.9528\n",
      "Epoch 35/55\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.2100 - mse: 1.2100 - val_loss: 2.9282 - val_mse: 2.9282\n",
      "Epoch 36/55\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.2015 - mse: 1.2015 - val_loss: 2.8999 - val_mse: 2.8999\n",
      "Epoch 37/55\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.1934 - mse: 1.1934 - val_loss: 2.8537 - val_mse: 2.8537\n",
      "Epoch 38/55\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.1812 - mse: 1.1812 - val_loss: 2.8169 - val_mse: 2.8169\n",
      "Epoch 39/55\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.1697 - mse: 1.1697 - val_loss: 2.7998 - val_mse: 2.7998\n",
      "Epoch 40/55\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1.1632 - mse: 1.1632 - val_loss: 2.7804 - val_mse: 2.7804\n",
      "Epoch 41/55\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1.1553 - mse: 1.1553 - val_loss: 2.7778 - val_mse: 2.7778\n",
      "Epoch 42/55\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.1483 - mse: 1.1483 - val_loss: 2.7438 - val_mse: 2.7438\n",
      "Epoch 43/55\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.1391 - mse: 1.1391 - val_loss: 2.7152 - val_mse: 2.7152\n",
      "Epoch 44/55\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.1320 - mse: 1.1320 - val_loss: 2.6919 - val_mse: 2.6919\n",
      "Epoch 45/55\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1.1232 - mse: 1.1232 - val_loss: 2.6708 - val_mse: 2.6708\n",
      "Epoch 46/55\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1.1181 - mse: 1.1181 - val_loss: 2.6554 - val_mse: 2.6554\n",
      "Epoch 47/55\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.1127 - mse: 1.1127 - val_loss: 2.6365 - val_mse: 2.6365\n",
      "Epoch 48/55\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.1072 - mse: 1.1072 - val_loss: 2.6250 - val_mse: 2.6250\n",
      "Epoch 49/55\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1.1026 - mse: 1.1026 - val_loss: 2.6123 - val_mse: 2.6123\n",
      "Epoch 50/55\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1.0961 - mse: 1.0961 - val_loss: 2.6145 - val_mse: 2.6145\n",
      "Epoch 51/55\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.0938 - mse: 1.0938 - val_loss: 2.5935 - val_mse: 2.5935\n",
      "Epoch 52/55\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1.0917 - mse: 1.0917 - val_loss: 2.5905 - val_mse: 2.5905\n",
      "Epoch 53/55\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.0877 - mse: 1.0877 - val_loss: 2.5658 - val_mse: 2.5658\n",
      "Epoch 54/55\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.0812 - mse: 1.0812 - val_loss: 2.5519 - val_mse: 2.5519\n",
      "Epoch 55/55\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1.0770 - mse: 1.0770 - val_loss: 2.5324 - val_mse: 2.5324\n",
      "INFO:tensorflow:Assets written to: out/111-model-ntrain=100-sigma=1.0-epochs=55.tf/assets\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 1.0712 - mse: 1.0712 - val_loss: 2.5066 - val_mse: 2.5066\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.0659 - mse: 1.0659 - val_loss: 2.5007 - val_mse: 2.5007\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.0627 - mse: 1.0627 - val_loss: 2.4856 - val_mse: 2.4856\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.0604 - mse: 1.0604 - val_loss: 2.4870 - val_mse: 2.4870\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.0581 - mse: 1.0581 - val_loss: 2.4808 - val_mse: 2.4808\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1.0551 - mse: 1.0551 - val_loss: 2.4746 - val_mse: 2.4746\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.0537 - mse: 1.0537 - val_loss: 2.4488 - val_mse: 2.4488\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.0506 - mse: 1.0506 - val_loss: 2.4410 - val_mse: 2.4410\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.0470 - mse: 1.0470 - val_loss: 2.4357 - val_mse: 2.4357\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1.0439 - mse: 1.0439 - val_loss: 2.4365 - val_mse: 2.4365\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.0431 - mse: 1.0431 - val_loss: 2.4428 - val_mse: 2.4428\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.0419 - mse: 1.0419 - val_loss: 2.4088 - val_mse: 2.4088\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.0366 - mse: 1.0366 - val_loss: 2.4079 - val_mse: 2.4079\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.0358 - mse: 1.0358 - val_loss: 2.4108 - val_mse: 2.4108\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.0335 - mse: 1.0335 - val_loss: 2.4064 - val_mse: 2.4064\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 28ms/step - loss: 1.0329 - mse: 1.0329 - val_loss: 2.3853 - val_mse: 2.3853\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.0301 - mse: 1.0301 - val_loss: 2.3743 - val_mse: 2.3743\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.0283 - mse: 1.0283 - val_loss: 2.3608 - val_mse: 2.3608\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.0260 - mse: 1.0260 - val_loss: 2.3390 - val_mse: 2.3390\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.0234 - mse: 1.0234 - val_loss: 2.3299 - val_mse: 2.3299\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.0230 - mse: 1.0230 - val_loss: 2.3337 - val_mse: 2.3337\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.0215 - mse: 1.0215 - val_loss: 2.3234 - val_mse: 2.3234\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1.0201 - mse: 1.0201 - val_loss: 2.3243 - val_mse: 2.3243\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.0198 - mse: 1.0198 - val_loss: 2.3184 - val_mse: 2.3184\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.0192 - mse: 1.0192 - val_loss: 2.3191 - val_mse: 2.3191\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.0184 - mse: 1.0184 - val_loss: 2.3164 - val_mse: 2.3164\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.0188 - mse: 1.0188 - val_loss: 2.3061 - val_mse: 2.3061\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.0182 - mse: 1.0182 - val_loss: 2.3071 - val_mse: 2.3071\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.0182 - mse: 1.0182 - val_loss: 2.2929 - val_mse: 2.2929\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1.0161 - mse: 1.0161 - val_loss: 2.2810 - val_mse: 2.2810\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1.0144 - mse: 1.0144 - val_loss: 2.2727 - val_mse: 2.2727\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.0140 - mse: 1.0140 - val_loss: 2.2764 - val_mse: 2.2764\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.0147 - mse: 1.0147 - val_loss: 2.2714 - val_mse: 2.2714\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.0132 - mse: 1.0132 - val_loss: 2.2623 - val_mse: 2.2623\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.0117 - mse: 1.0117 - val_loss: 2.2591 - val_mse: 2.2591\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.0111 - mse: 1.0111 - val_loss: 2.2514 - val_mse: 2.2514\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.0120 - mse: 1.0120 - val_loss: 2.2337 - val_mse: 2.2337\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.0101 - mse: 1.0101 - val_loss: 2.2275 - val_mse: 2.2275\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.0093 - mse: 1.0093 - val_loss: 2.2309 - val_mse: 2.2309\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.0094 - mse: 1.0094 - val_loss: 2.2282 - val_mse: 2.2282\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1.0091 - mse: 1.0091 - val_loss: 2.2412 - val_mse: 2.2412\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.0083 - mse: 1.0083 - val_loss: 2.2329 - val_mse: 2.2329\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.0079 - mse: 1.0079 - val_loss: 2.2251 - val_mse: 2.2251\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.0079 - mse: 1.0079 - val_loss: 2.2197 - val_mse: 2.2197\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.0074 - mse: 1.0074 - val_loss: 2.2132 - val_mse: 2.2132\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1.0067 - mse: 1.0067 - val_loss: 2.2121 - val_mse: 2.2121\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.0064 - mse: 1.0064 - val_loss: 2.2055 - val_mse: 2.2055\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.0065 - mse: 1.0065 - val_loss: 2.2070 - val_mse: 2.2070\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.0063 - mse: 1.0063 - val_loss: 2.2052 - val_mse: 2.2052\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.0052 - mse: 1.0052 - val_loss: 2.2163 - val_mse: 2.2163\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.0056 - mse: 1.0056 - val_loss: 2.2100 - val_mse: 2.2100\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1.0067 - mse: 1.0067 - val_loss: 2.2143 - val_mse: 2.2143\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.0066 - mse: 1.0066 - val_loss: 2.2033 - val_mse: 2.2033\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.0051 - mse: 1.0051 - val_loss: 2.1993 - val_mse: 2.1993\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.0049 - mse: 1.0049 - val_loss: 2.1934 - val_mse: 2.1934\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.0038 - mse: 1.0038 - val_loss: 2.1879 - val_mse: 2.1879\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.0047 - mse: 1.0047 - val_loss: 2.1966 - val_mse: 2.1966\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.0045 - mse: 1.0045 - val_loss: 2.1802 - val_mse: 2.1802\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.0035 - mse: 1.0035 - val_loss: 2.1904 - val_mse: 2.1904\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.0033 - mse: 1.0033 - val_loss: 2.1880 - val_mse: 2.1880\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.0027 - mse: 1.0027 - val_loss: 2.1888 - val_mse: 2.1888\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 1.0033 - mse: 1.0033 - val_loss: 2.1944 - val_mse: 2.1944\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.0031 - mse: 1.0031 - val_loss: 2.1876 - val_mse: 2.1876\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.0025 - mse: 1.0025 - val_loss: 2.1744 - val_mse: 2.1744\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1.0027 - mse: 1.0027 - val_loss: 2.1709 - val_mse: 2.1709\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.0024 - mse: 1.0024 - val_loss: 2.1682 - val_mse: 2.1682\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1.0023 - mse: 1.0023 - val_loss: 2.1641 - val_mse: 2.1641\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1.0026 - mse: 1.0026 - val_loss: 2.1621 - val_mse: 2.1621\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.0012 - mse: 1.0012 - val_loss: 2.1554 - val_mse: 2.1554\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.0016 - mse: 1.0016 - val_loss: 2.1703 - val_mse: 2.1703\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.0015 - mse: 1.0015 - val_loss: 2.1722 - val_mse: 2.1722\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1.0011 - mse: 1.0011 - val_loss: 2.1662 - val_mse: 2.1662\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.0023 - mse: 1.0023 - val_loss: 2.1616 - val_mse: 2.1616\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.0006 - mse: 1.0006 - val_loss: 2.1536 - val_mse: 2.1536\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.0012 - mse: 1.0012 - val_loss: 2.1521 - val_mse: 2.1521\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.0018 - mse: 1.0018 - val_loss: 2.1478 - val_mse: 2.1478\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.0005 - mse: 1.0005 - val_loss: 2.1503 - val_mse: 2.1503\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 28ms/step - loss: 1.0001 - mse: 1.0001 - val_loss: 2.1549 - val_mse: 2.1549\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.0000 - mse: 1.0000 - val_loss: 2.1499 - val_mse: 2.1499\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.0000 - mse: 1.0000 - val_loss: 2.1474 - val_mse: 2.1474\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.9999 - mse: 0.9999 - val_loss: 2.1515 - val_mse: 2.1515\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.0012 - mse: 1.0012 - val_loss: 2.1562 - val_mse: 2.1562\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.0007 - mse: 1.0007 - val_loss: 2.1509 - val_mse: 2.1509\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.0007 - mse: 1.0007 - val_loss: 2.1495 - val_mse: 2.1495\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.0000 - mse: 1.0000 - val_loss: 2.1402 - val_mse: 2.1402\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.9995 - mse: 0.9995 - val_loss: 2.1232 - val_mse: 2.1232\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.9998 - mse: 0.9998 - val_loss: 2.1275 - val_mse: 2.1275\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.9993 - mse: 0.9993 - val_loss: 2.1278 - val_mse: 2.1278\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.9994 - mse: 0.9994 - val_loss: 2.1200 - val_mse: 2.1200\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.9989 - mse: 0.9989 - val_loss: 2.1208 - val_mse: 2.1208\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.9997 - mse: 0.9997 - val_loss: 2.1138 - val_mse: 2.1138\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.9987 - mse: 0.9987 - val_loss: 2.1201 - val_mse: 2.1201\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.9993 - mse: 0.9993 - val_loss: 2.1160 - val_mse: 2.1160\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.9995 - mse: 0.9995 - val_loss: 2.1230 - val_mse: 2.1230\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.9991 - mse: 0.9991 - val_loss: 2.1218 - val_mse: 2.1218\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.9989 - mse: 0.9989 - val_loss: 2.1197 - val_mse: 2.1197\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.9996 - mse: 0.9996 - val_loss: 2.1115 - val_mse: 2.1115\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.9989 - mse: 0.9989 - val_loss: 2.1161 - val_mse: 2.1161\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.9996 - mse: 0.9996 - val_loss: 2.1131 - val_mse: 2.1131\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.9993 - mse: 0.9993 - val_loss: 2.1167 - val_mse: 2.1167\n",
      "INFO:tensorflow:Assets written to: out/111-model-ntrain=100-sigma=1.0-epochs=100.tf/assets\n",
      "\n",
      "Epoch 1/10\n",
      "4/4 [==============================] - 1s 92ms/step - loss: 101.9755 - mse: 101.9755 - val_loss: 222.4313 - val_mse: 222.4313\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 101.5139 - mse: 101.5139 - val_loss: 222.0269 - val_mse: 222.0269\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 101.3854 - mse: 101.3854 - val_loss: 220.8467 - val_mse: 220.8467\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 101.0899 - mse: 101.0899 - val_loss: 221.2065 - val_mse: 221.2065\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 101.1969 - mse: 101.1969 - val_loss: 220.7112 - val_mse: 220.7112\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 101.0738 - mse: 101.0738 - val_loss: 220.2231 - val_mse: 220.2231\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 100.8095 - mse: 100.8095 - val_loss: 218.5506 - val_mse: 218.5506\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 100.6577 - mse: 100.6577 - val_loss: 218.1870 - val_mse: 218.1870\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 100.5180 - mse: 100.5180 - val_loss: 218.0412 - val_mse: 218.0412\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 100.5487 - mse: 100.5487 - val_loss: 218.6157 - val_mse: 218.6157\n",
      "INFO:tensorflow:Assets written to: out/111-model-ntrain=100-sigma=10.0-epochs=10.tf/assets\n",
      "Epoch 1/55\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 100.6738 - mse: 100.6738 - val_loss: 217.1265 - val_mse: 217.1265\n",
      "Epoch 2/55\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 100.4559 - mse: 100.4559 - val_loss: 217.1035 - val_mse: 217.1035\n",
      "Epoch 3/55\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 100.4356 - mse: 100.4356 - val_loss: 216.3938 - val_mse: 216.3938\n",
      "Epoch 4/55\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 100.3159 - mse: 100.3159 - val_loss: 216.9909 - val_mse: 216.9909\n",
      "Epoch 5/55\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 100.4364 - mse: 100.4364 - val_loss: 216.7792 - val_mse: 216.7792\n",
      "Epoch 6/55\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 100.3931 - mse: 100.3931 - val_loss: 216.5909 - val_mse: 216.5909\n",
      "Epoch 7/55\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 100.2540 - mse: 100.2540 - val_loss: 215.2899 - val_mse: 215.2899\n",
      "Epoch 8/55\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 100.2263 - mse: 100.2263 - val_loss: 215.1503 - val_mse: 215.1503\n",
      "Epoch 9/55\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 100.1269 - mse: 100.1269 - val_loss: 215.1687 - val_mse: 215.1687\n",
      "Epoch 10/55\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 100.1726 - mse: 100.1726 - val_loss: 215.8844 - val_mse: 215.8844\n",
      "Epoch 11/55\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 100.3309 - mse: 100.3309 - val_loss: 216.9709 - val_mse: 216.9709\n",
      "Epoch 12/55\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 100.3853 - mse: 100.3853 - val_loss: 214.9936 - val_mse: 214.9936\n",
      "Epoch 13/55\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 100.2148 - mse: 100.2148 - val_loss: 215.3469 - val_mse: 215.3469\n",
      "Epoch 14/55\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 100.2502 - mse: 100.2502 - val_loss: 216.0306 - val_mse: 216.0306\n",
      "Epoch 15/55\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 100.4405 - mse: 100.4405 - val_loss: 216.1193 - val_mse: 216.1193\n",
      "Epoch 16/55\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 100.5050 - mse: 100.5050 - val_loss: 214.5954 - val_mse: 214.5954\n",
      "Epoch 17/55\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 100.2664 - mse: 100.2664 - val_loss: 214.1301 - val_mse: 214.1301\n",
      "Epoch 18/55\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 100.0695 - mse: 100.0695 - val_loss: 213.4167 - val_mse: 213.4167\n",
      "Epoch 19/55\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 100.0451 - mse: 100.0451 - val_loss: 212.1247 - val_mse: 212.1247\n",
      "Epoch 20/55\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 100.0193 - mse: 100.0193 - val_loss: 211.8398 - val_mse: 211.8398\n",
      "Epoch 21/55\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 100.0865 - mse: 100.0865 - val_loss: 212.5782 - val_mse: 212.5782\n",
      "Epoch 22/55\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 99.9759 - mse: 99.9759 - val_loss: 212.0356 - val_mse: 212.0356\n",
      "Epoch 23/55\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 99.9612 - mse: 99.9612 - val_loss: 212.5166 - val_mse: 212.5166\n",
      "Epoch 24/55\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 100.0859 - mse: 100.0859 - val_loss: 212.4057 - val_mse: 212.4057\n",
      "Epoch 25/55\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 99.9559 - mse: 99.9559 - val_loss: 212.9015 - val_mse: 212.9015\n",
      "Epoch 26/55\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 99.9518 - mse: 99.9518 - val_loss: 213.2540 - val_mse: 213.2540\n",
      "Epoch 27/55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 23ms/step - loss: 99.9944 - mse: 99.9944 - val_loss: 212.7554 - val_mse: 212.7554\n",
      "Epoch 28/55\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 99.9574 - mse: 99.9574 - val_loss: 213.2334 - val_mse: 213.2334\n",
      "Epoch 29/55\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 100.0014 - mse: 100.0014 - val_loss: 212.5083 - val_mse: 212.5083\n",
      "Epoch 30/55\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 99.9283 - mse: 99.9283 - val_loss: 211.8820 - val_mse: 211.8820\n",
      "Epoch 31/55\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 99.8838 - mse: 99.8838 - val_loss: 211.5043 - val_mse: 211.5043\n",
      "Epoch 32/55\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 99.9065 - mse: 99.9065 - val_loss: 212.2136 - val_mse: 212.2136\n",
      "Epoch 33/55\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 99.9298 - mse: 99.9298 - val_loss: 212.0685 - val_mse: 212.0685\n",
      "Epoch 34/55\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 99.9659 - mse: 99.9659 - val_loss: 211.5256 - val_mse: 211.5256\n",
      "Epoch 35/55\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 99.9140 - mse: 99.9140 - val_loss: 211.5440 - val_mse: 211.5440\n",
      "Epoch 36/55\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 99.8946 - mse: 99.8946 - val_loss: 211.1140 - val_mse: 211.1140\n",
      "Epoch 37/55\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 100.0370 - mse: 100.0370 - val_loss: 209.8510 - val_mse: 209.8510\n",
      "Epoch 38/55\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 99.9142 - mse: 99.9142 - val_loss: 209.7775 - val_mse: 209.7775\n",
      "Epoch 39/55\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 99.9117 - mse: 99.9117 - val_loss: 210.4513 - val_mse: 210.4513\n",
      "Epoch 40/55\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 99.9292 - mse: 99.9292 - val_loss: 210.4706 - val_mse: 210.4706\n",
      "Epoch 41/55\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 99.9592 - mse: 99.9592 - val_loss: 212.0145 - val_mse: 212.0145\n",
      "Epoch 42/55\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 99.8901 - mse: 99.8901 - val_loss: 211.6632 - val_mse: 211.6632\n",
      "Epoch 43/55\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 99.9111 - mse: 99.9111 - val_loss: 211.2693 - val_mse: 211.2693\n",
      "Epoch 44/55\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 99.9642 - mse: 99.9642 - val_loss: 211.0781 - val_mse: 211.0781\n",
      "Epoch 45/55\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 99.9969 - mse: 99.9969 - val_loss: 210.7046 - val_mse: 210.7046\n",
      "Epoch 46/55\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 99.9049 - mse: 99.9049 - val_loss: 210.8601 - val_mse: 210.8601\n",
      "Epoch 47/55\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 99.9015 - mse: 99.9015 - val_loss: 210.4314 - val_mse: 210.4314\n",
      "Epoch 48/55\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 99.9406 - mse: 99.9406 - val_loss: 210.8328 - val_mse: 210.8328\n",
      "Epoch 49/55\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 99.9219 - mse: 99.9219 - val_loss: 210.8692 - val_mse: 210.8692\n",
      "Epoch 50/55\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 99.8827 - mse: 99.8827 - val_loss: 212.1195 - val_mse: 212.1195\n",
      "Epoch 51/55\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 99.9005 - mse: 99.9005 - val_loss: 211.7884 - val_mse: 211.7884\n",
      "Epoch 52/55\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 99.9937 - mse: 99.9937 - val_loss: 212.3624 - val_mse: 212.3624\n",
      "Epoch 53/55\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 100.0252 - mse: 100.0252 - val_loss: 211.5480 - val_mse: 211.5480\n",
      "Epoch 54/55\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 99.9330 - mse: 99.9330 - val_loss: 211.3588 - val_mse: 211.3588\n",
      "Epoch 55/55\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 99.9466 - mse: 99.9466 - val_loss: 211.0573 - val_mse: 211.0573\n",
      "INFO:tensorflow:Assets written to: out/111-model-ntrain=100-sigma=10.0-epochs=55.tf/assets\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 99.9226 - mse: 99.9226 - val_loss: 210.3234 - val_mse: 210.3234\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 99.8950 - mse: 99.8950 - val_loss: 210.7274 - val_mse: 210.7274\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 99.8780 - mse: 99.8780 - val_loss: 210.6090 - val_mse: 210.6090\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 99.8992 - mse: 99.8992 - val_loss: 211.4519 - val_mse: 211.4519\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 99.9157 - mse: 99.9157 - val_loss: 211.5836 - val_mse: 211.5836\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 99.8972 - mse: 99.8972 - val_loss: 211.7831 - val_mse: 211.7831\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 99.8792 - mse: 99.8792 - val_loss: 210.9771 - val_mse: 210.9771\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 99.9733 - mse: 99.9733 - val_loss: 211.1202 - val_mse: 211.1202\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 99.8729 - mse: 99.8729 - val_loss: 211.3384 - val_mse: 211.3384\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 99.8862 - mse: 99.8862 - val_loss: 212.2218 - val_mse: 212.2218\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 99.9819 - mse: 99.9819 - val_loss: 213.4581 - val_mse: 213.4581\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 99.9861 - mse: 99.9861 - val_loss: 211.8792 - val_mse: 211.8792\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 99.9397 - mse: 99.9397 - val_loss: 212.4003 - val_mse: 212.4003\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 99.9706 - mse: 99.9706 - val_loss: 213.1411 - val_mse: 213.1411\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 100.0745 - mse: 100.0745 - val_loss: 213.3964 - val_mse: 213.3964\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 100.1594 - mse: 100.1594 - val_loss: 212.1329 - val_mse: 212.1329\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 100.0386 - mse: 100.0386 - val_loss: 211.8757 - val_mse: 211.8757\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 99.9131 - mse: 99.9131 - val_loss: 211.3216 - val_mse: 211.3216\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 99.9150 - mse: 99.9150 - val_loss: 210.2082 - val_mse: 210.2082\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 99.9316 - mse: 99.9316 - val_loss: 210.0558 - val_mse: 210.0558\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 100.0193 - mse: 100.0193 - val_loss: 210.8728 - val_mse: 210.8728\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 99.8975 - mse: 99.8975 - val_loss: 210.4440 - val_mse: 210.4440\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 99.9008 - mse: 99.9008 - val_loss: 210.9814 - val_mse: 210.9814\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 100.0044 - mse: 100.0044 - val_loss: 210.9790 - val_mse: 210.9790\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 99.9042 - mse: 99.9042 - val_loss: 211.5389 - val_mse: 211.5389\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 99.8912 - mse: 99.8912 - val_loss: 211.9785 - val_mse: 211.9785\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 99.9439 - mse: 99.9439 - val_loss: 211.5745 - val_mse: 211.5745\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 99.9300 - mse: 99.9300 - val_loss: 212.1045 - val_mse: 212.1045\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 99.9669 - mse: 99.9669 - val_loss: 211.4627 - val_mse: 211.4627\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 99.9085 - mse: 99.9085 - val_loss: 210.9032 - val_mse: 210.9032\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 24ms/step - loss: 99.8743 - mse: 99.8743 - val_loss: 210.5869 - val_mse: 210.5869\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 99.9044 - mse: 99.9044 - val_loss: 211.3402 - val_mse: 211.3402\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 99.9249 - mse: 99.9249 - val_loss: 211.2262 - val_mse: 211.2262\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 99.9525 - mse: 99.9525 - val_loss: 210.7267 - val_mse: 210.7267\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 99.9072 - mse: 99.9072 - val_loss: 210.7834 - val_mse: 210.7834\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 99.8882 - mse: 99.8882 - val_loss: 210.3935 - val_mse: 210.3935\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 100.0364 - mse: 100.0364 - val_loss: 209.1871 - val_mse: 209.1871\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 99.9291 - mse: 99.9291 - val_loss: 209.1511 - val_mse: 209.1511\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 99.9239 - mse: 99.9239 - val_loss: 209.8488 - val_mse: 209.8488\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 99.9346 - mse: 99.9346 - val_loss: 209.8933 - val_mse: 209.8933\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 99.9627 - mse: 99.9627 - val_loss: 211.4472 - val_mse: 211.4472\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 99.8800 - mse: 99.8800 - val_loss: 211.1302 - val_mse: 211.1302\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 99.9042 - mse: 99.9042 - val_loss: 210.7665 - val_mse: 210.7665\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 99.9601 - mse: 99.9601 - val_loss: 210.5970 - val_mse: 210.5970\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 99.9923 - mse: 99.9923 - val_loss: 210.2489 - val_mse: 210.2489\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 99.9048 - mse: 99.9048 - val_loss: 210.4229 - val_mse: 210.4229\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 99.9009 - mse: 99.9009 - val_loss: 210.0131 - val_mse: 210.0131\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 99.9429 - mse: 99.9429 - val_loss: 210.4292 - val_mse: 210.4292\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 99.9217 - mse: 99.9217 - val_loss: 210.4778 - val_mse: 210.4778\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 99.8809 - mse: 99.8809 - val_loss: 211.7357 - val_mse: 211.7357\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 99.8937 - mse: 99.8937 - val_loss: 211.4248 - val_mse: 211.4248\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 99.9894 - mse: 99.9894 - val_loss: 212.0059 - val_mse: 212.0059\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 100.0183 - mse: 100.0183 - val_loss: 211.2088 - val_mse: 211.2088\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 99.9289 - mse: 99.9289 - val_loss: 211.0313 - val_mse: 211.0313\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 99.9430 - mse: 99.9430 - val_loss: 210.7440 - val_mse: 210.7440\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 99.8865 - mse: 99.8865 - val_loss: 210.4281 - val_mse: 210.4281\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 99.9589 - mse: 99.9589 - val_loss: 211.4991 - val_mse: 211.4991\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 99.9569 - mse: 99.9569 - val_loss: 210.2065 - val_mse: 210.2065\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 99.9201 - mse: 99.9201 - val_loss: 211.3560 - val_mse: 211.3560\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 99.9144 - mse: 99.9144 - val_loss: 211.2750 - val_mse: 211.2750\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 99.8775 - mse: 99.8775 - val_loss: 211.5061 - val_mse: 211.5061\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 99.9210 - mse: 99.9210 - val_loss: 212.2308 - val_mse: 212.2308\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 99.9065 - mse: 99.9065 - val_loss: 211.7378 - val_mse: 211.7378\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 99.8945 - mse: 99.8945 - val_loss: 210.7072 - val_mse: 210.7072\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 99.9449 - mse: 99.9449 - val_loss: 210.5676 - val_mse: 210.5676\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 99.9229 - mse: 99.9229 - val_loss: 210.4859 - val_mse: 210.4859\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 99.9110 - mse: 99.9110 - val_loss: 210.3145 - val_mse: 210.3145\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 99.9686 - mse: 99.9686 - val_loss: 210.2487 - val_mse: 210.2487\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 99.8897 - mse: 99.8897 - val_loss: 209.7523 - val_mse: 209.7523\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 99.9377 - mse: 99.9377 - val_loss: 211.3098 - val_mse: 211.3098\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 99.9318 - mse: 99.9318 - val_loss: 211.6674 - val_mse: 211.6674\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 99.8866 - mse: 99.8866 - val_loss: 211.2329 - val_mse: 211.2329\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 100.0372 - mse: 100.0372 - val_loss: 210.9751 - val_mse: 210.9751\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 99.8768 - mse: 99.8768 - val_loss: 210.3717 - val_mse: 210.3717\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 99.9470 - mse: 99.9470 - val_loss: 210.3518 - val_mse: 210.3518\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 99.9940 - mse: 99.9940 - val_loss: 210.0737 - val_mse: 210.0737\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 99.8979 - mse: 99.8979 - val_loss: 210.3960 - val_mse: 210.3960\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 99.8813 - mse: 99.8813 - val_loss: 210.9751 - val_mse: 210.9751\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 99.8707 - mse: 99.8707 - val_loss: 210.5967 - val_mse: 210.5967\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 99.8873 - mse: 99.8873 - val_loss: 210.4462 - val_mse: 210.4462\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 99.8996 - mse: 99.8996 - val_loss: 210.9574 - val_mse: 210.9574\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 100.0268 - mse: 100.0268 - val_loss: 211.5223 - val_mse: 211.5223\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 99.9815 - mse: 99.9815 - val_loss: 211.1156 - val_mse: 211.1156\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 99.9841 - mse: 99.9841 - val_loss: 211.0558 - val_mse: 211.0558\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 99.9236 - mse: 99.9236 - val_loss: 210.2658 - val_mse: 210.2658\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 99.8951 - mse: 99.8951 - val_loss: 208.7572 - val_mse: 208.7572\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 99.9741 - mse: 99.9741 - val_loss: 209.2512 - val_mse: 209.2512\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 99.9200 - mse: 99.9200 - val_loss: 209.3618 - val_mse: 209.3618\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 99.9310 - mse: 99.9310 - val_loss: 208.6697 - val_mse: 208.6697\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 99.8999 - mse: 99.8999 - val_loss: 208.8185 - val_mse: 208.8185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 99.9800 - mse: 99.9800 - val_loss: 208.2216 - val_mse: 208.2216\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 99.8814 - mse: 99.8814 - val_loss: 208.8996 - val_mse: 208.8996\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 99.9244 - mse: 99.9244 - val_loss: 208.6004 - val_mse: 208.6004\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 99.9456 - mse: 99.9456 - val_loss: 209.3732 - val_mse: 209.3732\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 99.9042 - mse: 99.9042 - val_loss: 209.3219 - val_mse: 209.3219\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 99.8803 - mse: 99.8803 - val_loss: 209.1927 - val_mse: 209.1927\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 99.9530 - mse: 99.9530 - val_loss: 208.4512 - val_mse: 208.4512\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 99.8793 - mse: 99.8793 - val_loss: 208.9666 - val_mse: 208.9666\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 99.9353 - mse: 99.9353 - val_loss: 208.7383 - val_mse: 208.7383\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 99.9013 - mse: 99.9013 - val_loss: 209.1449 - val_mse: 209.1449\n",
      "INFO:tensorflow:Assets written to: out/111-model-ntrain=100-sigma=10.0-epochs=100.tf/assets\n",
      "\n",
      "Epoch 1/10\n",
      "18/18 [==============================] - 1s 19ms/step - loss: 2.9446 - mse: 2.9446 - val_loss: 2.9579 - val_mse: 2.9579\n",
      "Epoch 2/10\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 2.1058 - mse: 2.1058 - val_loss: 2.1363 - val_mse: 2.1363\n",
      "Epoch 3/10\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.5390 - mse: 1.5390 - val_loss: 1.5969 - val_mse: 1.5969\n",
      "Epoch 4/10\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.1626 - mse: 1.1626 - val_loss: 1.2156 - val_mse: 1.2156\n",
      "Epoch 5/10\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.8912 - mse: 0.8912 - val_loss: 0.9356 - val_mse: 0.9356\n",
      "Epoch 6/10\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.6905 - mse: 0.6905 - val_loss: 0.7170 - val_mse: 0.7170\n",
      "Epoch 7/10\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5334 - mse: 0.5334 - val_loss: 0.5496 - val_mse: 0.5496\n",
      "Epoch 8/10\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4112 - mse: 0.4112 - val_loss: 0.4298 - val_mse: 0.4298\n",
      "Epoch 9/10\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.3229 - mse: 0.3229 - val_loss: 0.3362 - val_mse: 0.3362\n",
      "Epoch 10/10\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.2534 - mse: 0.2534 - val_loss: 0.2610 - val_mse: 0.2610\n",
      "INFO:tensorflow:Assets written to: out/111-model-ntrain=550-sigma=0.0-epochs=10.tf/assets\n",
      "Epoch 1/55\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.1971 - mse: 0.1971 - val_loss: 0.2039 - val_mse: 0.2039\n",
      "Epoch 2/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1544 - mse: 0.1544 - val_loss: 0.1589 - val_mse: 0.1589\n",
      "Epoch 3/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1206 - mse: 0.1206 - val_loss: 0.1244 - val_mse: 0.1244\n",
      "Epoch 4/55\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0944 - mse: 0.0944 - val_loss: 0.0972 - val_mse: 0.0972\n",
      "Epoch 5/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0737 - mse: 0.0737 - val_loss: 0.0765 - val_mse: 0.0765\n",
      "Epoch 6/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0580 - mse: 0.0580 - val_loss: 0.0597 - val_mse: 0.0597\n",
      "Epoch 7/55\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0454 - mse: 0.0454 - val_loss: 0.0463 - val_mse: 0.0463\n",
      "Epoch 8/55\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0353 - mse: 0.0353 - val_loss: 0.0365 - val_mse: 0.0365\n",
      "Epoch 9/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0278 - mse: 0.0278 - val_loss: 0.0287 - val_mse: 0.0287\n",
      "Epoch 10/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0224 - val_mse: 0.0224\n",
      "Epoch 11/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0175 - val_mse: 0.0175\n",
      "Epoch 12/55\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 13/55\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0105 - mse: 0.0105 - val_loss: 0.0109 - val_mse: 0.0109\n",
      "Epoch 14/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0083 - mse: 0.0083 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 15/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0067 - val_mse: 0.0067\n",
      "Epoch 16/55\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0053 - val_mse: 0.0053\n",
      "Epoch 17/55\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0042 - val_mse: 0.0042\n",
      "Epoch 18/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0032 - mse: 0.0032 - val_loss: 0.0033 - val_mse: 0.0033\n",
      "Epoch 19/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 0.0026 - val_mse: 0.0026\n",
      "Epoch 20/55\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0020 - val_mse: 0.0020\n",
      "Epoch 21/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0016 - val_mse: 0.0016\n",
      "Epoch 22/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 23/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9.2742e-04 - mse: 9.2742e-04 - val_loss: 9.4765e-04 - val_mse: 9.4765e-04\n",
      "Epoch 24/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 7.2325e-04 - mse: 7.2325e-04 - val_loss: 7.4001e-04 - val_mse: 7.4001e-04\n",
      "Epoch 25/55\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 5.6622e-04 - mse: 5.6622e-04 - val_loss: 5.8203e-04 - val_mse: 5.8203e-04\n",
      "Epoch 26/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 4.4506e-04 - mse: 4.4506e-04 - val_loss: 4.6026e-04 - val_mse: 4.6026e-04\n",
      "Epoch 27/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 3.5142e-04 - mse: 3.5142e-04 - val_loss: 3.5875e-04 - val_mse: 3.5875e-04\n",
      "Epoch 28/55\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 2.7403e-04 - mse: 2.7403e-04 - val_loss: 2.8182e-04 - val_mse: 2.8182e-04\n",
      "Epoch 29/55\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 2.1476e-04 - mse: 2.1476e-04 - val_loss: 2.1968e-04 - val_mse: 2.1968e-04\n",
      "Epoch 30/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.6713e-04 - mse: 1.6713e-04 - val_loss: 1.7234e-04 - val_mse: 1.7234e-04\n",
      "Epoch 31/55\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.3105e-04 - mse: 1.3105e-04 - val_loss: 1.3459e-04 - val_mse: 1.3459e-04\n",
      "Epoch 32/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0242e-04 - mse: 1.0242e-04 - val_loss: 1.0554e-04 - val_mse: 1.0554e-04\n",
      "Epoch 33/55\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 8.0299e-05 - mse: 8.0299e-05 - val_loss: 8.2954e-05 - val_mse: 8.2954e-05\n",
      "Epoch 34/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 6.3091e-05 - mse: 6.3091e-05 - val_loss: 6.4470e-05 - val_mse: 6.4470e-05\n",
      "Epoch 35/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 4.9107e-05 - mse: 4.9107e-05 - val_loss: 5.0560e-05 - val_mse: 5.0560e-05\n",
      "Epoch 36/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 3.8548e-05 - mse: 3.8548e-05 - val_loss: 3.9609e-05 - val_mse: 3.9609e-05\n",
      "Epoch 37/55\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 3.0168e-05 - mse: 3.0168e-05 - val_loss: 3.1024e-05 - val_mse: 3.1024e-05\n",
      "Epoch 38/55\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.3605e-05 - mse: 2.3605e-05 - val_loss: 2.4383e-05 - val_mse: 2.4383e-05\n",
      "Epoch 39/55\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.8562e-05 - mse: 1.8562e-05 - val_loss: 1.9030e-05 - val_mse: 1.9030e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/55\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.4439e-05 - mse: 1.4439e-05 - val_loss: 1.4895e-05 - val_mse: 1.4895e-05\n",
      "Epoch 41/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.1307e-05 - mse: 1.1307e-05 - val_loss: 1.1620e-05 - val_mse: 1.1620e-05\n",
      "Epoch 42/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 8.8309e-06 - mse: 8.8309e-06 - val_loss: 9.0704e-06 - val_mse: 9.0704e-06\n",
      "Epoch 43/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 6.9059e-06 - mse: 6.9059e-06 - val_loss: 7.1452e-06 - val_mse: 7.1452e-06\n",
      "Epoch 44/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 5.4389e-06 - mse: 5.4389e-06 - val_loss: 5.6238e-06 - val_mse: 5.6238e-06\n",
      "Epoch 45/55\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 4.2706e-06 - mse: 4.2706e-06 - val_loss: 4.4235e-06 - val_mse: 4.4235e-06\n",
      "Epoch 46/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 3.3571e-06 - mse: 3.3571e-06 - val_loss: 3.4519e-06 - val_mse: 3.4519e-06\n",
      "Epoch 47/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.6230e-06 - mse: 2.6230e-06 - val_loss: 2.6928e-06 - val_mse: 2.6928e-06\n",
      "Epoch 48/55\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 2.0440e-06 - mse: 2.0440e-06 - val_loss: 2.1246e-06 - val_mse: 2.1246e-06\n",
      "Epoch 49/55\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.6127e-06 - mse: 1.6127e-06 - val_loss: 1.6476e-06 - val_mse: 1.6476e-06\n",
      "Epoch 50/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.2542e-06 - mse: 1.2542e-06 - val_loss: 1.2946e-06 - val_mse: 1.2946e-06\n",
      "Epoch 51/55\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 9.8401e-07 - mse: 9.8401e-07 - val_loss: 1.0095e-06 - val_mse: 1.0095e-06\n",
      "Epoch 52/55\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 7.6784e-07 - mse: 7.6784e-07 - val_loss: 7.8972e-07 - val_mse: 7.8972e-07\n",
      "Epoch 53/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 6.0068e-07 - mse: 6.0068e-07 - val_loss: 6.1752e-07 - val_mse: 6.1752e-07\n",
      "Epoch 54/55\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 4.6951e-07 - mse: 4.6951e-07 - val_loss: 4.8181e-07 - val_mse: 4.8181e-07\n",
      "Epoch 55/55\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 3.6679e-07 - mse: 3.6679e-07 - val_loss: 3.7951e-07 - val_mse: 3.7951e-07\n",
      "INFO:tensorflow:Assets written to: out/111-model-ntrain=550-sigma=0.0-epochs=55.tf/assets\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 2.8927e-07 - mse: 2.8927e-07 - val_loss: 2.9741e-07 - val_mse: 2.9741e-07\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.2697e-07 - mse: 2.2697e-07 - val_loss: 2.3247e-07 - val_mse: 2.3247e-07\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1.7741e-07 - mse: 1.7741e-07 - val_loss: 1.8205e-07 - val_mse: 1.8205e-07\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 1.3888e-07 - mse: 1.3888e-07 - val_loss: 1.4243e-07 - val_mse: 1.4243e-07\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 1.0835e-07 - mse: 1.0835e-07 - val_loss: 1.1217e-07 - val_mse: 1.1217e-07\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 8.5242e-08 - mse: 8.5242e-08 - val_loss: 8.7586e-08 - val_mse: 8.7586e-08\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 6.6690e-08 - mse: 6.6690e-08 - val_loss: 6.7974e-08 - val_mse: 6.7974e-08\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 5.1790e-08 - mse: 5.1790e-08 - val_loss: 5.3480e-08 - val_mse: 5.3480e-08\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 4.0737e-08 - mse: 4.0737e-08 - val_loss: 4.2039e-08 - val_mse: 4.2039e-08\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 3.2060e-08 - mse: 3.2060e-08 - val_loss: 3.2802e-08 - val_mse: 3.2802e-08\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 2.5004e-08 - mse: 2.5004e-08 - val_loss: 2.5705e-08 - val_mse: 2.5705e-08\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.9616e-08 - mse: 1.9616e-08 - val_loss: 2.0331e-08 - val_mse: 2.0331e-08\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1.5514e-08 - mse: 1.5514e-08 - val_loss: 1.6048e-08 - val_mse: 1.6048e-08\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1.2243e-08 - mse: 1.2243e-08 - val_loss: 1.2618e-08 - val_mse: 1.2618e-08\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 9.6076e-09 - mse: 9.6076e-09 - val_loss: 9.8917e-09 - val_mse: 9.8917e-09\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.5377e-09 - mse: 7.5377e-09 - val_loss: 7.7827e-09 - val_mse: 7.7827e-09\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 5.9193e-09 - mse: 5.9193e-09 - val_loss: 6.1169e-09 - val_mse: 6.1169e-09\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 4.6540e-09 - mse: 4.6540e-09 - val_loss: 4.7983e-09 - val_mse: 4.7983e-09\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 3.6573e-09 - mse: 3.6573e-09 - val_loss: 3.7949e-09 - val_mse: 3.7949e-09\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 2.8878e-09 - mse: 2.8878e-09 - val_loss: 2.9503e-09 - val_mse: 2.9503e-09\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 2.2430e-09 - mse: 2.2430e-09 - val_loss: 2.2928e-09 - val_mse: 2.2928e-09\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.7522e-09 - mse: 1.7522e-09 - val_loss: 1.8001e-09 - val_mse: 1.8001e-09\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.3695e-09 - mse: 1.3695e-09 - val_loss: 1.3963e-09 - val_mse: 1.3963e-09\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.0624e-09 - mse: 1.0624e-09 - val_loss: 1.0870e-09 - val_mse: 1.0870e-09\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 8.2553e-10 - mse: 8.2553e-10 - val_loss: 8.4601e-10 - val_mse: 8.4601e-10\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 6.4487e-10 - mse: 6.4487e-10 - val_loss: 6.6956e-10 - val_mse: 6.6956e-10\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 5.0965e-10 - mse: 5.0965e-10 - val_loss: 5.1886e-10 - val_mse: 5.1886e-10\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 3.9674e-10 - mse: 3.9674e-10 - val_loss: 4.0681e-10 - val_mse: 4.0681e-10\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 3.0972e-10 - mse: 3.0972e-10 - val_loss: 3.1291e-10 - val_mse: 3.1291e-10\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.3851e-10 - mse: 2.3851e-10 - val_loss: 2.5026e-10 - val_mse: 2.5026e-10\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.9151e-10 - mse: 1.9151e-10 - val_loss: 1.9598e-10 - val_mse: 1.9598e-10\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.5100e-10 - mse: 1.5100e-10 - val_loss: 1.5825e-10 - val_mse: 1.5825e-10\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.2141e-10 - mse: 1.2141e-10 - val_loss: 1.2587e-10 - val_mse: 1.2587e-10\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 9.5458e-11 - mse: 9.5458e-11 - val_loss: 9.7038e-11 - val_mse: 9.7038e-11\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 7.2471e-11 - mse: 7.2471e-11 - val_loss: 7.2389e-11 - val_mse: 7.2389e-11\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 5.2960e-11 - mse: 5.2960e-11 - val_loss: 5.2010e-11 - val_mse: 5.2010e-11\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 3.7822e-11 - mse: 3.7822e-11 - val_loss: 3.6431e-11 - val_mse: 3.6431e-11\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 2.7321e-11 - mse: 2.7321e-11 - val_loss: 2.8793e-11 - val_mse: 2.8793e-11\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 2.2960e-11 - mse: 2.2960e-11 - val_loss: 2.4031e-11 - val_mse: 2.4031e-11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.0095e-11 - mse: 2.0095e-11 - val_loss: 2.3133e-11 - val_mse: 2.3133e-11\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.9270e-11 - mse: 1.9270e-11 - val_loss: 2.2026e-11 - val_mse: 2.2026e-11\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.7865e-11 - mse: 1.7865e-11 - val_loss: 2.0450e-11 - val_mse: 2.0450e-11\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.7033e-11 - mse: 1.7033e-11 - val_loss: 1.9882e-11 - val_mse: 1.9882e-11\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.6707e-11 - mse: 1.6707e-11 - val_loss: 1.9882e-11 - val_mse: 1.9882e-11\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.6698e-11 - mse: 1.6698e-11 - val_loss: 1.9882e-11 - val_mse: 1.9882e-11\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.6479e-11 - mse: 1.6479e-11 - val_loss: 1.9119e-11 - val_mse: 1.9119e-11\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.6139e-11 - mse: 1.6139e-11 - val_loss: 1.8432e-11 - val_mse: 1.8432e-11\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.5232e-11 - mse: 1.5232e-11 - val_loss: 1.7808e-11 - val_mse: 1.7808e-11\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.5029e-11 - mse: 1.5029e-11 - val_loss: 1.7115e-11 - val_mse: 1.7115e-11\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.4481e-11 - mse: 1.4481e-11 - val_loss: 1.7242e-11 - val_mse: 1.7242e-11\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.4499e-11 - mse: 1.4499e-11 - val_loss: 1.7242e-11 - val_mse: 1.7242e-11\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.4242e-11 - mse: 1.4242e-11 - val_loss: 1.6580e-11 - val_mse: 1.6580e-11\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.3985e-11 - mse: 1.3985e-11 - val_loss: 1.6580e-11 - val_mse: 1.6580e-11\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.4022e-11 - mse: 1.4022e-11 - val_loss: 1.6580e-11 - val_mse: 1.6580e-11\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.3985e-11 - mse: 1.3985e-11 - val_loss: 1.6623e-11 - val_mse: 1.6623e-11\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.3970e-11 - mse: 1.3970e-11 - val_loss: 1.6623e-11 - val_mse: 1.6623e-11\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.3970e-11 - mse: 1.3970e-11 - val_loss: 1.6623e-11 - val_mse: 1.6623e-11\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.3879e-11 - mse: 1.3879e-11 - val_loss: 1.5852e-11 - val_mse: 1.5852e-11\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.3439e-11 - mse: 1.3439e-11 - val_loss: 1.6003e-11 - val_mse: 1.6003e-11\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.3454e-11 - mse: 1.3454e-11 - val_loss: 1.5947e-11 - val_mse: 1.5947e-11\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.3433e-11 - mse: 1.3433e-11 - val_loss: 1.5947e-11 - val_mse: 1.5947e-11\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.3431e-11 - mse: 1.3431e-11 - val_loss: 1.5294e-11 - val_mse: 1.5294e-11\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.2968e-11 - mse: 1.2968e-11 - val_loss: 1.5294e-11 - val_mse: 1.5294e-11\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.2968e-11 - mse: 1.2968e-11 - val_loss: 1.5294e-11 - val_mse: 1.5294e-11\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.2968e-11 - mse: 1.2968e-11 - val_loss: 1.5398e-11 - val_mse: 1.5398e-11\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.2960e-11 - mse: 1.2960e-11 - val_loss: 1.5398e-11 - val_mse: 1.5398e-11\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.2960e-11 - mse: 1.2960e-11 - val_loss: 1.5398e-11 - val_mse: 1.5398e-11\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.2960e-11 - mse: 1.2960e-11 - val_loss: 1.5294e-11 - val_mse: 1.5294e-11\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.2968e-11 - mse: 1.2968e-11 - val_loss: 1.5294e-11 - val_mse: 1.5294e-11\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.2968e-11 - mse: 1.2968e-11 - val_loss: 1.5294e-11 - val_mse: 1.5294e-11\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.2961e-11 - mse: 1.2961e-11 - val_loss: 1.5294e-11 - val_mse: 1.5294e-11\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.2968e-11 - mse: 1.2968e-11 - val_loss: 1.4777e-11 - val_mse: 1.4777e-11\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.2486e-11 - mse: 1.2486e-11 - val_loss: 1.4858e-11 - val_mse: 1.4858e-11\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.2476e-11 - mse: 1.2476e-11 - val_loss: 1.4777e-11 - val_mse: 1.4777e-11\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.2412e-11 - mse: 1.2412e-11 - val_loss: 1.4276e-11 - val_mse: 1.4276e-11\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.2008e-11 - mse: 1.2008e-11 - val_loss: 1.3615e-11 - val_mse: 1.3615e-11\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.1444e-11 - mse: 1.1444e-11 - val_loss: 1.3608e-11 - val_mse: 1.3608e-11\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1.1442e-11 - mse: 1.1442e-11 - val_loss: 1.3608e-11 - val_mse: 1.3608e-11\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1.1442e-11 - mse: 1.1442e-11 - val_loss: 1.3608e-11 - val_mse: 1.3608e-11\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.1442e-11 - mse: 1.1442e-11 - val_loss: 1.3608e-11 - val_mse: 1.3608e-11\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.1442e-11 - mse: 1.1442e-11 - val_loss: 1.3066e-11 - val_mse: 1.3066e-11\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.1005e-11 - mse: 1.1005e-11 - val_loss: 1.2555e-11 - val_mse: 1.2555e-11\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0584e-11 - mse: 1.0584e-11 - val_loss: 1.2555e-11 - val_mse: 1.2555e-11\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.0584e-11 - mse: 1.0584e-11 - val_loss: 1.2555e-11 - val_mse: 1.2555e-11\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0584e-11 - mse: 1.0584e-11 - val_loss: 1.2555e-11 - val_mse: 1.2555e-11\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0584e-11 - mse: 1.0584e-11 - val_loss: 1.2555e-11 - val_mse: 1.2555e-11\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0584e-11 - mse: 1.0584e-11 - val_loss: 1.2555e-11 - val_mse: 1.2555e-11\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0584e-11 - mse: 1.0584e-11 - val_loss: 1.2469e-11 - val_mse: 1.2469e-11\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0596e-11 - mse: 1.0596e-11 - val_loss: 1.2469e-11 - val_mse: 1.2469e-11\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1.0596e-11 - mse: 1.0596e-11 - val_loss: 1.2469e-11 - val_mse: 1.2469e-11\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0602e-11 - mse: 1.0602e-11 - val_loss: 1.2450e-11 - val_mse: 1.2450e-11\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0596e-11 - mse: 1.0596e-11 - val_loss: 1.2450e-11 - val_mse: 1.2450e-11\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0621e-11 - mse: 1.0621e-11 - val_loss: 1.2425e-11 - val_mse: 1.2425e-11\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0629e-11 - mse: 1.0629e-11 - val_loss: 1.2425e-11 - val_mse: 1.2425e-11\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 8ms/step - loss: 1.0629e-11 - mse: 1.0629e-11 - val_loss: 1.2450e-11 - val_mse: 1.2450e-11\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0596e-11 - mse: 1.0596e-11 - val_loss: 1.2469e-11 - val_mse: 1.2469e-11\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0597e-11 - mse: 1.0597e-11 - val_loss: 1.2069e-11 - val_mse: 1.2069e-11\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.0144e-11 - mse: 1.0144e-11 - val_loss: 1.2026e-11 - val_mse: 1.2026e-11\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0120e-11 - mse: 1.0120e-11 - val_loss: 1.2026e-11 - val_mse: 1.2026e-11\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.0120e-11 - mse: 1.0120e-11 - val_loss: 1.2026e-11 - val_mse: 1.2026e-11\n",
      "INFO:tensorflow:Assets written to: out/111-model-ntrain=550-sigma=0.0-epochs=100.tf/assets\n",
      "\n",
      "Epoch 1/10\n",
      "18/18 [==============================] - 1s 20ms/step - loss: 3.9053 - mse: 3.9053 - val_loss: 3.0414 - val_mse: 3.0414\n",
      "Epoch 2/10\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 3.0824 - mse: 3.0824 - val_loss: 2.4048 - val_mse: 2.4048\n",
      "Epoch 3/10\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.5408 - mse: 2.5408 - val_loss: 1.9783 - val_mse: 1.9783\n",
      "Epoch 4/10\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1640 - mse: 2.1640 - val_loss: 1.6841 - val_mse: 1.6841\n",
      "Epoch 5/10\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.8956 - mse: 1.8956 - val_loss: 1.4767 - val_mse: 1.4767\n",
      "Epoch 6/10\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1.6983 - mse: 1.6983 - val_loss: 1.3212 - val_mse: 1.3212\n",
      "Epoch 7/10\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1.5440 - mse: 1.5440 - val_loss: 1.2085 - val_mse: 1.2085\n",
      "Epoch 8/10\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1.4260 - mse: 1.4260 - val_loss: 1.1254 - val_mse: 1.1254\n",
      "Epoch 9/10\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 1.3373 - mse: 1.3373 - val_loss: 1.0657 - val_mse: 1.0657\n",
      "Epoch 10/10\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 1.2676 - mse: 1.2676 - val_loss: 1.0226 - val_mse: 1.0226\n",
      "INFO:tensorflow:Assets written to: out/111-model-ntrain=550-sigma=1.0-epochs=10.tf/assets\n",
      "Epoch 1/55\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 1.2133 - mse: 1.2133 - val_loss: 0.9865 - val_mse: 0.9865\n",
      "Epoch 2/55\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.1676 - mse: 1.1676 - val_loss: 0.9588 - val_mse: 0.9588\n",
      "Epoch 3/55\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.1348 - mse: 1.1348 - val_loss: 0.9395 - val_mse: 0.9395\n",
      "Epoch 4/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.1075 - mse: 1.1075 - val_loss: 0.9269 - val_mse: 0.9269\n",
      "Epoch 5/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0870 - mse: 1.0870 - val_loss: 0.9161 - val_mse: 0.9161\n",
      "Epoch 6/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0716 - mse: 1.0716 - val_loss: 0.9104 - val_mse: 0.9104\n",
      "Epoch 7/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0593 - mse: 1.0593 - val_loss: 0.9094 - val_mse: 0.9094\n",
      "Epoch 8/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0507 - mse: 1.0507 - val_loss: 0.9078 - val_mse: 0.9078\n",
      "Epoch 9/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0430 - mse: 1.0430 - val_loss: 0.9101 - val_mse: 0.9101\n",
      "Epoch 10/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0370 - mse: 1.0370 - val_loss: 0.9139 - val_mse: 0.9139\n",
      "Epoch 11/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0328 - mse: 1.0328 - val_loss: 0.9163 - val_mse: 0.9163\n",
      "Epoch 12/55\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.0285 - mse: 1.0285 - val_loss: 0.9150 - val_mse: 0.9150\n",
      "Epoch 13/55\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.0253 - mse: 1.0253 - val_loss: 0.9160 - val_mse: 0.9160\n",
      "Epoch 14/55\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0235 - mse: 1.0235 - val_loss: 0.9178 - val_mse: 0.9178\n",
      "Epoch 15/55\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0216 - mse: 1.0216 - val_loss: 0.9186 - val_mse: 0.9186\n",
      "Epoch 16/55\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0204 - mse: 1.0204 - val_loss: 0.9228 - val_mse: 0.9228\n",
      "Epoch 17/55\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0197 - mse: 1.0197 - val_loss: 0.9258 - val_mse: 0.9258\n",
      "Epoch 18/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0187 - mse: 1.0187 - val_loss: 0.9247 - val_mse: 0.9247\n",
      "Epoch 19/55\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0179 - mse: 1.0179 - val_loss: 0.9286 - val_mse: 0.9286\n",
      "Epoch 20/55\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0176 - mse: 1.0176 - val_loss: 0.9207 - val_mse: 0.9207\n",
      "Epoch 21/55\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0174 - mse: 1.0174 - val_loss: 0.9236 - val_mse: 0.9236\n",
      "Epoch 22/55\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0170 - mse: 1.0170 - val_loss: 0.9247 - val_mse: 0.9247\n",
      "Epoch 23/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0167 - mse: 1.0167 - val_loss: 0.9227 - val_mse: 0.9227\n",
      "Epoch 24/55\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.0167 - mse: 1.0167 - val_loss: 0.9265 - val_mse: 0.9265\n",
      "Epoch 25/55\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0165 - mse: 1.0165 - val_loss: 0.9308 - val_mse: 0.9308\n",
      "Epoch 26/55\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0162 - mse: 1.0162 - val_loss: 0.9375 - val_mse: 0.9375\n",
      "Epoch 27/55\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0164 - mse: 1.0164 - val_loss: 0.9409 - val_mse: 0.9409\n",
      "Epoch 28/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0157 - mse: 1.0157 - val_loss: 0.9406 - val_mse: 0.9406\n",
      "Epoch 29/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0157 - mse: 1.0157 - val_loss: 0.9374 - val_mse: 0.9374\n",
      "Epoch 30/55\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0158 - mse: 1.0158 - val_loss: 0.9357 - val_mse: 0.9357\n",
      "Epoch 31/55\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0160 - mse: 1.0160 - val_loss: 0.9395 - val_mse: 0.9395\n",
      "Epoch 32/55\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0157 - mse: 1.0157 - val_loss: 0.9425 - val_mse: 0.9425\n",
      "Epoch 33/55\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.0156 - mse: 1.0156 - val_loss: 0.9346 - val_mse: 0.9346\n",
      "Epoch 34/55\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.0152 - mse: 1.0152 - val_loss: 0.9344 - val_mse: 0.9344\n",
      "Epoch 35/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0154 - mse: 1.0154 - val_loss: 0.9390 - val_mse: 0.9390\n",
      "Epoch 36/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0156 - mse: 1.0156 - val_loss: 0.9417 - val_mse: 0.9417\n",
      "Epoch 37/55\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0159 - mse: 1.0159 - val_loss: 0.9407 - val_mse: 0.9407\n",
      "Epoch 38/55\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0154 - mse: 1.0154 - val_loss: 0.9431 - val_mse: 0.9431\n",
      "Epoch 39/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0159 - mse: 1.0159 - val_loss: 0.9422 - val_mse: 0.9422\n",
      "Epoch 40/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0154 - mse: 1.0154 - val_loss: 0.9443 - val_mse: 0.9443\n",
      "Epoch 41/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0158 - mse: 1.0158 - val_loss: 0.9395 - val_mse: 0.9395\n",
      "Epoch 42/55\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.0157 - mse: 1.0157 - val_loss: 0.9379 - val_mse: 0.9379\n",
      "Epoch 43/55\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.0156 - mse: 1.0156 - val_loss: 0.9361 - val_mse: 0.9361\n",
      "Epoch 44/55\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.0154 - mse: 1.0154 - val_loss: 0.9381 - val_mse: 0.9381\n",
      "Epoch 45/55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 8ms/step - loss: 1.0154 - mse: 1.0154 - val_loss: 0.9406 - val_mse: 0.9406\n",
      "Epoch 46/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0157 - mse: 1.0157 - val_loss: 0.9429 - val_mse: 0.9429\n",
      "Epoch 47/55\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.0161 - mse: 1.0161 - val_loss: 0.9426 - val_mse: 0.9426\n",
      "Epoch 48/55\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0155 - mse: 1.0155 - val_loss: 0.9377 - val_mse: 0.9377\n",
      "Epoch 49/55\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0155 - mse: 1.0155 - val_loss: 0.9328 - val_mse: 0.9328\n",
      "Epoch 50/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0154 - mse: 1.0154 - val_loss: 0.9346 - val_mse: 0.9346\n",
      "Epoch 51/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0159 - mse: 1.0159 - val_loss: 0.9344 - val_mse: 0.9344\n",
      "Epoch 52/55\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0153 - mse: 1.0153 - val_loss: 0.9405 - val_mse: 0.9405\n",
      "Epoch 53/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0152 - mse: 1.0152 - val_loss: 0.9386 - val_mse: 0.9386\n",
      "Epoch 54/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0155 - mse: 1.0155 - val_loss: 0.9410 - val_mse: 0.9410\n",
      "Epoch 55/55\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.0156 - mse: 1.0156 - val_loss: 0.9374 - val_mse: 0.9374\n",
      "INFO:tensorflow:Assets written to: out/111-model-ntrain=550-sigma=1.0-epochs=55.tf/assets\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 1.0153 - mse: 1.0153 - val_loss: 0.9410 - val_mse: 0.9410\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0152 - mse: 1.0152 - val_loss: 0.9363 - val_mse: 0.9363\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0153 - mse: 1.0153 - val_loss: 0.9380 - val_mse: 0.9380\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0157 - mse: 1.0157 - val_loss: 0.9400 - val_mse: 0.9400\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0155 - mse: 1.0155 - val_loss: 0.9372 - val_mse: 0.9372\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0157 - mse: 1.0157 - val_loss: 0.9355 - val_mse: 0.9355\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0153 - mse: 1.0153 - val_loss: 0.9357 - val_mse: 0.9357\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.0156 - mse: 1.0156 - val_loss: 0.9360 - val_mse: 0.9360\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0155 - mse: 1.0155 - val_loss: 0.9388 - val_mse: 0.9388\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0153 - mse: 1.0153 - val_loss: 0.9415 - val_mse: 0.9415\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0153 - mse: 1.0153 - val_loss: 0.9437 - val_mse: 0.9437\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0155 - mse: 1.0155 - val_loss: 0.9417 - val_mse: 0.9417\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0154 - mse: 1.0154 - val_loss: 0.9410 - val_mse: 0.9410\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0159 - mse: 1.0159 - val_loss: 0.9415 - val_mse: 0.9415\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0157 - mse: 1.0157 - val_loss: 0.9395 - val_mse: 0.9395\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0154 - mse: 1.0154 - val_loss: 0.9425 - val_mse: 0.9425\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0158 - mse: 1.0158 - val_loss: 0.9437 - val_mse: 0.9437\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0157 - mse: 1.0157 - val_loss: 0.9410 - val_mse: 0.9410\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0156 - mse: 1.0156 - val_loss: 0.9435 - val_mse: 0.9435\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.0157 - mse: 1.0157 - val_loss: 0.9332 - val_mse: 0.9332\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0155 - mse: 1.0155 - val_loss: 0.9345 - val_mse: 0.9345\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0154 - mse: 1.0154 - val_loss: 0.9347 - val_mse: 0.9347\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0154 - mse: 1.0154 - val_loss: 0.9314 - val_mse: 0.9314\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0155 - mse: 1.0155 - val_loss: 0.9344 - val_mse: 0.9344\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0158 - mse: 1.0158 - val_loss: 0.9380 - val_mse: 0.9380\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0157 - mse: 1.0157 - val_loss: 0.9441 - val_mse: 0.9441\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0160 - mse: 1.0160 - val_loss: 0.9470 - val_mse: 0.9470\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0155 - mse: 1.0155 - val_loss: 0.9461 - val_mse: 0.9461\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0156 - mse: 1.0156 - val_loss: 0.9423 - val_mse: 0.9423\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0157 - mse: 1.0157 - val_loss: 0.9401 - val_mse: 0.9401\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.0159 - mse: 1.0159 - val_loss: 0.9435 - val_mse: 0.9435\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0157 - mse: 1.0157 - val_loss: 0.9460 - val_mse: 0.9460\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0156 - mse: 1.0156 - val_loss: 0.9377 - val_mse: 0.9377\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0152 - mse: 1.0152 - val_loss: 0.9371 - val_mse: 0.9371\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0154 - mse: 1.0154 - val_loss: 0.9414 - val_mse: 0.9414\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0156 - mse: 1.0156 - val_loss: 0.9439 - val_mse: 0.9439\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0159 - mse: 1.0159 - val_loss: 0.9426 - val_mse: 0.9426\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0154 - mse: 1.0154 - val_loss: 0.9448 - val_mse: 0.9448\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0160 - mse: 1.0160 - val_loss: 0.9437 - val_mse: 0.9437\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0154 - mse: 1.0154 - val_loss: 0.9456 - val_mse: 0.9456\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.0157 - mse: 1.0157 - val_loss: 0.9406 - val_mse: 0.9406\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.0157 - mse: 1.0157 - val_loss: 0.9389 - val_mse: 0.9389\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0155 - mse: 1.0155 - val_loss: 0.9370 - val_mse: 0.9370\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0153 - mse: 1.0153 - val_loss: 0.9389 - val_mse: 0.9389\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0154 - mse: 1.0154 - val_loss: 0.9413 - val_mse: 0.9413\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0156 - mse: 1.0156 - val_loss: 0.9435 - val_mse: 0.9435\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.0161 - mse: 1.0161 - val_loss: 0.9431 - val_mse: 0.9431\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1.0155 - mse: 1.0155 - val_loss: 0.9382 - val_mse: 0.9382\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0155 - mse: 1.0155 - val_loss: 0.9333 - val_mse: 0.9333\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0154 - mse: 1.0154 - val_loss: 0.9350 - val_mse: 0.9350\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 8ms/step - loss: 1.0159 - mse: 1.0159 - val_loss: 0.9347 - val_mse: 0.9347\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0153 - mse: 1.0153 - val_loss: 0.9408 - val_mse: 0.9408\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0152 - mse: 1.0152 - val_loss: 0.9389 - val_mse: 0.9389\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.0155 - mse: 1.0155 - val_loss: 0.9412 - val_mse: 0.9412\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0156 - mse: 1.0156 - val_loss: 0.9376 - val_mse: 0.9376\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0153 - mse: 1.0153 - val_loss: 0.9419 - val_mse: 0.9419\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0153 - mse: 1.0153 - val_loss: 0.9426 - val_mse: 0.9426\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0158 - mse: 1.0158 - val_loss: 0.9349 - val_mse: 0.9349\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.0155 - mse: 1.0155 - val_loss: 0.9414 - val_mse: 0.9414\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0156 - mse: 1.0156 - val_loss: 0.9370 - val_mse: 0.9370\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.0152 - mse: 1.0152 - val_loss: 0.9387 - val_mse: 0.9387\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0156 - mse: 1.0156 - val_loss: 0.9387 - val_mse: 0.9387\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0156 - mse: 1.0156 - val_loss: 0.9411 - val_mse: 0.9411\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0155 - mse: 1.0155 - val_loss: 0.9385 - val_mse: 0.9385\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1.0158 - mse: 1.0158 - val_loss: 0.9390 - val_mse: 0.9390\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1.0154 - mse: 1.0154 - val_loss: 0.9358 - val_mse: 0.9358\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 1.0152 - mse: 1.0152 - val_loss: 0.9320 - val_mse: 0.9320\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.0153 - mse: 1.0153 - val_loss: 0.9308 - val_mse: 0.9308\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0158 - mse: 1.0158 - val_loss: 0.9362 - val_mse: 0.9362\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0152 - mse: 1.0152 - val_loss: 0.9389 - val_mse: 0.9389\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.0155 - mse: 1.0155 - val_loss: 0.9368 - val_mse: 0.9368\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 1.0157 - mse: 1.0157 - val_loss: 0.9381 - val_mse: 0.9381\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 1.0153 - mse: 1.0153 - val_loss: 0.9363 - val_mse: 0.9363\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0151 - mse: 1.0151 - val_loss: 0.9305 - val_mse: 0.9305\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0156 - mse: 1.0156 - val_loss: 0.9338 - val_mse: 0.9338\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.0157 - mse: 1.0157 - val_loss: 0.9394 - val_mse: 0.9394\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0154 - mse: 1.0154 - val_loss: 0.9390 - val_mse: 0.9390\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0156 - mse: 1.0156 - val_loss: 0.9429 - val_mse: 0.9429\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0161 - mse: 1.0161 - val_loss: 0.9439 - val_mse: 0.9439\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0157 - mse: 1.0157 - val_loss: 0.9418 - val_mse: 0.9418\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0160 - mse: 1.0160 - val_loss: 0.9446 - val_mse: 0.9446\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 1.0156 - mse: 1.0156 - val_loss: 0.9404 - val_mse: 0.9404\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 1.0154 - mse: 1.0154 - val_loss: 0.9436 - val_mse: 0.9436\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0156 - mse: 1.0156 - val_loss: 0.9427 - val_mse: 0.9427\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0154 - mse: 1.0154 - val_loss: 0.9458 - val_mse: 0.9458\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0159 - mse: 1.0159 - val_loss: 0.9485 - val_mse: 0.9485\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0163 - mse: 1.0163 - val_loss: 0.9457 - val_mse: 0.9457\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.0157 - mse: 1.0157 - val_loss: 0.9379 - val_mse: 0.9379\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0154 - mse: 1.0154 - val_loss: 0.9388 - val_mse: 0.9388\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0155 - mse: 1.0155 - val_loss: 0.9365 - val_mse: 0.9365\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0157 - mse: 1.0157 - val_loss: 0.9285 - val_mse: 0.9285\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0154 - mse: 1.0154 - val_loss: 0.9309 - val_mse: 0.9309\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0154 - mse: 1.0154 - val_loss: 0.9327 - val_mse: 0.9327\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.0157 - mse: 1.0157 - val_loss: 0.9344 - val_mse: 0.9344\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0154 - mse: 1.0154 - val_loss: 0.9302 - val_mse: 0.9302\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0152 - mse: 1.0152 - val_loss: 0.9319 - val_mse: 0.9319\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0157 - mse: 1.0157 - val_loss: 0.9308 - val_mse: 0.9308\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0154 - mse: 1.0154 - val_loss: 0.9288 - val_mse: 0.9288\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0158 - mse: 1.0158 - val_loss: 0.9334 - val_mse: 0.9334\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0154 - mse: 1.0154 - val_loss: 0.9336 - val_mse: 0.9336\n",
      "INFO:tensorflow:Assets written to: out/111-model-ntrain=550-sigma=1.0-epochs=100.tf/assets\n",
      "\n",
      "Epoch 1/10\n",
      "18/18 [==============================] - 1s 19ms/step - loss: 104.0397 - mse: 104.0397 - val_loss: 89.6236 - val_mse: 89.6236\n",
      "Epoch 2/10\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 103.3043 - mse: 103.3043 - val_loss: 89.8114 - val_mse: 89.8114\n",
      "Epoch 3/10\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 102.9375 - mse: 102.9375 - val_loss: 90.3108 - val_mse: 90.3108\n",
      "Epoch 4/10\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 102.5899 - mse: 102.5899 - val_loss: 90.8218 - val_mse: 90.8218\n",
      "Epoch 5/10\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 102.3339 - mse: 102.3339 - val_loss: 90.8989 - val_mse: 90.8989\n",
      "Epoch 6/10\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 102.1730 - mse: 102.1730 - val_loss: 91.0764 - val_mse: 91.0764\n",
      "Epoch 7/10\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 102.0110 - mse: 102.0110 - val_loss: 91.4355 - val_mse: 91.4355\n",
      "Epoch 8/10\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 101.9588 - mse: 101.9588 - val_loss: 91.6749 - val_mse: 91.6749\n",
      "Epoch 9/10\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 101.8570 - mse: 101.8570 - val_loss: 92.1523 - val_mse: 92.1523\n",
      "Epoch 10/10\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 101.7770 - mse: 101.7770 - val_loss: 92.6252 - val_mse: 92.6252\n",
      "INFO:tensorflow:Assets written to: out/111-model-ntrain=550-sigma=10.0-epochs=10.tf/assets\n",
      "Epoch 1/55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 11ms/step - loss: 101.7468 - mse: 101.7468 - val_loss: 92.9645 - val_mse: 92.9645\n",
      "Epoch 2/55\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 101.6605 - mse: 101.6605 - val_loss: 92.5601 - val_mse: 92.5601\n",
      "Epoch 3/55\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 101.6318 - mse: 101.6318 - val_loss: 92.7656 - val_mse: 92.7656\n",
      "Epoch 4/55\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 101.6312 - mse: 101.6312 - val_loss: 93.0239 - val_mse: 93.0239\n",
      "Epoch 5/55\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 101.6003 - mse: 101.6003 - val_loss: 92.8244 - val_mse: 92.8244\n",
      "Epoch 6/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 101.5999 - mse: 101.5999 - val_loss: 92.7451 - val_mse: 92.7451\n",
      "Epoch 7/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 101.5587 - mse: 101.5587 - val_loss: 92.8746 - val_mse: 92.8746\n",
      "Epoch 8/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 101.5903 - mse: 101.5903 - val_loss: 92.9672 - val_mse: 92.9672\n",
      "Epoch 9/55\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 101.5704 - mse: 101.5704 - val_loss: 93.3120 - val_mse: 93.3120\n",
      "Epoch 10/55\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 101.5543 - mse: 101.5543 - val_loss: 93.6466 - val_mse: 93.6466\n",
      "Epoch 11/55\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 101.5528 - mse: 101.5528 - val_loss: 93.9130 - val_mse: 93.9130\n",
      "Epoch 12/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 101.5585 - mse: 101.5585 - val_loss: 93.7553 - val_mse: 93.7553\n",
      "Epoch 13/55\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 101.5439 - mse: 101.5439 - val_loss: 93.7310 - val_mse: 93.7310\n",
      "Epoch 14/55\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 101.5876 - mse: 101.5876 - val_loss: 93.8166 - val_mse: 93.8166\n",
      "Epoch 15/55\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 101.5696 - mse: 101.5696 - val_loss: 93.6630 - val_mse: 93.6630\n",
      "Epoch 16/55\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 101.5434 - mse: 101.5434 - val_loss: 93.9872 - val_mse: 93.9872\n",
      "Epoch 17/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 101.5835 - mse: 101.5835 - val_loss: 94.1408 - val_mse: 94.1408\n",
      "Epoch 18/55\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 101.5701 - mse: 101.5701 - val_loss: 93.8940 - val_mse: 93.8940\n",
      "Epoch 19/55\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 101.5578 - mse: 101.5578 - val_loss: 94.1618 - val_mse: 94.1618\n",
      "Epoch 20/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 101.5725 - mse: 101.5725 - val_loss: 93.1655 - val_mse: 93.1655\n",
      "Epoch 21/55\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 101.5591 - mse: 101.5591 - val_loss: 93.3170 - val_mse: 93.3170\n",
      "Epoch 22/55\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 101.5417 - mse: 101.5417 - val_loss: 93.3508 - val_mse: 93.3508\n",
      "Epoch 23/55\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 101.5431 - mse: 101.5431 - val_loss: 93.0347 - val_mse: 93.0347\n",
      "Epoch 24/55\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 101.5579 - mse: 101.5579 - val_loss: 93.3478 - val_mse: 93.3478\n",
      "Epoch 25/55\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 101.5816 - mse: 101.5816 - val_loss: 93.7193 - val_mse: 93.7193\n",
      "Epoch 26/55\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 101.5717 - mse: 101.5717 - val_loss: 94.3305 - val_mse: 94.3305\n",
      "Epoch 27/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 101.6007 - mse: 101.6007 - val_loss: 94.6293 - val_mse: 94.6293\n",
      "Epoch 28/55\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 101.5463 - mse: 101.5463 - val_loss: 94.5498 - val_mse: 94.5498\n",
      "Epoch 29/55\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 101.5608 - mse: 101.5608 - val_loss: 94.1775 - val_mse: 94.1775\n",
      "Epoch 30/55\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 101.5681 - mse: 101.5681 - val_loss: 93.9607 - val_mse: 93.9607\n",
      "Epoch 31/55\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 101.5860 - mse: 101.5860 - val_loss: 94.3014 - val_mse: 94.3014\n",
      "Epoch 32/55\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 101.5704 - mse: 101.5704 - val_loss: 94.5624 - val_mse: 94.5624\n",
      "Epoch 33/55\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 101.5583 - mse: 101.5583 - val_loss: 93.7362 - val_mse: 93.7362\n",
      "Epoch 34/55\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 101.5179 - mse: 101.5179 - val_loss: 93.6817 - val_mse: 93.6817\n",
      "Epoch 35/55\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 101.5441 - mse: 101.5441 - val_loss: 94.1157 - val_mse: 94.1157\n",
      "Epoch 36/55\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 101.5615 - mse: 101.5615 - val_loss: 94.3639 - val_mse: 94.3639\n",
      "Epoch 37/55\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 101.5881 - mse: 101.5881 - val_loss: 94.2434 - val_mse: 94.2434\n",
      "Epoch 38/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 101.5426 - mse: 101.5426 - val_loss: 94.4602 - val_mse: 94.4602\n",
      "Epoch 39/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 101.5951 - mse: 101.5951 - val_loss: 94.3539 - val_mse: 94.3539\n",
      "Epoch 40/55\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 101.5372 - mse: 101.5372 - val_loss: 94.5425 - val_mse: 94.5425\n",
      "Epoch 41/55\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 101.5747 - mse: 101.5747 - val_loss: 94.0515 - val_mse: 94.0515\n",
      "Epoch 42/55\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 101.5682 - mse: 101.5682 - val_loss: 93.8777 - val_mse: 93.8777\n",
      "Epoch 43/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 101.5541 - mse: 101.5541 - val_loss: 93.6898 - val_mse: 93.6898\n",
      "Epoch 44/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 101.5330 - mse: 101.5330 - val_loss: 93.8858 - val_mse: 93.8858\n",
      "Epoch 45/55\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 101.5365 - mse: 101.5365 - val_loss: 94.1241 - val_mse: 94.1241\n",
      "Epoch 46/55\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 101.5637 - mse: 101.5637 - val_loss: 94.3468 - val_mse: 94.3468\n",
      "Epoch 47/55\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 101.6071 - mse: 101.6071 - val_loss: 94.3072 - val_mse: 94.3072\n",
      "Epoch 48/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 101.5493 - mse: 101.5493 - val_loss: 93.8118 - val_mse: 93.8118\n",
      "Epoch 49/55\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 101.5462 - mse: 101.5462 - val_loss: 93.3206 - val_mse: 93.3206\n",
      "Epoch 50/55\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 101.5394 - mse: 101.5394 - val_loss: 93.4950 - val_mse: 93.4950\n",
      "Epoch 51/55\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 101.5856 - mse: 101.5856 - val_loss: 93.4678 - val_mse: 93.4678\n",
      "Epoch 52/55\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 101.5315 - mse: 101.5315 - val_loss: 94.0785 - val_mse: 94.0785\n",
      "Epoch 53/55\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 101.5222 - mse: 101.5222 - val_loss: 93.8853 - val_mse: 93.8853\n",
      "Epoch 54/55\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 101.5509 - mse: 101.5509 - val_loss: 94.1186 - val_mse: 94.1186\n",
      "Epoch 55/55\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 101.5603 - mse: 101.5603 - val_loss: 93.7595 - val_mse: 93.7595\n",
      "INFO:tensorflow:Assets written to: out/111-model-ntrain=550-sigma=10.0-epochs=55.tf/assets\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 101.5303 - mse: 101.5303 - val_loss: 94.1213 - val_mse: 94.1213\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 101.5195 - mse: 101.5195 - val_loss: 93.6456 - val_mse: 93.6456\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 101.5266 - mse: 101.5266 - val_loss: 93.8119 - val_mse: 93.8119\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 101.5663 - mse: 101.5663 - val_loss: 94.0094 - val_mse: 94.0094\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 7ms/step - loss: 101.5507 - mse: 101.5507 - val_loss: 93.7316 - val_mse: 93.7316\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 101.5659 - mse: 101.5659 - val_loss: 93.5545 - val_mse: 93.5545\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 101.5307 - mse: 101.5307 - val_loss: 93.5818 - val_mse: 93.5818\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 101.5573 - mse: 101.5573 - val_loss: 93.6096 - val_mse: 93.6096\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 101.5457 - mse: 101.5457 - val_loss: 93.8898 - val_mse: 93.8898\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 101.5346 - mse: 101.5346 - val_loss: 94.1552 - val_mse: 94.1552\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 101.5302 - mse: 101.5302 - val_loss: 94.3761 - val_mse: 94.3761\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 101.5491 - mse: 101.5491 - val_loss: 94.1766 - val_mse: 94.1766\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 101.5400 - mse: 101.5400 - val_loss: 94.1070 - val_mse: 94.1070\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 101.5863 - mse: 101.5863 - val_loss: 94.1574 - val_mse: 94.1574\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 101.5700 - mse: 101.5700 - val_loss: 93.9557 - val_mse: 93.9557\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 101.5398 - mse: 101.5398 - val_loss: 94.2523 - val_mse: 94.2523\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 101.5812 - mse: 101.5812 - val_loss: 94.3761 - val_mse: 94.3761\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 101.5685 - mse: 101.5685 - val_loss: 94.1036 - val_mse: 94.1036\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 101.5566 - mse: 101.5566 - val_loss: 94.3490 - val_mse: 94.3490\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 101.5717 - mse: 101.5717 - val_loss: 93.3218 - val_mse: 93.3218\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 101.5543 - mse: 101.5543 - val_loss: 93.4512 - val_mse: 93.4512\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 101.5353 - mse: 101.5353 - val_loss: 93.4723 - val_mse: 93.4723\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 101.5384 - mse: 101.5384 - val_loss: 93.1390 - val_mse: 93.1390\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 101.5526 - mse: 101.5526 - val_loss: 93.4409 - val_mse: 93.4409\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 101.5791 - mse: 101.5791 - val_loss: 93.8042 - val_mse: 93.8042\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 101.5705 - mse: 101.5705 - val_loss: 94.4072 - val_mse: 94.4072\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 101.5995 - mse: 101.5995 - val_loss: 94.6991 - val_mse: 94.6991\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 101.5470 - mse: 101.5470 - val_loss: 94.6129 - val_mse: 94.6129\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 101.5617 - mse: 101.5617 - val_loss: 94.2336 - val_mse: 94.2336\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 101.5687 - mse: 101.5687 - val_loss: 94.0098 - val_mse: 94.0098\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 101.5860 - mse: 101.5860 - val_loss: 94.3460 - val_mse: 94.3460\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 101.5713 - mse: 101.5713 - val_loss: 94.6018 - val_mse: 94.6018\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 101.5591 - mse: 101.5591 - val_loss: 93.7709 - val_mse: 93.7709\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 101.5186 - mse: 101.5186 - val_loss: 93.7120 - val_mse: 93.7120\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 101.5448 - mse: 101.5448 - val_loss: 94.1426 - val_mse: 94.1426\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 101.5622 - mse: 101.5622 - val_loss: 94.3879 - val_mse: 94.3879\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 101.5886 - mse: 101.5886 - val_loss: 94.2645 - val_mse: 94.2645\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 101.5429 - mse: 101.5429 - val_loss: 94.4789 - val_mse: 94.4789\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 101.5953 - mse: 101.5953 - val_loss: 94.3708 - val_mse: 94.3708\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 101.5374 - mse: 101.5374 - val_loss: 94.5569 - val_mse: 94.5569\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 101.5746 - mse: 101.5746 - val_loss: 94.0640 - val_mse: 94.0640\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 101.5679 - mse: 101.5679 - val_loss: 93.8885 - val_mse: 93.8885\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 101.5538 - mse: 101.5538 - val_loss: 93.6994 - val_mse: 93.6994\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 101.5328 - mse: 101.5328 - val_loss: 93.8946 - val_mse: 93.8946\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 101.5364 - mse: 101.5364 - val_loss: 94.1319 - val_mse: 94.1319\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 101.5635 - mse: 101.5635 - val_loss: 94.3536 - val_mse: 94.3536\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 101.6069 - mse: 101.6069 - val_loss: 94.3134 - val_mse: 94.3134\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 101.5493 - mse: 101.5493 - val_loss: 93.8173 - val_mse: 93.8173\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 101.5463 - mse: 101.5463 - val_loss: 93.3253 - val_mse: 93.3253\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 101.5394 - mse: 101.5394 - val_loss: 93.4993 - val_mse: 93.4993\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 101.5856 - mse: 101.5856 - val_loss: 93.4715 - val_mse: 93.4715\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 101.5315 - mse: 101.5315 - val_loss: 94.0819 - val_mse: 94.0819\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 101.5222 - mse: 101.5222 - val_loss: 93.8883 - val_mse: 93.8883\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 101.5509 - mse: 101.5509 - val_loss: 94.1212 - val_mse: 94.1212\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 101.5603 - mse: 101.5603 - val_loss: 93.7618 - val_mse: 93.7618\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 101.5312 - mse: 101.5312 - val_loss: 94.1943 - val_mse: 94.1943\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 101.5329 - mse: 101.5329 - val_loss: 94.2606 - val_mse: 94.2606\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 101.5849 - mse: 101.5849 - val_loss: 93.4949 - val_mse: 93.4949\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 101.5519 - mse: 101.5519 - val_loss: 94.1367 - val_mse: 94.1367\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 101.5605 - mse: 101.5605 - val_loss: 93.7016 - val_mse: 93.7016\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 101.5239 - mse: 101.5239 - val_loss: 93.8677 - val_mse: 93.8677\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 101.5585 - mse: 101.5585 - val_loss: 93.8677 - val_mse: 93.8677\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 101.5577 - mse: 101.5577 - val_loss: 94.1108 - val_mse: 94.1108\n",
      "Epoch 64/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 7ms/step - loss: 101.5522 - mse: 101.5522 - val_loss: 93.8526 - val_mse: 93.8526\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 101.5789 - mse: 101.5789 - val_loss: 93.9046 - val_mse: 93.9046\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 101.5387 - mse: 101.5387 - val_loss: 93.5832 - val_mse: 93.5832\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 101.5227 - mse: 101.5227 - val_loss: 93.2022 - val_mse: 93.2022\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 101.5288 - mse: 101.5288 - val_loss: 93.0772 - val_mse: 93.0772\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 101.5798 - mse: 101.5798 - val_loss: 93.6201 - val_mse: 93.6201\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 101.5222 - mse: 101.5222 - val_loss: 93.8883 - val_mse: 93.8883\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 101.5500 - mse: 101.5500 - val_loss: 93.6756 - val_mse: 93.6756\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 101.5672 - mse: 101.5672 - val_loss: 93.8095 - val_mse: 93.8095\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 101.5268 - mse: 101.5268 - val_loss: 93.6326 - val_mse: 93.6326\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 101.5100 - mse: 101.5100 - val_loss: 93.0486 - val_mse: 93.0486\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 101.5648 - mse: 101.5648 - val_loss: 93.3789 - val_mse: 93.3789\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 101.5748 - mse: 101.5748 - val_loss: 93.9392 - val_mse: 93.9392\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 101.5429 - mse: 101.5429 - val_loss: 93.8981 - val_mse: 93.8981\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 101.5643 - mse: 101.5643 - val_loss: 94.2854 - val_mse: 94.2854\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 101.6063 - mse: 101.6063 - val_loss: 94.3866 - val_mse: 94.3866\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 101.5682 - mse: 101.5682 - val_loss: 94.1825 - val_mse: 94.1825\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 101.5954 - mse: 101.5954 - val_loss: 94.4630 - val_mse: 94.4630\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 101.5626 - mse: 101.5626 - val_loss: 94.0412 - val_mse: 94.0412\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 101.5401 - mse: 101.5401 - val_loss: 94.3591 - val_mse: 94.3591\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 101.5646 - mse: 101.5646 - val_loss: 94.2699 - val_mse: 94.2699\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 101.5439 - mse: 101.5439 - val_loss: 94.5834 - val_mse: 94.5834\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 101.5910 - mse: 101.5910 - val_loss: 94.8505 - val_mse: 94.8505\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 101.6280 - mse: 101.6280 - val_loss: 94.5653 - val_mse: 94.5653\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 101.5744 - mse: 101.5744 - val_loss: 93.7949 - val_mse: 93.7949\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 101.5408 - mse: 101.5408 - val_loss: 93.8847 - val_mse: 93.8847\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 101.5546 - mse: 101.5546 - val_loss: 93.6518 - val_mse: 93.6518\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 101.5711 - mse: 101.5711 - val_loss: 92.8472 - val_mse: 92.8472\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 101.5368 - mse: 101.5368 - val_loss: 93.0874 - val_mse: 93.0874\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 101.5421 - mse: 101.5421 - val_loss: 93.2724 - val_mse: 93.2724\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 101.5655 - mse: 101.5655 - val_loss: 93.4362 - val_mse: 93.4362\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 101.5417 - mse: 101.5417 - val_loss: 93.0219 - val_mse: 93.0219\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 101.5176 - mse: 101.5176 - val_loss: 93.1925 - val_mse: 93.1925\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 101.5672 - mse: 101.5672 - val_loss: 93.0819 - val_mse: 93.0819\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 101.5356 - mse: 101.5356 - val_loss: 92.8790 - val_mse: 92.8790\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 101.5758 - mse: 101.5758 - val_loss: 93.3376 - val_mse: 93.3376\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 101.5444 - mse: 101.5444 - val_loss: 93.3558 - val_mse: 93.3558\n",
      "INFO:tensorflow:Assets written to: out/111-model-ntrain=550-sigma=10.0-epochs=100.tf/assets\n",
      "\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 2.6126 - mse: 2.6126 - val_loss: 2.0575 - val_mse: 2.0575\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.4898 - mse: 1.4898 - val_loss: 1.2609 - val_mse: 1.2609\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9154 - mse: 0.9154 - val_loss: 0.8010 - val_mse: 0.8010\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5806 - mse: 0.5806 - val_loss: 0.5134 - val_mse: 0.5134\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.3710 - mse: 0.3710 - val_loss: 0.3338 - val_mse: 0.3338\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.2407 - mse: 0.2407 - val_loss: 0.2166 - val_mse: 0.2166\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1558 - mse: 0.1558 - val_loss: 0.1396 - val_mse: 0.1396\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1003 - mse: 0.1003 - val_loss: 0.0909 - val_mse: 0.0909\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0652 - mse: 0.0652 - val_loss: 0.0590 - val_mse: 0.0590\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0423 - mse: 0.0423 - val_loss: 0.0381 - val_mse: 0.0381\n",
      "INFO:tensorflow:Assets written to: out/111-model-ntrain=1000-sigma=0.0-epochs=10.tf/assets\n",
      "Epoch 1/55\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0273 - mse: 0.0273 - val_loss: 0.0247 - val_mse: 0.0247\n",
      "Epoch 2/55\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 3/55\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0116 - mse: 0.0116 - val_loss: 0.0105 - val_mse: 0.0105\n",
      "Epoch 4/55\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0075 - mse: 0.0075 - val_loss: 0.0068 - val_mse: 0.0068\n",
      "Epoch 5/55\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0044 - val_mse: 0.0044\n",
      "Epoch 6/55\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0032 - mse: 0.0032 - val_loss: 0.0029 - val_mse: 0.0029\n",
      "Epoch 7/55\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 0.0018 - val_mse: 0.0018\n",
      "Epoch 8/55\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 9/55\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 8.6074e-04 - mse: 8.6074e-04 - val_loss: 7.7971e-04 - val_mse: 7.7971e-04\n",
      "Epoch 10/55\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.5808e-04 - mse: 5.5808e-04 - val_loss: 5.0339e-04 - val_mse: 5.0339e-04\n",
      "Epoch 11/55\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 3.6078e-04 - mse: 3.6078e-04 - val_loss: 3.2477e-04 - val_mse: 3.2477e-04\n",
      "Epoch 12/55\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 2.3287e-04 - mse: 2.3287e-04 - val_loss: 2.1158e-04 - val_mse: 2.1158e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/55\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.5160e-04 - mse: 1.5160e-04 - val_loss: 1.3648e-04 - val_mse: 1.3648e-04\n",
      "Epoch 14/55\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 9.7848e-05 - mse: 9.7848e-05 - val_loss: 8.8439e-05 - val_mse: 8.8439e-05\n",
      "Epoch 15/55\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.3420e-05 - mse: 6.3420e-05 - val_loss: 5.7259e-05 - val_mse: 5.7259e-05\n",
      "Epoch 16/55\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.1052e-05 - mse: 4.1052e-05 - val_loss: 3.7076e-05 - val_mse: 3.7076e-05\n",
      "Epoch 17/55\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 2.6579e-05 - mse: 2.6579e-05 - val_loss: 2.4100e-05 - val_mse: 2.4100e-05\n",
      "Epoch 18/55\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.7263e-05 - mse: 1.7263e-05 - val_loss: 1.5618e-05 - val_mse: 1.5618e-05\n",
      "Epoch 19/55\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.1182e-05 - mse: 1.1182e-05 - val_loss: 1.0133e-05 - val_mse: 1.0133e-05\n",
      "Epoch 20/55\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.2619e-06 - mse: 7.2619e-06 - val_loss: 6.5851e-06 - val_mse: 6.5851e-06\n",
      "Epoch 21/55\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.7135e-06 - mse: 4.7135e-06 - val_loss: 4.2654e-06 - val_mse: 4.2654e-06\n",
      "Epoch 22/55\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 3.0555e-06 - mse: 3.0555e-06 - val_loss: 2.7620e-06 - val_mse: 2.7620e-06\n",
      "Epoch 23/55\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.9811e-06 - mse: 1.9811e-06 - val_loss: 1.7826e-06 - val_mse: 1.7826e-06\n",
      "Epoch 24/55\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.2779e-06 - mse: 1.2779e-06 - val_loss: 1.1567e-06 - val_mse: 1.1567e-06\n",
      "Epoch 25/55\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.2894e-07 - mse: 8.2894e-07 - val_loss: 7.4996e-07 - val_mse: 7.4996e-07\n",
      "Epoch 26/55\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.3777e-07 - mse: 5.3777e-07 - val_loss: 4.8492e-07 - val_mse: 4.8492e-07\n",
      "Epoch 27/55\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 3.4775e-07 - mse: 3.4775e-07 - val_loss: 3.1595e-07 - val_mse: 3.1595e-07\n",
      "Epoch 28/55\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 2.2658e-07 - mse: 2.2658e-07 - val_loss: 2.0517e-07 - val_mse: 2.0517e-07\n",
      "Epoch 29/55\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.4701e-07 - mse: 1.4701e-07 - val_loss: 1.3247e-07 - val_mse: 1.3247e-07\n",
      "Epoch 30/55\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 9.4958e-08 - mse: 9.4958e-08 - val_loss: 8.5754e-08 - val_mse: 8.5754e-08\n",
      "Epoch 31/55\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 6.1469e-08 - mse: 6.1469e-08 - val_loss: 5.5331e-08 - val_mse: 5.5331e-08\n",
      "Epoch 32/55\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.9739e-08 - mse: 3.9739e-08 - val_loss: 3.5989e-08 - val_mse: 3.5989e-08\n",
      "Epoch 33/55\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 2.5817e-08 - mse: 2.5817e-08 - val_loss: 2.3413e-08 - val_mse: 2.3413e-08\n",
      "Epoch 34/55\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.6769e-08 - mse: 1.6769e-08 - val_loss: 1.5137e-08 - val_mse: 1.5137e-08\n",
      "Epoch 35/55\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0855e-08 - mse: 1.0855e-08 - val_loss: 9.8313e-09 - val_mse: 9.8313e-09\n",
      "Epoch 36/55\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 7.0347e-09 - mse: 7.0347e-09 - val_loss: 6.3902e-09 - val_mse: 6.3902e-09\n",
      "Epoch 37/55\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.5799e-09 - mse: 4.5799e-09 - val_loss: 4.1382e-09 - val_mse: 4.1382e-09\n",
      "Epoch 38/55\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 2.9732e-09 - mse: 2.9732e-09 - val_loss: 2.7126e-09 - val_mse: 2.7126e-09\n",
      "Epoch 39/55\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.9339e-09 - mse: 1.9339e-09 - val_loss: 1.7431e-09 - val_mse: 1.7431e-09\n",
      "Epoch 40/55\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.2515e-09 - mse: 1.2515e-09 - val_loss: 1.1394e-09 - val_mse: 1.1394e-09\n",
      "Epoch 41/55\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.1599e-10 - mse: 8.1599e-10 - val_loss: 7.3786e-10 - val_mse: 7.3786e-10\n",
      "Epoch 42/55\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 5.2875e-10 - mse: 5.2875e-10 - val_loss: 4.8004e-10 - val_mse: 4.8004e-10\n",
      "Epoch 43/55\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 3.3897e-10 - mse: 3.3897e-10 - val_loss: 2.9944e-10 - val_mse: 2.9944e-10\n",
      "Epoch 44/55\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.1596e-10 - mse: 2.1596e-10 - val_loss: 1.9852e-10 - val_mse: 1.9852e-10\n",
      "Epoch 45/55\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.4645e-10 - mse: 1.4645e-10 - val_loss: 1.3566e-10 - val_mse: 1.3566e-10\n",
      "Epoch 46/55\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 9.7297e-11 - mse: 9.7297e-11 - val_loss: 8.7596e-11 - val_mse: 8.7596e-11\n",
      "Epoch 47/55\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.9103e-11 - mse: 5.9103e-11 - val_loss: 4.8518e-11 - val_mse: 4.8518e-11\n",
      "Epoch 48/55\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 3.2708e-11 - mse: 3.2708e-11 - val_loss: 2.9423e-11 - val_mse: 2.9423e-11\n",
      "Epoch 49/55\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.2147e-11 - mse: 2.2147e-11 - val_loss: 2.1916e-11 - val_mse: 2.1916e-11\n",
      "Epoch 50/55\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.8474e-11 - mse: 1.8474e-11 - val_loss: 1.9849e-11 - val_mse: 1.9849e-11\n",
      "Epoch 51/55\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.6550e-11 - mse: 1.6550e-11 - val_loss: 1.7884e-11 - val_mse: 1.7884e-11\n",
      "Epoch 52/55\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.5418e-11 - mse: 1.5418e-11 - val_loss: 1.7352e-11 - val_mse: 1.7352e-11\n",
      "Epoch 53/55\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.5006e-11 - mse: 1.5006e-11 - val_loss: 1.6663e-11 - val_mse: 1.6663e-11\n",
      "Epoch 54/55\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.4417e-11 - mse: 1.4417e-11 - val_loss: 1.5507e-11 - val_mse: 1.5507e-11\n",
      "Epoch 55/55\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.3467e-11 - mse: 1.3467e-11 - val_loss: 1.5507e-11 - val_mse: 1.5507e-11\n",
      "INFO:tensorflow:Assets written to: out/111-model-ntrain=1000-sigma=0.0-epochs=55.tf/assets\n",
      "Epoch 1/100\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.3467e-11 - mse: 1.3467e-11 - val_loss: 1.5507e-11 - val_mse: 1.5507e-11\n",
      "Epoch 2/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.3467e-11 - mse: 1.3467e-11 - val_loss: 1.5507e-11 - val_mse: 1.5507e-11\n",
      "Epoch 3/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.3471e-11 - mse: 1.3471e-11 - val_loss: 1.5441e-11 - val_mse: 1.5441e-11\n",
      "Epoch 4/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.3493e-11 - mse: 1.3493e-11 - val_loss: 1.5414e-11 - val_mse: 1.5414e-11\n",
      "Epoch 5/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.3451e-11 - mse: 1.3451e-11 - val_loss: 1.5414e-11 - val_mse: 1.5414e-11\n",
      "Epoch 6/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.3451e-11 - mse: 1.3451e-11 - val_loss: 1.5414e-11 - val_mse: 1.5414e-11\n",
      "Epoch 7/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.3451e-11 - mse: 1.3451e-11 - val_loss: 1.4933e-11 - val_mse: 1.4933e-11\n",
      "Epoch 8/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.2972e-11 - mse: 1.2972e-11 - val_loss: 1.4933e-11 - val_mse: 1.4933e-11\n",
      "Epoch 9/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.2990e-11 - mse: 1.2990e-11 - val_loss: 1.4933e-11 - val_mse: 1.4933e-11\n",
      "Epoch 10/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.2972e-11 - mse: 1.2972e-11 - val_loss: 1.4880e-11 - val_mse: 1.4880e-11\n",
      "Epoch 11/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.2976e-11 - mse: 1.2976e-11 - val_loss: 1.4933e-11 - val_mse: 1.4933e-11\n",
      "Epoch 12/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.2973e-11 - mse: 1.2973e-11 - val_loss: 1.4972e-11 - val_mse: 1.4972e-11\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 6ms/step - loss: 1.2978e-11 - mse: 1.2978e-11 - val_loss: 1.4972e-11 - val_mse: 1.4972e-11\n",
      "Epoch 14/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.2978e-11 - mse: 1.2978e-11 - val_loss: 1.4972e-11 - val_mse: 1.4972e-11\n",
      "Epoch 15/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.2978e-11 - mse: 1.2978e-11 - val_loss: 1.4972e-11 - val_mse: 1.4972e-11\n",
      "Epoch 16/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.2978e-11 - mse: 1.2978e-11 - val_loss: 1.4972e-11 - val_mse: 1.4972e-11\n",
      "Epoch 17/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.2990e-11 - mse: 1.2990e-11 - val_loss: 1.4933e-11 - val_mse: 1.4933e-11\n",
      "Epoch 18/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.2972e-11 - mse: 1.2972e-11 - val_loss: 1.4933e-11 - val_mse: 1.4933e-11\n",
      "Epoch 19/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.2972e-11 - mse: 1.2972e-11 - val_loss: 1.4933e-11 - val_mse: 1.4933e-11\n",
      "Epoch 20/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.2992e-11 - mse: 1.2992e-11 - val_loss: 1.4933e-11 - val_mse: 1.4933e-11\n",
      "Epoch 21/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.2972e-11 - mse: 1.2972e-11 - val_loss: 1.4933e-11 - val_mse: 1.4933e-11\n",
      "Epoch 22/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.2965e-11 - mse: 1.2965e-11 - val_loss: 1.4880e-11 - val_mse: 1.4880e-11\n",
      "Epoch 23/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.2952e-11 - mse: 1.2952e-11 - val_loss: 1.4359e-11 - val_mse: 1.4359e-11\n",
      "Epoch 24/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.2502e-11 - mse: 1.2502e-11 - val_loss: 1.4359e-11 - val_mse: 1.4359e-11\n",
      "Epoch 25/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.2508e-11 - mse: 1.2508e-11 - val_loss: 1.4384e-11 - val_mse: 1.4384e-11\n",
      "Epoch 26/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.2519e-11 - mse: 1.2519e-11 - val_loss: 1.4384e-11 - val_mse: 1.4384e-11\n",
      "Epoch 27/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.2506e-11 - mse: 1.2506e-11 - val_loss: 1.4384e-11 - val_mse: 1.4384e-11\n",
      "Epoch 28/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.2516e-11 - mse: 1.2516e-11 - val_loss: 1.4384e-11 - val_mse: 1.4384e-11\n",
      "Epoch 29/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.2491e-11 - mse: 1.2491e-11 - val_loss: 1.4384e-11 - val_mse: 1.4384e-11\n",
      "Epoch 30/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.2506e-11 - mse: 1.2506e-11 - val_loss: 1.4384e-11 - val_mse: 1.4384e-11\n",
      "Epoch 31/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.2506e-11 - mse: 1.2506e-11 - val_loss: 1.4359e-11 - val_mse: 1.4359e-11\n",
      "Epoch 32/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.2502e-11 - mse: 1.2502e-11 - val_loss: 1.4359e-11 - val_mse: 1.4359e-11\n",
      "Epoch 33/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.2502e-11 - mse: 1.2502e-11 - val_loss: 1.4384e-11 - val_mse: 1.4384e-11\n",
      "Epoch 34/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.2506e-11 - mse: 1.2506e-11 - val_loss: 1.4384e-11 - val_mse: 1.4384e-11\n",
      "Epoch 35/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.2481e-11 - mse: 1.2481e-11 - val_loss: 1.4384e-11 - val_mse: 1.4384e-11\n",
      "Epoch 36/100\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.2472e-11 - mse: 1.2472e-11 - val_loss: 1.4384e-11 - val_mse: 1.4384e-11\n",
      "Epoch 37/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.2025e-11 - mse: 1.2025e-11 - val_loss: 1.3771e-11 - val_mse: 1.3771e-11\n",
      "Epoch 38/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.1960e-11 - mse: 1.1960e-11 - val_loss: 1.3771e-11 - val_mse: 1.3771e-11\n",
      "Epoch 39/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.1960e-11 - mse: 1.1960e-11 - val_loss: 1.3771e-11 - val_mse: 1.3771e-11\n",
      "Epoch 40/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.1960e-11 - mse: 1.1960e-11 - val_loss: 1.3771e-11 - val_mse: 1.3771e-11\n",
      "Epoch 41/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.1961e-11 - mse: 1.1961e-11 - val_loss: 1.3838e-11 - val_mse: 1.3838e-11\n",
      "Epoch 42/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.1985e-11 - mse: 1.1985e-11 - val_loss: 1.3838e-11 - val_mse: 1.3838e-11\n",
      "Epoch 43/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.2007e-11 - mse: 1.2007e-11 - val_loss: 1.3841e-11 - val_mse: 1.3841e-11\n",
      "Epoch 44/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.2002e-11 - mse: 1.2002e-11 - val_loss: 1.3749e-11 - val_mse: 1.3749e-11\n",
      "Epoch 45/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.1991e-11 - mse: 1.1991e-11 - val_loss: 1.3749e-11 - val_mse: 1.3749e-11\n",
      "Epoch 46/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.1977e-11 - mse: 1.1977e-11 - val_loss: 1.3771e-11 - val_mse: 1.3771e-11\n",
      "Epoch 47/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.1972e-11 - mse: 1.1972e-11 - val_loss: 1.3841e-11 - val_mse: 1.3841e-11\n",
      "Epoch 48/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.2002e-11 - mse: 1.2002e-11 - val_loss: 1.3841e-11 - val_mse: 1.3841e-11\n",
      "Epoch 49/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.1999e-11 - mse: 1.1999e-11 - val_loss: 1.3841e-11 - val_mse: 1.3841e-11\n",
      "Epoch 50/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.1999e-11 - mse: 1.1999e-11 - val_loss: 1.3841e-11 - val_mse: 1.3841e-11\n",
      "Epoch 51/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.1991e-11 - mse: 1.1991e-11 - val_loss: 1.3838e-11 - val_mse: 1.3838e-11\n",
      "Epoch 52/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.2001e-11 - mse: 1.2001e-11 - val_loss: 1.3841e-11 - val_mse: 1.3841e-11\n",
      "Epoch 53/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.1998e-11 - mse: 1.1998e-11 - val_loss: 1.3838e-11 - val_mse: 1.3838e-11\n",
      "Epoch 54/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.1980e-11 - mse: 1.1980e-11 - val_loss: 1.3207e-11 - val_mse: 1.3207e-11\n",
      "Epoch 55/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.1485e-11 - mse: 1.1485e-11 - val_loss: 1.3207e-11 - val_mse: 1.3207e-11\n",
      "Epoch 56/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.1485e-11 - mse: 1.1485e-11 - val_loss: 1.3207e-11 - val_mse: 1.3207e-11\n",
      "Epoch 57/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.1495e-11 - mse: 1.1495e-11 - val_loss: 1.3264e-11 - val_mse: 1.3264e-11\n",
      "Epoch 58/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.1493e-11 - mse: 1.1493e-11 - val_loss: 1.3207e-11 - val_mse: 1.3207e-11\n",
      "Epoch 59/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.1485e-11 - mse: 1.1485e-11 - val_loss: 1.2692e-11 - val_mse: 1.2692e-11\n",
      "Epoch 60/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.1054e-11 - mse: 1.1054e-11 - val_loss: 1.2656e-11 - val_mse: 1.2656e-11\n",
      "Epoch 61/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.1083e-11 - mse: 1.1083e-11 - val_loss: 1.2725e-11 - val_mse: 1.2725e-11\n",
      "Epoch 62/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.1084e-11 - mse: 1.1084e-11 - val_loss: 1.2725e-11 - val_mse: 1.2725e-11\n",
      "Epoch 63/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.1084e-11 - mse: 1.1084e-11 - val_loss: 1.2260e-11 - val_mse: 1.2260e-11\n",
      "Epoch 64/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0615e-11 - mse: 1.0615e-11 - val_loss: 1.2281e-11 - val_mse: 1.2281e-11\n",
      "Epoch 65/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0610e-11 - mse: 1.0610e-11 - val_loss: 1.2281e-11 - val_mse: 1.2281e-11\n",
      "Epoch 66/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0611e-11 - mse: 1.0611e-11 - val_loss: 1.2260e-11 - val_mse: 1.2260e-11\n",
      "Epoch 67/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0608e-11 - mse: 1.0608e-11 - val_loss: 1.2260e-11 - val_mse: 1.2260e-11\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 6ms/step - loss: 1.0608e-11 - mse: 1.0608e-11 - val_loss: 1.2260e-11 - val_mse: 1.2260e-11\n",
      "Epoch 69/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0608e-11 - mse: 1.0608e-11 - val_loss: 1.2237e-11 - val_mse: 1.2237e-11\n",
      "Epoch 70/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0611e-11 - mse: 1.0611e-11 - val_loss: 1.2260e-11 - val_mse: 1.2260e-11\n",
      "Epoch 71/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0608e-11 - mse: 1.0608e-11 - val_loss: 1.2260e-11 - val_mse: 1.2260e-11\n",
      "Epoch 72/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.0608e-11 - mse: 1.0608e-11 - val_loss: 1.2281e-11 - val_mse: 1.2281e-11\n",
      "Epoch 73/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.0618e-11 - mse: 1.0618e-11 - val_loss: 1.2281e-11 - val_mse: 1.2281e-11\n",
      "Epoch 74/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0610e-11 - mse: 1.0610e-11 - val_loss: 1.2281e-11 - val_mse: 1.2281e-11\n",
      "Epoch 75/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.0612e-11 - mse: 1.0612e-11 - val_loss: 1.2228e-11 - val_mse: 1.2228e-11\n",
      "Epoch 76/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0601e-11 - mse: 1.0601e-11 - val_loss: 1.2228e-11 - val_mse: 1.2228e-11\n",
      "Epoch 77/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0601e-11 - mse: 1.0601e-11 - val_loss: 1.2228e-11 - val_mse: 1.2228e-11\n",
      "Epoch 78/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.0601e-11 - mse: 1.0601e-11 - val_loss: 1.2228e-11 - val_mse: 1.2228e-11\n",
      "Epoch 79/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.0601e-11 - mse: 1.0601e-11 - val_loss: 1.2281e-11 - val_mse: 1.2281e-11\n",
      "Epoch 80/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.0610e-11 - mse: 1.0610e-11 - val_loss: 1.2260e-11 - val_mse: 1.2260e-11\n",
      "Epoch 81/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0608e-11 - mse: 1.0608e-11 - val_loss: 1.2260e-11 - val_mse: 1.2260e-11\n",
      "Epoch 82/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0608e-11 - mse: 1.0608e-11 - val_loss: 1.2260e-11 - val_mse: 1.2260e-11\n",
      "Epoch 83/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.0622e-11 - mse: 1.0622e-11 - val_loss: 1.2237e-11 - val_mse: 1.2237e-11\n",
      "Epoch 84/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.0608e-11 - mse: 1.0608e-11 - val_loss: 1.2237e-11 - val_mse: 1.2237e-11\n",
      "Epoch 85/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.0613e-11 - mse: 1.0613e-11 - val_loss: 1.2260e-11 - val_mse: 1.2260e-11\n",
      "Epoch 86/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0619e-11 - mse: 1.0619e-11 - val_loss: 1.2281e-11 - val_mse: 1.2281e-11\n",
      "Epoch 87/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0610e-11 - mse: 1.0610e-11 - val_loss: 1.2281e-11 - val_mse: 1.2281e-11\n",
      "Epoch 88/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0610e-11 - mse: 1.0610e-11 - val_loss: 1.2260e-11 - val_mse: 1.2260e-11\n",
      "Epoch 89/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0606e-11 - mse: 1.0606e-11 - val_loss: 1.2228e-11 - val_mse: 1.2228e-11\n",
      "Epoch 90/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.0615e-11 - mse: 1.0615e-11 - val_loss: 1.2298e-11 - val_mse: 1.2298e-11\n",
      "Epoch 91/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0615e-11 - mse: 1.0615e-11 - val_loss: 1.2298e-11 - val_mse: 1.2298e-11\n",
      "Epoch 92/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0615e-11 - mse: 1.0615e-11 - val_loss: 1.2298e-11 - val_mse: 1.2298e-11\n",
      "Epoch 93/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.0615e-11 - mse: 1.0615e-11 - val_loss: 1.2298e-11 - val_mse: 1.2298e-11\n",
      "Epoch 94/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0615e-11 - mse: 1.0615e-11 - val_loss: 1.2298e-11 - val_mse: 1.2298e-11\n",
      "Epoch 95/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.0615e-11 - mse: 1.0615e-11 - val_loss: 1.2298e-11 - val_mse: 1.2298e-11\n",
      "Epoch 96/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0615e-11 - mse: 1.0615e-11 - val_loss: 1.2298e-11 - val_mse: 1.2298e-11\n",
      "Epoch 97/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0615e-11 - mse: 1.0615e-11 - val_loss: 1.2298e-11 - val_mse: 1.2298e-11\n",
      "Epoch 98/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.0615e-11 - mse: 1.0615e-11 - val_loss: 1.2298e-11 - val_mse: 1.2298e-11\n",
      "Epoch 99/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.0615e-11 - mse: 1.0615e-11 - val_loss: 1.2298e-11 - val_mse: 1.2298e-11\n",
      "Epoch 100/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0615e-11 - mse: 1.0615e-11 - val_loss: 1.2298e-11 - val_mse: 1.2298e-11\n",
      "INFO:tensorflow:Assets written to: out/111-model-ntrain=1000-sigma=0.0-epochs=100.tf/assets\n",
      "\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 1s 13ms/step - loss: 3.4971 - mse: 3.4971 - val_loss: 2.6866 - val_mse: 2.6866\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.4232 - mse: 2.4232 - val_loss: 1.9336 - val_mse: 1.9336\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.8679 - mse: 1.8679 - val_loss: 1.5050 - val_mse: 1.5050\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.5417 - mse: 1.5417 - val_loss: 1.2422 - val_mse: 1.2422\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.3379 - mse: 1.3379 - val_loss: 1.0849 - val_mse: 1.0849\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.2120 - mse: 1.2120 - val_loss: 0.9815 - val_mse: 0.9815\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.1274 - mse: 1.1274 - val_loss: 0.9176 - val_mse: 0.9176\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.0734 - mse: 1.0734 - val_loss: 0.8802 - val_mse: 0.8802\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.0401 - mse: 1.0401 - val_loss: 0.8560 - val_mse: 0.8560\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.0168 - mse: 1.0168 - val_loss: 0.8413 - val_mse: 0.8413\n",
      "INFO:tensorflow:Assets written to: out/111-model-ntrain=1000-sigma=1.0-epochs=10.tf/assets\n",
      "Epoch 1/55\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.0014 - mse: 1.0014 - val_loss: 0.8324 - val_mse: 0.8324\n",
      "Epoch 2/55\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9917 - mse: 0.9917 - val_loss: 0.8279 - val_mse: 0.8279\n",
      "Epoch 3/55\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9859 - mse: 0.9859 - val_loss: 0.8257 - val_mse: 0.8257\n",
      "Epoch 4/55\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9819 - mse: 0.9819 - val_loss: 0.8247 - val_mse: 0.8247\n",
      "Epoch 5/55\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9793 - mse: 0.9793 - val_loss: 0.8254 - val_mse: 0.8254\n",
      "Epoch 6/55\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9782 - mse: 0.9782 - val_loss: 0.8254 - val_mse: 0.8254\n",
      "Epoch 7/55\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9768 - mse: 0.9768 - val_loss: 0.8256 - val_mse: 0.8256\n",
      "Epoch 8/55\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9762 - mse: 0.9762 - val_loss: 0.8262 - val_mse: 0.8262\n",
      "Epoch 9/55\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9758 - mse: 0.9758 - val_loss: 0.8267 - val_mse: 0.8267\n",
      "Epoch 10/55\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9753 - mse: 0.9753 - val_loss: 0.8275 - val_mse: 0.8275\n",
      "Epoch 11/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9752 - mse: 0.9752 - val_loss: 0.8276 - val_mse: 0.8276\n",
      "Epoch 12/55\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.9751 - mse: 0.9751 - val_loss: 0.8290 - val_mse: 0.8290\n",
      "Epoch 13/55\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9750 - mse: 0.9750 - val_loss: 0.8286 - val_mse: 0.8286\n",
      "Epoch 14/55\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9749 - mse: 0.9749 - val_loss: 0.8284 - val_mse: 0.8284\n",
      "Epoch 15/55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9748 - mse: 0.9748 - val_loss: 0.8301 - val_mse: 0.8301\n",
      "Epoch 16/55\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9750 - mse: 0.9750 - val_loss: 0.8290 - val_mse: 0.8290\n",
      "Epoch 17/55\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9749 - mse: 0.9749 - val_loss: 0.8292 - val_mse: 0.8292\n",
      "Epoch 18/55\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.9748 - mse: 0.9748 - val_loss: 0.8302 - val_mse: 0.8302\n",
      "Epoch 19/55\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.9748 - mse: 0.9748 - val_loss: 0.8285 - val_mse: 0.8285\n",
      "Epoch 20/55\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.9747 - mse: 0.9747 - val_loss: 0.8292 - val_mse: 0.8292\n",
      "Epoch 21/55\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.9746 - mse: 0.9746 - val_loss: 0.8295 - val_mse: 0.8295\n",
      "Epoch 22/55\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9748 - mse: 0.9748 - val_loss: 0.8289 - val_mse: 0.8289\n",
      "Epoch 23/55\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9751 - mse: 0.9751 - val_loss: 0.8294 - val_mse: 0.8294\n",
      "Epoch 24/55\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.9748 - mse: 0.9748 - val_loss: 0.8287 - val_mse: 0.8287\n",
      "Epoch 25/55\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.9750 - mse: 0.9750 - val_loss: 0.8283 - val_mse: 0.8283\n",
      "Epoch 26/55\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.9747 - mse: 0.9747 - val_loss: 0.8292 - val_mse: 0.8292\n",
      "Epoch 27/55\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.9745 - mse: 0.9745 - val_loss: 0.8284 - val_mse: 0.8284\n",
      "Epoch 28/55\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.9748 - mse: 0.9748 - val_loss: 0.8283 - val_mse: 0.8283\n",
      "Epoch 29/55\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.9752 - mse: 0.9752 - val_loss: 0.8290 - val_mse: 0.8290\n",
      "Epoch 30/55\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.9748 - mse: 0.9748 - val_loss: 0.8290 - val_mse: 0.8290\n",
      "Epoch 31/55\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.9752 - mse: 0.9752 - val_loss: 0.8282 - val_mse: 0.8282\n",
      "Epoch 32/55\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.9746 - mse: 0.9746 - val_loss: 0.8278 - val_mse: 0.8278\n",
      "Epoch 33/55\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.9749 - mse: 0.9749 - val_loss: 0.8283 - val_mse: 0.8283\n",
      "Epoch 34/55\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.9746 - mse: 0.9746 - val_loss: 0.8293 - val_mse: 0.8293\n",
      "Epoch 35/55\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.9748 - mse: 0.9748 - val_loss: 0.8284 - val_mse: 0.8284\n",
      "Epoch 36/55\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.9745 - mse: 0.9745 - val_loss: 0.8288 - val_mse: 0.8288\n",
      "Epoch 37/55\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.9746 - mse: 0.9746 - val_loss: 0.8294 - val_mse: 0.8294\n",
      "Epoch 38/55\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.9748 - mse: 0.9748 - val_loss: 0.8283 - val_mse: 0.8283\n",
      "Epoch 39/55\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.9748 - mse: 0.9748 - val_loss: 0.8283 - val_mse: 0.8283\n",
      "Epoch 40/55\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.9749 - mse: 0.9749 - val_loss: 0.8280 - val_mse: 0.8280\n",
      "Epoch 41/55\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.9748 - mse: 0.9748 - val_loss: 0.8278 - val_mse: 0.8278\n",
      "Epoch 42/55\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.9748 - mse: 0.9748 - val_loss: 0.8280 - val_mse: 0.8280\n",
      "Epoch 43/55\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.9749 - mse: 0.9749 - val_loss: 0.8279 - val_mse: 0.8279\n",
      "Epoch 44/55\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9749 - mse: 0.9749 - val_loss: 0.8275 - val_mse: 0.8275\n",
      "Epoch 45/55\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.9752 - mse: 0.9752 - val_loss: 0.8280 - val_mse: 0.8280\n",
      "Epoch 46/55\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.9751 - mse: 0.9751 - val_loss: 0.8278 - val_mse: 0.8278\n",
      "Epoch 47/55\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.9747 - mse: 0.9747 - val_loss: 0.8287 - val_mse: 0.8287\n",
      "Epoch 48/55\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.9748 - mse: 0.9748 - val_loss: 0.8294 - val_mse: 0.8294\n",
      "Epoch 49/55\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.9749 - mse: 0.9749 - val_loss: 0.8299 - val_mse: 0.8299\n",
      "Epoch 50/55\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.9748 - mse: 0.9748 - val_loss: 0.8300 - val_mse: 0.8300\n",
      "Epoch 51/55\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.9749 - mse: 0.9749 - val_loss: 0.8311 - val_mse: 0.8311\n",
      "Epoch 52/55\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.9747 - mse: 0.9747 - val_loss: 0.8304 - val_mse: 0.8304\n",
      "Epoch 53/55\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.9749 - mse: 0.9749 - val_loss: 0.8293 - val_mse: 0.8293\n",
      "Epoch 54/55\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.9748 - mse: 0.9748 - val_loss: 0.8289 - val_mse: 0.8289\n",
      "Epoch 55/55\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9749 - mse: 0.9749 - val_loss: 0.8296 - val_mse: 0.8296\n",
      "INFO:tensorflow:Assets written to: out/111-model-ntrain=1000-sigma=1.0-epochs=55.tf/assets\n",
      "Epoch 1/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.9746 - mse: 0.9746 - val_loss: 0.8292 - val_mse: 0.8292\n",
      "Epoch 2/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9747 - mse: 0.9747 - val_loss: 0.8292 - val_mse: 0.8292\n",
      "Epoch 3/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9748 - mse: 0.9748 - val_loss: 0.8291 - val_mse: 0.8291\n",
      "Epoch 4/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9748 - mse: 0.9748 - val_loss: 0.8291 - val_mse: 0.8291\n",
      "Epoch 5/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9747 - mse: 0.9747 - val_loss: 0.8298 - val_mse: 0.8298\n",
      "Epoch 6/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9750 - mse: 0.9750 - val_loss: 0.8298 - val_mse: 0.8298\n",
      "Epoch 7/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9748 - mse: 0.9748 - val_loss: 0.8295 - val_mse: 0.8295\n",
      "Epoch 8/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9749 - mse: 0.9749 - val_loss: 0.8294 - val_mse: 0.8294\n",
      "Epoch 9/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9749 - mse: 0.9749 - val_loss: 0.8296 - val_mse: 0.8296\n",
      "Epoch 10/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9747 - mse: 0.9747 - val_loss: 0.8300 - val_mse: 0.8300\n",
      "Epoch 11/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9749 - mse: 0.9749 - val_loss: 0.8297 - val_mse: 0.8297\n",
      "Epoch 12/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9749 - mse: 0.9749 - val_loss: 0.8308 - val_mse: 0.8308\n",
      "Epoch 13/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9749 - mse: 0.9749 - val_loss: 0.8301 - val_mse: 0.8301\n",
      "Epoch 14/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9748 - mse: 0.9748 - val_loss: 0.8296 - val_mse: 0.8296\n",
      "Epoch 15/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9748 - mse: 0.9748 - val_loss: 0.8310 - val_mse: 0.8310\n",
      "Epoch 16/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9749 - mse: 0.9749 - val_loss: 0.8297 - val_mse: 0.8297\n",
      "Epoch 17/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9749 - mse: 0.9749 - val_loss: 0.8298 - val_mse: 0.8298\n",
      "Epoch 18/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9748 - mse: 0.9748 - val_loss: 0.8307 - val_mse: 0.8307\n",
      "Epoch 19/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9748 - mse: 0.9748 - val_loss: 0.8289 - val_mse: 0.8289\n",
      "Epoch 20/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9747 - mse: 0.9747 - val_loss: 0.8296 - val_mse: 0.8296\n",
      "Epoch 21/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9746 - mse: 0.9746 - val_loss: 0.8297 - val_mse: 0.8297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9748 - mse: 0.9748 - val_loss: 0.8291 - val_mse: 0.8291\n",
      "Epoch 23/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9751 - mse: 0.9751 - val_loss: 0.8296 - val_mse: 0.8296\n",
      "Epoch 24/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9748 - mse: 0.9748 - val_loss: 0.8288 - val_mse: 0.8288\n",
      "Epoch 25/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9750 - mse: 0.9750 - val_loss: 0.8285 - val_mse: 0.8285\n",
      "Epoch 26/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9747 - mse: 0.9747 - val_loss: 0.8293 - val_mse: 0.8293\n",
      "Epoch 27/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9745 - mse: 0.9745 - val_loss: 0.8285 - val_mse: 0.8285\n",
      "Epoch 28/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9748 - mse: 0.9748 - val_loss: 0.8284 - val_mse: 0.8284\n",
      "Epoch 29/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9752 - mse: 0.9752 - val_loss: 0.8291 - val_mse: 0.8291\n",
      "Epoch 30/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9748 - mse: 0.9748 - val_loss: 0.8290 - val_mse: 0.8290\n",
      "Epoch 31/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9752 - mse: 0.9752 - val_loss: 0.8283 - val_mse: 0.8283\n",
      "Epoch 32/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9746 - mse: 0.9746 - val_loss: 0.8279 - val_mse: 0.8279\n",
      "Epoch 33/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9749 - mse: 0.9749 - val_loss: 0.8283 - val_mse: 0.8283\n",
      "Epoch 34/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9746 - mse: 0.9746 - val_loss: 0.8293 - val_mse: 0.8293\n",
      "Epoch 35/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9748 - mse: 0.9748 - val_loss: 0.8284 - val_mse: 0.8284\n",
      "Epoch 36/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9745 - mse: 0.9745 - val_loss: 0.8288 - val_mse: 0.8288\n",
      "Epoch 37/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9746 - mse: 0.9746 - val_loss: 0.8294 - val_mse: 0.8294\n",
      "Epoch 38/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9748 - mse: 0.9748 - val_loss: 0.8284 - val_mse: 0.8284\n",
      "Epoch 39/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9748 - mse: 0.9748 - val_loss: 0.8283 - val_mse: 0.8283\n",
      "Epoch 40/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9749 - mse: 0.9749 - val_loss: 0.8280 - val_mse: 0.8280\n",
      "Epoch 41/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9748 - mse: 0.9748 - val_loss: 0.8278 - val_mse: 0.8278\n",
      "Epoch 42/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9748 - mse: 0.9748 - val_loss: 0.8280 - val_mse: 0.8280\n",
      "Epoch 43/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9749 - mse: 0.9749 - val_loss: 0.8279 - val_mse: 0.8279\n",
      "Epoch 44/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9749 - mse: 0.9749 - val_loss: 0.8275 - val_mse: 0.8275\n",
      "Epoch 45/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9752 - mse: 0.9752 - val_loss: 0.8280 - val_mse: 0.8280\n",
      "Epoch 46/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9751 - mse: 0.9751 - val_loss: 0.8278 - val_mse: 0.8278\n",
      "Epoch 47/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9747 - mse: 0.9747 - val_loss: 0.8287 - val_mse: 0.8287\n",
      "Epoch 48/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9748 - mse: 0.9748 - val_loss: 0.8294 - val_mse: 0.8294\n",
      "Epoch 49/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9749 - mse: 0.9749 - val_loss: 0.8299 - val_mse: 0.8299\n",
      "Epoch 50/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9748 - mse: 0.9748 - val_loss: 0.8300 - val_mse: 0.8300\n",
      "Epoch 51/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9749 - mse: 0.9749 - val_loss: 0.8311 - val_mse: 0.8311\n",
      "Epoch 52/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9747 - mse: 0.9747 - val_loss: 0.8304 - val_mse: 0.8304\n",
      "Epoch 53/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9749 - mse: 0.9749 - val_loss: 0.8293 - val_mse: 0.8293\n",
      "Epoch 54/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9748 - mse: 0.9748 - val_loss: 0.8289 - val_mse: 0.8289\n",
      "Epoch 55/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9749 - mse: 0.9749 - val_loss: 0.8296 - val_mse: 0.8296\n",
      "Epoch 56/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9746 - mse: 0.9746 - val_loss: 0.8294 - val_mse: 0.8294\n",
      "Epoch 57/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9747 - mse: 0.9747 - val_loss: 0.8296 - val_mse: 0.8296\n",
      "Epoch 58/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9747 - mse: 0.9747 - val_loss: 0.8292 - val_mse: 0.8292\n",
      "Epoch 59/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9750 - mse: 0.9750 - val_loss: 0.8278 - val_mse: 0.8278\n",
      "Epoch 60/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9749 - mse: 0.9749 - val_loss: 0.8286 - val_mse: 0.8286\n",
      "Epoch 61/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9748 - mse: 0.9748 - val_loss: 0.8294 - val_mse: 0.8294\n",
      "Epoch 62/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9749 - mse: 0.9749 - val_loss: 0.8299 - val_mse: 0.8299\n",
      "Epoch 63/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9751 - mse: 0.9751 - val_loss: 0.8296 - val_mse: 0.8296\n",
      "Epoch 64/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9748 - mse: 0.9748 - val_loss: 0.8298 - val_mse: 0.8298\n",
      "Epoch 65/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9749 - mse: 0.9749 - val_loss: 0.8301 - val_mse: 0.8301\n",
      "Epoch 66/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9746 - mse: 0.9746 - val_loss: 0.8295 - val_mse: 0.8295\n",
      "Epoch 67/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9746 - mse: 0.9746 - val_loss: 0.8292 - val_mse: 0.8292\n",
      "Epoch 68/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9747 - mse: 0.9747 - val_loss: 0.8284 - val_mse: 0.8284\n",
      "Epoch 69/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9750 - mse: 0.9750 - val_loss: 0.8288 - val_mse: 0.8288\n",
      "Epoch 70/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9747 - mse: 0.9747 - val_loss: 0.8287 - val_mse: 0.8287\n",
      "Epoch 71/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9750 - mse: 0.9750 - val_loss: 0.8288 - val_mse: 0.8288\n",
      "Epoch 72/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9750 - mse: 0.9750 - val_loss: 0.8292 - val_mse: 0.8292\n",
      "Epoch 73/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9747 - mse: 0.9747 - val_loss: 0.8286 - val_mse: 0.8286\n",
      "Epoch 74/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9747 - mse: 0.9747 - val_loss: 0.8297 - val_mse: 0.8297\n",
      "Epoch 75/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9750 - mse: 0.9750 - val_loss: 0.8285 - val_mse: 0.8285\n",
      "Epoch 76/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9749 - mse: 0.9749 - val_loss: 0.8286 - val_mse: 0.8286\n",
      "Epoch 77/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9749 - mse: 0.9749 - val_loss: 0.8300 - val_mse: 0.8300\n",
      "Epoch 78/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9748 - mse: 0.9748 - val_loss: 0.8305 - val_mse: 0.8305\n",
      "Epoch 79/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9751 - mse: 0.9751 - val_loss: 0.8311 - val_mse: 0.8311\n",
      "Epoch 80/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9751 - mse: 0.9751 - val_loss: 0.8324 - val_mse: 0.8324\n",
      "Epoch 81/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9751 - mse: 0.9751 - val_loss: 0.8312 - val_mse: 0.8312\n",
      "Epoch 82/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9747 - mse: 0.9747 - val_loss: 0.8299 - val_mse: 0.8299\n",
      "Epoch 83/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9748 - mse: 0.9748 - val_loss: 0.8291 - val_mse: 0.8291\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9748 - mse: 0.9748 - val_loss: 0.8291 - val_mse: 0.8291\n",
      "Epoch 85/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9747 - mse: 0.9747 - val_loss: 0.8293 - val_mse: 0.8293\n",
      "Epoch 86/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9750 - mse: 0.9750 - val_loss: 0.8292 - val_mse: 0.8292\n",
      "Epoch 87/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9747 - mse: 0.9747 - val_loss: 0.8290 - val_mse: 0.8290\n",
      "Epoch 88/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9750 - mse: 0.9750 - val_loss: 0.8294 - val_mse: 0.8294\n",
      "Epoch 89/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9746 - mse: 0.9746 - val_loss: 0.8295 - val_mse: 0.8295\n",
      "Epoch 90/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9747 - mse: 0.9747 - val_loss: 0.8294 - val_mse: 0.8294\n",
      "Epoch 91/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9748 - mse: 0.9748 - val_loss: 0.8297 - val_mse: 0.8297\n",
      "Epoch 92/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9750 - mse: 0.9750 - val_loss: 0.8293 - val_mse: 0.8293\n",
      "Epoch 93/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9747 - mse: 0.9747 - val_loss: 0.8299 - val_mse: 0.8299\n",
      "Epoch 94/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9746 - mse: 0.9746 - val_loss: 0.8296 - val_mse: 0.8296\n",
      "Epoch 95/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9747 - mse: 0.9747 - val_loss: 0.8293 - val_mse: 0.8293\n",
      "Epoch 96/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9746 - mse: 0.9746 - val_loss: 0.8290 - val_mse: 0.8290\n",
      "Epoch 97/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9748 - mse: 0.9748 - val_loss: 0.8290 - val_mse: 0.8290\n",
      "Epoch 98/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9747 - mse: 0.9747 - val_loss: 0.8289 - val_mse: 0.8289\n",
      "Epoch 99/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9748 - mse: 0.9748 - val_loss: 0.8285 - val_mse: 0.8285\n",
      "Epoch 100/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9745 - mse: 0.9745 - val_loss: 0.8285 - val_mse: 0.8285\n",
      "INFO:tensorflow:Assets written to: out/111-model-ntrain=1000-sigma=1.0-epochs=100.tf/assets\n",
      "\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 1s 11ms/step - loss: 99.3098 - mse: 99.3098 - val_loss: 83.0102 - val_mse: 83.0102\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 98.5891 - mse: 98.5891 - val_loss: 82.6665 - val_mse: 82.6665\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 98.1891 - mse: 98.1891 - val_loss: 82.5206 - val_mse: 82.5206\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.9318 - mse: 97.9318 - val_loss: 82.4771 - val_mse: 82.4771\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.7661 - mse: 97.7661 - val_loss: 82.5742 - val_mse: 82.5742\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.7045 - mse: 97.7045 - val_loss: 82.5936 - val_mse: 82.5936\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.6088 - mse: 97.6088 - val_loss: 82.6169 - val_mse: 82.6169\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.5693 - mse: 97.5693 - val_loss: 82.6655 - val_mse: 82.6655\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.5514 - mse: 97.5514 - val_loss: 82.7185 - val_mse: 82.7185\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.5120 - mse: 97.5120 - val_loss: 82.7945 - val_mse: 82.7945\n",
      "INFO:tensorflow:Assets written to: out/111-model-ntrain=1000-sigma=10.0-epochs=10.tf/assets\n",
      "Epoch 1/55\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 97.4839 - mse: 97.4839 - val_loss: 82.7715 - val_mse: 82.7715\n",
      "Epoch 2/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4772 - mse: 97.4772 - val_loss: 82.7908 - val_mse: 82.7908\n",
      "Epoch 3/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4826 - mse: 97.4826 - val_loss: 82.8019 - val_mse: 82.8019\n",
      "Epoch 4/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4805 - mse: 97.4805 - val_loss: 82.8176 - val_mse: 82.8176\n",
      "Epoch 5/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4717 - mse: 97.4717 - val_loss: 82.9060 - val_mse: 82.9060\n",
      "Epoch 6/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.5034 - mse: 97.5034 - val_loss: 82.9199 - val_mse: 82.9199\n",
      "Epoch 7/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4860 - mse: 97.4860 - val_loss: 82.9052 - val_mse: 82.9052\n",
      "Epoch 8/55\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 97.4875 - mse: 97.4875 - val_loss: 82.9060 - val_mse: 82.9060\n",
      "Epoch 9/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4890 - mse: 97.4890 - val_loss: 82.9285 - val_mse: 82.9285\n",
      "Epoch 10/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4727 - mse: 97.4727 - val_loss: 82.9767 - val_mse: 82.9767\n",
      "Epoch 11/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4896 - mse: 97.4896 - val_loss: 82.9471 - val_mse: 82.9471\n",
      "Epoch 12/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4941 - mse: 97.4941 - val_loss: 83.0585 - val_mse: 83.0585\n",
      "Epoch 13/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4874 - mse: 97.4874 - val_loss: 82.9948 - val_mse: 82.9948\n",
      "Epoch 14/55\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 97.4787 - mse: 97.4787 - val_loss: 82.9510 - val_mse: 82.9510\n",
      "Epoch 15/55\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 97.4755 - mse: 97.4755 - val_loss: 83.0947 - val_mse: 83.0947\n",
      "Epoch 16/55\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 97.4929 - mse: 97.4929 - val_loss: 82.9650 - val_mse: 82.9650\n",
      "Epoch 17/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4872 - mse: 97.4872 - val_loss: 82.9786 - val_mse: 82.9786\n",
      "Epoch 18/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4834 - mse: 97.4834 - val_loss: 83.0644 - val_mse: 83.0644\n",
      "Epoch 19/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4764 - mse: 97.4764 - val_loss: 82.8861 - val_mse: 82.8861\n",
      "Epoch 20/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4719 - mse: 97.4719 - val_loss: 82.9533 - val_mse: 82.9533\n",
      "Epoch 21/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4562 - mse: 97.4562 - val_loss: 82.9707 - val_mse: 82.9707\n",
      "Epoch 22/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4759 - mse: 97.4759 - val_loss: 82.9108 - val_mse: 82.9108\n",
      "Epoch 23/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.5113 - mse: 97.5113 - val_loss: 82.9551 - val_mse: 82.9551\n",
      "Epoch 24/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4818 - mse: 97.4818 - val_loss: 82.8810 - val_mse: 82.8810\n",
      "Epoch 25/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4961 - mse: 97.4961 - val_loss: 82.8450 - val_mse: 82.8450\n",
      "Epoch 26/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4704 - mse: 97.4704 - val_loss: 82.9262 - val_mse: 82.9262\n",
      "Epoch 27/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4522 - mse: 97.4522 - val_loss: 82.8509 - val_mse: 82.8509\n",
      "Epoch 28/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4801 - mse: 97.4801 - val_loss: 82.8393 - val_mse: 82.8393\n",
      "Epoch 29/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.5195 - mse: 97.5195 - val_loss: 82.9046 - val_mse: 82.9046\n",
      "Epoch 30/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4772 - mse: 97.4772 - val_loss: 82.9007 - val_mse: 82.9007\n",
      "Epoch 31/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.5197 - mse: 97.5197 - val_loss: 82.8267 - val_mse: 82.8267\n",
      "Epoch 32/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4631 - mse: 97.4631 - val_loss: 82.7862 - val_mse: 82.7862\n",
      "Epoch 33/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4939 - mse: 97.4939 - val_loss: 82.8274 - val_mse: 82.8274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4575 - mse: 97.4575 - val_loss: 82.9282 - val_mse: 82.9282\n",
      "Epoch 35/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4755 - mse: 97.4755 - val_loss: 82.8372 - val_mse: 82.8372\n",
      "Epoch 36/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4546 - mse: 97.4546 - val_loss: 82.8825 - val_mse: 82.8825\n",
      "Epoch 37/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4644 - mse: 97.4644 - val_loss: 82.9384 - val_mse: 82.9384\n",
      "Epoch 38/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4827 - mse: 97.4827 - val_loss: 82.8352 - val_mse: 82.8352\n",
      "Epoch 39/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4765 - mse: 97.4765 - val_loss: 82.8303 - val_mse: 82.8303\n",
      "Epoch 40/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4908 - mse: 97.4908 - val_loss: 82.8019 - val_mse: 82.8019\n",
      "Epoch 41/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4822 - mse: 97.4822 - val_loss: 82.7795 - val_mse: 82.7795\n",
      "Epoch 42/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4830 - mse: 97.4830 - val_loss: 82.7988 - val_mse: 82.7988\n",
      "Epoch 43/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4869 - mse: 97.4869 - val_loss: 82.7884 - val_mse: 82.7884\n",
      "Epoch 44/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4919 - mse: 97.4919 - val_loss: 82.7505 - val_mse: 82.7505\n",
      "Epoch 45/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.5171 - mse: 97.5171 - val_loss: 82.7981 - val_mse: 82.7981\n",
      "Epoch 46/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.5105 - mse: 97.5105 - val_loss: 82.7771 - val_mse: 82.7771\n",
      "Epoch 47/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4699 - mse: 97.4699 - val_loss: 82.8669 - val_mse: 82.8669\n",
      "Epoch 48/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4806 - mse: 97.4806 - val_loss: 82.9441 - val_mse: 82.9441\n",
      "Epoch 49/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4911 - mse: 97.4911 - val_loss: 82.9895 - val_mse: 82.9895\n",
      "Epoch 50/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4801 - mse: 97.4801 - val_loss: 83.0041 - val_mse: 83.0041\n",
      "Epoch 51/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4899 - mse: 97.4899 - val_loss: 83.1115 - val_mse: 83.1115\n",
      "Epoch 52/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4745 - mse: 97.4745 - val_loss: 83.0365 - val_mse: 83.0365\n",
      "Epoch 53/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4905 - mse: 97.4905 - val_loss: 82.9273 - val_mse: 82.9273\n",
      "Epoch 54/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4752 - mse: 97.4752 - val_loss: 82.8855 - val_mse: 82.8855\n",
      "Epoch 55/55\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4864 - mse: 97.4864 - val_loss: 82.9577 - val_mse: 82.9577\n",
      "INFO:tensorflow:Assets written to: out/111-model-ntrain=1000-sigma=10.0-epochs=55.tf/assets\n",
      "Epoch 1/100\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 97.4603 - mse: 97.4603 - val_loss: 82.9222 - val_mse: 82.9222\n",
      "Epoch 2/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4650 - mse: 97.4650 - val_loss: 82.9213 - val_mse: 82.9213\n",
      "Epoch 3/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4753 - mse: 97.4753 - val_loss: 82.9108 - val_mse: 82.9108\n",
      "Epoch 4/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4763 - mse: 97.4763 - val_loss: 82.9075 - val_mse: 82.9075\n",
      "Epoch 5/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 97.4686 - mse: 97.4686 - val_loss: 82.9782 - val_mse: 82.9782\n",
      "Epoch 6/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.5003 - mse: 97.5003 - val_loss: 82.9806 - val_mse: 82.9806\n",
      "Epoch 7/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4849 - mse: 97.4849 - val_loss: 82.9540 - val_mse: 82.9540\n",
      "Epoch 8/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4865 - mse: 97.4865 - val_loss: 82.9443 - val_mse: 82.9443\n",
      "Epoch 9/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4871 - mse: 97.4871 - val_loss: 82.9600 - val_mse: 82.9600\n",
      "Epoch 10/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4717 - mse: 97.4717 - val_loss: 83.0029 - val_mse: 83.0029\n",
      "Epoch 11/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4895 - mse: 97.4895 - val_loss: 82.9684 - val_mse: 82.9684\n",
      "Epoch 12/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4943 - mse: 97.4943 - val_loss: 83.0761 - val_mse: 83.0761\n",
      "Epoch 13/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4878 - mse: 97.4878 - val_loss: 83.0088 - val_mse: 83.0088\n",
      "Epoch 14/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4789 - mse: 97.4789 - val_loss: 82.9621 - val_mse: 82.9621\n",
      "Epoch 15/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4755 - mse: 97.4755 - val_loss: 83.1035 - val_mse: 83.1035\n",
      "Epoch 16/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4928 - mse: 97.4928 - val_loss: 82.9719 - val_mse: 82.9719\n",
      "Epoch 17/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4870 - mse: 97.4870 - val_loss: 82.9844 - val_mse: 82.9844\n",
      "Epoch 18/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4834 - mse: 97.4834 - val_loss: 83.0692 - val_mse: 83.0692\n",
      "Epoch 19/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4764 - mse: 97.4764 - val_loss: 82.8898 - val_mse: 82.8898\n",
      "Epoch 20/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4719 - mse: 97.4719 - val_loss: 82.9563 - val_mse: 82.9563\n",
      "Epoch 21/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4562 - mse: 97.4562 - val_loss: 82.9733 - val_mse: 82.9733\n",
      "Epoch 22/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4760 - mse: 97.4760 - val_loss: 82.9127 - val_mse: 82.9127\n",
      "Epoch 23/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.5113 - mse: 97.5113 - val_loss: 82.9567 - val_mse: 82.9567\n",
      "Epoch 24/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4818 - mse: 97.4818 - val_loss: 82.8823 - val_mse: 82.8823\n",
      "Epoch 25/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4961 - mse: 97.4961 - val_loss: 82.8460 - val_mse: 82.8460\n",
      "Epoch 26/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4704 - mse: 97.4704 - val_loss: 82.9270 - val_mse: 82.9270\n",
      "Epoch 27/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4522 - mse: 97.4522 - val_loss: 82.8516 - val_mse: 82.8516\n",
      "Epoch 28/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4801 - mse: 97.4801 - val_loss: 82.8398 - val_mse: 82.8398\n",
      "Epoch 29/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.5195 - mse: 97.5195 - val_loss: 82.9050 - val_mse: 82.9050\n",
      "Epoch 30/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4772 - mse: 97.4772 - val_loss: 82.9010 - val_mse: 82.9010\n",
      "Epoch 31/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.5197 - mse: 97.5197 - val_loss: 82.8270 - val_mse: 82.8270\n",
      "Epoch 32/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4630 - mse: 97.4630 - val_loss: 82.7864 - val_mse: 82.7864\n",
      "Epoch 33/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4939 - mse: 97.4939 - val_loss: 82.8276 - val_mse: 82.8276\n",
      "Epoch 34/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4575 - mse: 97.4575 - val_loss: 82.9284 - val_mse: 82.9284\n",
      "Epoch 35/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4756 - mse: 97.4756 - val_loss: 82.8373 - val_mse: 82.8373\n",
      "Epoch 36/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 97.4545 - mse: 97.4545 - val_loss: 82.8826 - val_mse: 82.8826\n",
      "Epoch 37/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4644 - mse: 97.4644 - val_loss: 82.9384 - val_mse: 82.9384\n",
      "Epoch 38/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4827 - mse: 97.4827 - val_loss: 82.8352 - val_mse: 82.8352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4765 - mse: 97.4765 - val_loss: 82.8303 - val_mse: 82.8303\n",
      "Epoch 40/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4908 - mse: 97.4908 - val_loss: 82.8019 - val_mse: 82.8019\n",
      "Epoch 41/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4822 - mse: 97.4822 - val_loss: 82.7795 - val_mse: 82.7795\n",
      "Epoch 42/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4830 - mse: 97.4830 - val_loss: 82.7988 - val_mse: 82.7988\n",
      "Epoch 43/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4869 - mse: 97.4869 - val_loss: 82.7884 - val_mse: 82.7884\n",
      "Epoch 44/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4919 - mse: 97.4919 - val_loss: 82.7505 - val_mse: 82.7505\n",
      "Epoch 45/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.5171 - mse: 97.5171 - val_loss: 82.7981 - val_mse: 82.7981\n",
      "Epoch 46/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.5105 - mse: 97.5105 - val_loss: 82.7771 - val_mse: 82.7771\n",
      "Epoch 47/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4699 - mse: 97.4699 - val_loss: 82.8669 - val_mse: 82.8669\n",
      "Epoch 48/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4806 - mse: 97.4806 - val_loss: 82.9441 - val_mse: 82.9441\n",
      "Epoch 49/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4911 - mse: 97.4911 - val_loss: 82.9895 - val_mse: 82.9895\n",
      "Epoch 50/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4801 - mse: 97.4801 - val_loss: 83.0041 - val_mse: 83.0041\n",
      "Epoch 51/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4899 - mse: 97.4899 - val_loss: 83.1115 - val_mse: 83.1115\n",
      "Epoch 52/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4745 - mse: 97.4745 - val_loss: 83.0365 - val_mse: 83.0365\n",
      "Epoch 53/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4905 - mse: 97.4905 - val_loss: 82.9274 - val_mse: 82.9274\n",
      "Epoch 54/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 97.4752 - mse: 97.4752 - val_loss: 82.8855 - val_mse: 82.8855\n",
      "Epoch 55/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 97.4864 - mse: 97.4864 - val_loss: 82.9577 - val_mse: 82.9577\n",
      "Epoch 56/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4646 - mse: 97.4646 - val_loss: 82.9436 - val_mse: 82.9436\n",
      "Epoch 57/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4745 - mse: 97.4745 - val_loss: 82.9644 - val_mse: 82.9644\n",
      "Epoch 58/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4685 - mse: 97.4685 - val_loss: 82.9156 - val_mse: 82.9156\n",
      "Epoch 59/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 97.5044 - mse: 97.5044 - val_loss: 82.7805 - val_mse: 82.7805\n",
      "Epoch 60/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4931 - mse: 97.4931 - val_loss: 82.8609 - val_mse: 82.8609\n",
      "Epoch 61/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4828 - mse: 97.4828 - val_loss: 82.9379 - val_mse: 82.9379\n",
      "Epoch 62/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4873 - mse: 97.4873 - val_loss: 82.9899 - val_mse: 82.9899\n",
      "Epoch 63/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.5067 - mse: 97.5067 - val_loss: 82.9597 - val_mse: 82.9597\n",
      "Epoch 64/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4819 - mse: 97.4819 - val_loss: 82.9837 - val_mse: 82.9837\n",
      "Epoch 65/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 97.4909 - mse: 97.4909 - val_loss: 83.0083 - val_mse: 83.0083\n",
      "Epoch 66/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4616 - mse: 97.4616 - val_loss: 82.9466 - val_mse: 82.9466\n",
      "Epoch 67/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4573 - mse: 97.4573 - val_loss: 82.9169 - val_mse: 82.9169\n",
      "Epoch 68/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4673 - mse: 97.4673 - val_loss: 82.8356 - val_mse: 82.8356\n",
      "Epoch 69/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4979 - mse: 97.4979 - val_loss: 82.8845 - val_mse: 82.8845\n",
      "Epoch 70/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4723 - mse: 97.4723 - val_loss: 82.8738 - val_mse: 82.8738\n",
      "Epoch 71/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4957 - mse: 97.4957 - val_loss: 82.8788 - val_mse: 82.8788\n",
      "Epoch 72/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4970 - mse: 97.4970 - val_loss: 82.9201 - val_mse: 82.9201\n",
      "Epoch 73/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4724 - mse: 97.4724 - val_loss: 82.8585 - val_mse: 82.8585\n",
      "Epoch 74/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4727 - mse: 97.4727 - val_loss: 82.9671 - val_mse: 82.9671\n",
      "Epoch 75/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4960 - mse: 97.4960 - val_loss: 82.8537 - val_mse: 82.8537\n",
      "Epoch 76/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4926 - mse: 97.4926 - val_loss: 82.8559 - val_mse: 82.8559\n",
      "Epoch 77/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4942 - mse: 97.4942 - val_loss: 83.0038 - val_mse: 83.0038\n",
      "Epoch 78/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4769 - mse: 97.4769 - val_loss: 83.0506 - val_mse: 83.0506\n",
      "Epoch 79/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.5105 - mse: 97.5105 - val_loss: 83.1074 - val_mse: 83.1074\n",
      "Epoch 80/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.5080 - mse: 97.5080 - val_loss: 83.2363 - val_mse: 83.2363\n",
      "Epoch 81/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.5115 - mse: 97.5115 - val_loss: 83.1230 - val_mse: 83.1230\n",
      "Epoch 82/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4719 - mse: 97.4719 - val_loss: 82.9879 - val_mse: 82.9879\n",
      "Epoch 83/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 97.4819 - mse: 97.4819 - val_loss: 82.9089 - val_mse: 82.9089\n",
      "Epoch 84/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4839 - mse: 97.4839 - val_loss: 82.9143 - val_mse: 82.9143\n",
      "Epoch 85/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4729 - mse: 97.4729 - val_loss: 82.9291 - val_mse: 82.9291\n",
      "Epoch 86/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4960 - mse: 97.4960 - val_loss: 82.9248 - val_mse: 82.9248\n",
      "Epoch 87/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4692 - mse: 97.4692 - val_loss: 82.9033 - val_mse: 82.9033\n",
      "Epoch 88/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4987 - mse: 97.4987 - val_loss: 82.9440 - val_mse: 82.9440\n",
      "Epoch 89/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4594 - mse: 97.4594 - val_loss: 82.9524 - val_mse: 82.9524\n",
      "Epoch 90/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4728 - mse: 97.4728 - val_loss: 82.9402 - val_mse: 82.9402\n",
      "Epoch 91/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4821 - mse: 97.4821 - val_loss: 82.9678 - val_mse: 82.9678\n",
      "Epoch 92/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4968 - mse: 97.4968 - val_loss: 82.9291 - val_mse: 82.9291\n",
      "Epoch 93/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4730 - mse: 97.4730 - val_loss: 82.9914 - val_mse: 82.9914\n",
      "Epoch 94/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4563 - mse: 97.4563 - val_loss: 82.9602 - val_mse: 82.9602\n",
      "Epoch 95/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4668 - mse: 97.4668 - val_loss: 82.9304 - val_mse: 82.9304\n",
      "Epoch 96/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4630 - mse: 97.4630 - val_loss: 82.8995 - val_mse: 82.8995\n",
      "Epoch 97/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4850 - mse: 97.4850 - val_loss: 82.8992 - val_mse: 82.8992\n",
      "Epoch 98/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4746 - mse: 97.4746 - val_loss: 82.8856 - val_mse: 82.8856\n",
      "Epoch 99/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4783 - mse: 97.4783 - val_loss: 82.8531 - val_mse: 82.8531\n",
      "Epoch 100/100\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 97.4540 - mse: 97.4540 - val_loss: 82.8512 - val_mse: 82.8512\n",
      "INFO:tensorflow:Assets written to: out/111-model-ntrain=1000-sigma=10.0-epochs=100.tf/assets\n",
      "\n"
     ]
    }
   ],
   "source": [
    "RERUN=True\n",
    "\n",
    "if(RERUN):\n",
    "    TestParameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f3ef8a50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig=plt.figure(figsize=(16, 8))\n",
    "plt.suptitle('equi', weight='bold')\n",
    "\n",
    "m_out=np.loadtxt(\"out/111-m_diff.csv\", usecols=(0), unpack=True )\n",
    "b_out=np.loadtxt(\"out/111-b_diff.csv\", usecols=(0), unpack=True )\n",
    "x=np.arange(0,len(m_out))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.title(\"m\")\n",
    "plt.scatter(x,np.absolute((m-m_out)/m))\n",
    "for l in np.arange(2.5,len(m_out)-3,3):\n",
    "    plt.axvline(l,ls=\":\")\n",
    "for l in np.arange(8.5,len(m_out)-9,9):\n",
    "    plt.axvline(l,ls=\"--\")\n",
    "\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.title(\"b\")\n",
    "plt.scatter(x,np.absolute((b-b_out)/b))\n",
    "for l in np.arange(2.5,len(b_out)-3,3):\n",
    "    plt.axvline(l,ls=\":\")\n",
    "for l in np.arange(8.5,len(b_out)-9,9):\n",
    "    plt.axvline(l,ls=\"--\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e784f4",
   "metadata": {},
   "source": [
    "In each dotted box we have the results obtained from different number of epochs at fixed sigma. Each dashed box contains results with fixed number of training data.\n",
    "\n",
    "Some observations:\n",
    "1. fixed sigma and number of epochs, increasing the size of training dataset leads to better results\n",
    "2. Increasing the number of epochs leads to better results but the impact of this parameter lowers by increasing the training dataset size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c443636e",
   "metadata": {},
   "source": [
    "Let's now see how the models performs0. The following script allows to view the error plots for train and test data. You can change parameters by changing the indices according to the table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a214550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sigma</th>\n",
       "      <th>N_train</th>\n",
       "      <th>N_epochs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>550</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sigma  N_train  N_epochs\n",
       "0    0.0      100        10\n",
       "1    1.0      550        55\n",
       "2   10.0     1000       100"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame({'sigma': sigmas, 'N_train':ntrains, 'N_epochs': epochss})\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fcd1ae34",
   "metadata": {},
   "outputs": [],
   "source": [
    "isigma=0\n",
    "itrain=2\n",
    "iepoch=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dc4725aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_df=pd.read_csv(\"out/111-history-ntrain=\"+str(ntrains[itrain])+\"-sigma=\"+str(sigmas[isigma])+\".csv\")\n",
    "model=load_model(\"out/111-model-ntrain=\"+str(ntrains[itrain])+\"-sigma=\"+str(sigmas[isigma])+\"-epochs=\"+str(epochss[iepoch])+\".tf\")\n",
    "\n",
    "show_results(model,history_df,50, epochss[iepoch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f390c57e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
