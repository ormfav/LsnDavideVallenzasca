{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eec349fa",
   "metadata": {},
   "source": [
    "# $11^{th}$ excercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f4c67f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import get_custom_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fe275f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target parameters of f(x) = m*x + b\n",
    "m = 2 \n",
    "b = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7ffcadbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.  0.1 1. ]\n",
      "[ 100  550 1000]\n",
      "[10 30 50]\n"
     ]
    }
   ],
   "source": [
    "sigmas = np.array([0.,0.1,1])\n",
    "Ntrains = np.linspace(100,1000,3,dtype=int)\n",
    "Nepochss = np.linspace(10,50,3,dtype=int)\n",
    "print(sigmas)\n",
    "print(Ntrains)\n",
    "print(Nepochss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7c51fd",
   "metadata": {},
   "source": [
    "Voglio plottare: m_model - m, b_model -b -> 2, 27 pti ognuna\n",
    "Loss functions: -> 27 grafici -> faccio script che stampa 3 grafici in cui una quantit√† varia e le altre sono fisse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf835335",
   "metadata": {},
   "source": [
    "One should consider the following blocks as interactive. Our script produced 27 datasets of Train/Validation loss in function of epochs. Referring to the following table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "96e5a758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sigma</th>\n",
       "      <th>N_train</th>\n",
       "      <th>N_epochs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>550</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sigma  N_train  N_epochs\n",
       "0    0.0      100        10\n",
       "1    0.1      550        30\n",
       "2    1.0     1000        50"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame({'sigma': sigmas, 'N_train':Ntrains, 'N_epochs': Nepochss})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f5a13a",
   "metadata": {},
   "source": [
    "One is able to choose one of those three quantities using their column name and then fix a value for the other two quantities using their row index. The block will produce 3 output graphs of the loss functions where the chosen quantity is different in each graph, while the ohter two are fixed to the selected values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2b94dffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4/4 [==============================] - 1s 92ms/step - loss: 3.1255 - mse: 3.1255 - val_loss: 1.4532 - val_mse: 1.4532\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 2.8571 - mse: 2.8571 - val_loss: 1.3592 - val_mse: 1.3592\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 2.6667 - mse: 2.6667 - val_loss: 1.2610 - val_mse: 1.2610\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 2.4662 - mse: 2.4662 - val_loss: 1.1927 - val_mse: 1.1927\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 2.3248 - mse: 2.3248 - val_loss: 1.1362 - val_mse: 1.1362\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 2.2055 - mse: 2.2055 - val_loss: 1.0764 - val_mse: 1.0764\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 2.0822 - mse: 2.0822 - val_loss: 0.9969 - val_mse: 0.9969\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.9113 - mse: 1.9113 - val_loss: 0.9456 - val_mse: 0.9456\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.7998 - mse: 1.7998 - val_loss: 0.8994 - val_mse: 0.8994\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.7037 - mse: 1.7037 - val_loss: 0.8501 - val_mse: 0.8501\n",
      "Epoch 1/30\n",
      "4/4 [==============================] - 1s 128ms/step - loss: 3.1255 - mse: 3.1255 - val_loss: 1.4532 - val_mse: 1.4532\n",
      "Epoch 2/30\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 2.8571 - mse: 2.8571 - val_loss: 1.3592 - val_mse: 1.3592\n",
      "Epoch 3/30\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 2.6667 - mse: 2.6667 - val_loss: 1.2610 - val_mse: 1.2610\n",
      "Epoch 4/30\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 2.4662 - mse: 2.4662 - val_loss: 1.1927 - val_mse: 1.1927\n",
      "Epoch 5/30\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 2.3248 - mse: 2.3248 - val_loss: 1.1362 - val_mse: 1.1362\n",
      "Epoch 6/30\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 2.2055 - mse: 2.2055 - val_loss: 1.0764 - val_mse: 1.0764\n",
      "Epoch 7/30\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 2.0822 - mse: 2.0822 - val_loss: 0.9969 - val_mse: 0.9969\n",
      "Epoch 8/30\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1.9113 - mse: 1.9113 - val_loss: 0.9456 - val_mse: 0.9456\n",
      "Epoch 9/30\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.7998 - mse: 1.7998 - val_loss: 0.8994 - val_mse: 0.8994\n",
      "Epoch 10/30\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.7037 - mse: 1.7037 - val_loss: 0.8501 - val_mse: 0.8501\n",
      "Epoch 11/30\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.5987 - mse: 1.5987 - val_loss: 0.8099 - val_mse: 0.8099\n",
      "Epoch 12/30\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.5086 - mse: 1.5086 - val_loss: 0.7559 - val_mse: 0.7559\n",
      "Epoch 13/30\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.3860 - mse: 1.3860 - val_loss: 0.7190 - val_mse: 0.7190\n",
      "Epoch 14/30\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 1.3135 - mse: 1.3135 - val_loss: 0.6864 - val_mse: 0.6864\n",
      "Epoch 15/30\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 1.2531 - mse: 1.2531 - val_loss: 0.6520 - val_mse: 0.6520\n",
      "Epoch 16/30\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.1866 - mse: 1.1866 - val_loss: 0.6203 - val_mse: 0.6203\n",
      "Epoch 17/30\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.1272 - mse: 1.1272 - val_loss: 0.5868 - val_mse: 0.5868\n",
      "Epoch 18/30\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.0615 - mse: 1.0615 - val_loss: 0.5616 - val_mse: 0.5616\n",
      "Epoch 19/30\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.0075 - mse: 1.0075 - val_loss: 0.5309 - val_mse: 0.5309\n",
      "Epoch 20/30\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.9455 - mse: 0.9455 - val_loss: 0.5029 - val_mse: 0.5029\n",
      "Epoch 21/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.8902 - mse: 0.8902 - val_loss: 0.4790 - val_mse: 0.4790\n",
      "Epoch 22/30\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.8451 - mse: 0.8451 - val_loss: 0.4600 - val_mse: 0.4600\n",
      "Epoch 23/30\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.8071 - mse: 0.8071 - val_loss: 0.4388 - val_mse: 0.4388\n",
      "Epoch 24/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.7681 - mse: 0.7681 - val_loss: 0.4135 - val_mse: 0.4135\n",
      "Epoch 25/30\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.7242 - mse: 0.7242 - val_loss: 0.3943 - val_mse: 0.3943\n",
      "Epoch 26/30\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.6862 - mse: 0.6862 - val_loss: 0.3719 - val_mse: 0.3719\n",
      "Epoch 27/30\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.6410 - mse: 0.6410 - val_loss: 0.3522 - val_mse: 0.3522\n",
      "Epoch 28/30\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.6057 - mse: 0.6057 - val_loss: 0.3374 - val_mse: 0.3374\n",
      "Epoch 29/30\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.5753 - mse: 0.5753 - val_loss: 0.3187 - val_mse: 0.3187\n",
      "Epoch 30/30\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.5388 - mse: 0.5388 - val_loss: 0.2996 - val_mse: 0.2996\n",
      "Epoch 1/50\n",
      "4/4 [==============================] - 1s 88ms/step - loss: 3.1255 - mse: 3.1255 - val_loss: 1.4532 - val_mse: 1.4532\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 2.8571 - mse: 2.8571 - val_loss: 1.3592 - val_mse: 1.3592\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 2.6667 - mse: 2.6667 - val_loss: 1.2610 - val_mse: 1.2610\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 2.4662 - mse: 2.4662 - val_loss: 1.1927 - val_mse: 1.1927\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 2.3248 - mse: 2.3248 - val_loss: 1.1362 - val_mse: 1.1362\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 2.2055 - mse: 2.2055 - val_loss: 1.0764 - val_mse: 1.0764\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 2.0822 - mse: 2.0822 - val_loss: 0.9969 - val_mse: 0.9969\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 1.9113 - mse: 1.9113 - val_loss: 0.9456 - val_mse: 0.9456\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.7998 - mse: 1.7998 - val_loss: 0.8994 - val_mse: 0.8994\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.7037 - mse: 1.7037 - val_loss: 0.8501 - val_mse: 0.8501\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.5987 - mse: 1.5987 - val_loss: 0.8099 - val_mse: 0.8099\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.5086 - mse: 1.5086 - val_loss: 0.7559 - val_mse: 0.7559\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.3860 - mse: 1.3860 - val_loss: 0.7190 - val_mse: 0.7190\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.3135 - mse: 1.3135 - val_loss: 0.6864 - val_mse: 0.6864\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1.2531 - mse: 1.2531 - val_loss: 0.6520 - val_mse: 0.6520\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1.1866 - mse: 1.1866 - val_loss: 0.6203 - val_mse: 0.6203\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.1272 - mse: 1.1272 - val_loss: 0.5868 - val_mse: 0.5868\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1.0615 - mse: 1.0615 - val_loss: 0.5616 - val_mse: 0.5616\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1.0075 - mse: 1.0075 - val_loss: 0.5309 - val_mse: 0.5309\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.9455 - mse: 0.9455 - val_loss: 0.5029 - val_mse: 0.5029\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.8902 - mse: 0.8902 - val_loss: 0.4790 - val_mse: 0.4790\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.8451 - mse: 0.8451 - val_loss: 0.4600 - val_mse: 0.4600\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.8071 - mse: 0.8071 - val_loss: 0.4388 - val_mse: 0.4388\n",
      "Epoch 24/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 24ms/step - loss: 0.7681 - mse: 0.7681 - val_loss: 0.4135 - val_mse: 0.4135\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7242 - mse: 0.7242 - val_loss: 0.3943 - val_mse: 0.3943\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6862 - mse: 0.6862 - val_loss: 0.3719 - val_mse: 0.3719\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.6410 - mse: 0.6410 - val_loss: 0.3522 - val_mse: 0.3522\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6057 - mse: 0.6057 - val_loss: 0.3374 - val_mse: 0.3374\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.5753 - mse: 0.5753 - val_loss: 0.3187 - val_mse: 0.3187\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.5388 - mse: 0.5388 - val_loss: 0.2996 - val_mse: 0.2996\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.5068 - mse: 0.5068 - val_loss: 0.2878 - val_mse: 0.2878\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.4826 - mse: 0.4826 - val_loss: 0.2744 - val_mse: 0.2744\n",
      "Epoch 33/50\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.4572 - mse: 0.4572 - val_loss: 0.2612 - val_mse: 0.2612\n",
      "Epoch 34/50\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.4359 - mse: 0.4359 - val_loss: 0.2460 - val_mse: 0.2460\n",
      "Epoch 35/50\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.4147 - mse: 0.4147 - val_loss: 0.2371 - val_mse: 0.2371\n",
      "Epoch 36/50\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.3971 - mse: 0.3971 - val_loss: 0.2260 - val_mse: 0.2260\n",
      "Epoch 37/50\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.3782 - mse: 0.3782 - val_loss: 0.2172 - val_mse: 0.2172\n",
      "Epoch 38/50\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.3602 - mse: 0.3602 - val_loss: 0.2074 - val_mse: 0.2074\n",
      "Epoch 39/50\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.3381 - mse: 0.3381 - val_loss: 0.1971 - val_mse: 0.1971\n",
      "Epoch 40/50\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.3192 - mse: 0.3192 - val_loss: 0.1886 - val_mse: 0.1886\n",
      "Epoch 41/50\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.3044 - mse: 0.3044 - val_loss: 0.1784 - val_mse: 0.1784\n",
      "Epoch 42/50\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.2865 - mse: 0.2865 - val_loss: 0.1697 - val_mse: 0.1697\n",
      "Epoch 43/50\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.2692 - mse: 0.2692 - val_loss: 0.1627 - val_mse: 0.1627\n",
      "Epoch 44/50\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.2553 - mse: 0.2553 - val_loss: 0.1534 - val_mse: 0.1534\n",
      "Epoch 45/50\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.2407 - mse: 0.2407 - val_loss: 0.1450 - val_mse: 0.1450\n",
      "Epoch 46/50\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.2284 - mse: 0.2284 - val_loss: 0.1374 - val_mse: 0.1374\n",
      "Epoch 47/50\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.2164 - mse: 0.2164 - val_loss: 0.1282 - val_mse: 0.1282\n",
      "Epoch 48/50\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.2050 - mse: 0.2050 - val_loss: 0.1210 - val_mse: 0.1210\n",
      "Epoch 49/50\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.1935 - mse: 0.1935 - val_loss: 0.1150 - val_mse: 0.1150\n",
      "Epoch 50/50\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.1845 - mse: 0.1845 - val_loss: 0.1085 - val_mse: 0.1085\n",
      "Epoch 1/10\n",
      "18/18 [==============================] - 1s 19ms/step - loss: 2.9446 - mse: 2.9446 - val_loss: 3.3276 - val_mse: 3.3276\n",
      "Epoch 2/10\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.1058 - mse: 2.1058 - val_loss: 2.4187 - val_mse: 2.4187\n",
      "Epoch 3/10\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.5390 - mse: 1.5390 - val_loss: 1.8150 - val_mse: 1.8150\n",
      "Epoch 4/10\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.1626 - mse: 1.1626 - val_loss: 1.3844 - val_mse: 1.3844\n",
      "Epoch 5/10\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.8912 - mse: 0.8912 - val_loss: 1.0673 - val_mse: 1.0673\n",
      "Epoch 6/10\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6905 - mse: 0.6905 - val_loss: 0.8190 - val_mse: 0.8190\n",
      "Epoch 7/10\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5334 - mse: 0.5334 - val_loss: 0.6282 - val_mse: 0.6282\n",
      "Epoch 8/10\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4112 - mse: 0.4112 - val_loss: 0.4915 - val_mse: 0.4915\n",
      "Epoch 9/10\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3229 - mse: 0.3229 - val_loss: 0.3845 - val_mse: 0.3845\n",
      "Epoch 10/10\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.2534 - mse: 0.2534 - val_loss: 0.2985 - val_mse: 0.2985\n",
      "Epoch 1/30\n",
      "18/18 [==============================] - 1s 19ms/step - loss: 2.9446 - mse: 2.9446 - val_loss: 3.3276 - val_mse: 3.3276\n",
      "Epoch 2/30\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.1058 - mse: 2.1058 - val_loss: 2.4187 - val_mse: 2.4187\n",
      "Epoch 3/30\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.5390 - mse: 1.5390 - val_loss: 1.8150 - val_mse: 1.8150\n",
      "Epoch 4/30\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.1626 - mse: 1.1626 - val_loss: 1.3844 - val_mse: 1.3844\n",
      "Epoch 5/30\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.8912 - mse: 0.8912 - val_loss: 1.0673 - val_mse: 1.0673\n",
      "Epoch 6/30\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.6905 - mse: 0.6905 - val_loss: 0.8190 - val_mse: 0.8190\n",
      "Epoch 7/30\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5334 - mse: 0.5334 - val_loss: 0.6282 - val_mse: 0.6282\n",
      "Epoch 8/30\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4112 - mse: 0.4112 - val_loss: 0.4915 - val_mse: 0.4915\n",
      "Epoch 9/30\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.3229 - mse: 0.3229 - val_loss: 0.3845 - val_mse: 0.3845\n",
      "Epoch 10/30\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.2534 - mse: 0.2534 - val_loss: 0.2985 - val_mse: 0.2985\n",
      "Epoch 11/30\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.1971 - mse: 0.1971 - val_loss: 0.2329 - val_mse: 0.2329\n",
      "Epoch 12/30\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1543 - mse: 0.1543 - val_loss: 0.1837 - val_mse: 0.1837\n",
      "Epoch 13/30\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.1217 - mse: 0.1217 - val_loss: 0.1445 - val_mse: 0.1445\n",
      "Epoch 14/30\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0960 - mse: 0.0960 - val_loss: 0.1135 - val_mse: 0.1135\n",
      "Epoch 15/30\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0752 - mse: 0.0752 - val_loss: 0.0887 - val_mse: 0.0887\n",
      "Epoch 16/30\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0590 - mse: 0.0590 - val_loss: 0.0699 - val_mse: 0.0699\n",
      "Epoch 17/30\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0464 - mse: 0.0464 - val_loss: 0.0549 - val_mse: 0.0549\n",
      "Epoch 18/30\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0365 - mse: 0.0365 - val_loss: 0.0432 - val_mse: 0.0432\n",
      "Epoch 19/30\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0287 - mse: 0.0287 - val_loss: 0.0340 - val_mse: 0.0340\n",
      "Epoch 20/30\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0226 - mse: 0.0226 - val_loss: 0.0265 - val_mse: 0.0265\n",
      "Epoch 21/30\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0206 - val_mse: 0.0206\n",
      "Epoch 22/30\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 23/30\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0107 - mse: 0.0107 - val_loss: 0.0125 - val_mse: 0.0125\n",
      "Epoch 24/30\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0084 - mse: 0.0084 - val_loss: 0.0098 - val_mse: 0.0098\n",
      "Epoch 25/30\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0077 - val_mse: 0.0077\n",
      "Epoch 26/30\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0061 - val_mse: 0.0061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/30\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0047 - val_mse: 0.0047\n",
      "Epoch 28/30\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0032 - mse: 0.0032 - val_loss: 0.0037 - val_mse: 0.0037\n",
      "Epoch 29/30\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 0.0029 - val_mse: 0.0029\n",
      "Epoch 30/30\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0023 - val_mse: 0.0023\n",
      "Epoch 1/50\n",
      "18/18 [==============================] - 1s 19ms/step - loss: 2.9446 - mse: 2.9446 - val_loss: 3.3276 - val_mse: 3.3276\n",
      "Epoch 2/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 2.1058 - mse: 2.1058 - val_loss: 2.4187 - val_mse: 2.4187\n",
      "Epoch 3/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.5390 - mse: 1.5390 - val_loss: 1.8150 - val_mse: 1.8150\n",
      "Epoch 4/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.1626 - mse: 1.1626 - val_loss: 1.3844 - val_mse: 1.3844\n",
      "Epoch 5/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.8912 - mse: 0.8912 - val_loss: 1.0673 - val_mse: 1.0673\n",
      "Epoch 6/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.6905 - mse: 0.6905 - val_loss: 0.8190 - val_mse: 0.8190\n",
      "Epoch 7/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5334 - mse: 0.5334 - val_loss: 0.6282 - val_mse: 0.6282\n",
      "Epoch 8/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4112 - mse: 0.4112 - val_loss: 0.4915 - val_mse: 0.4915\n",
      "Epoch 9/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3229 - mse: 0.3229 - val_loss: 0.3845 - val_mse: 0.3845\n",
      "Epoch 10/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.2534 - mse: 0.2534 - val_loss: 0.2985 - val_mse: 0.2985\n",
      "Epoch 11/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1971 - mse: 0.1971 - val_loss: 0.2329 - val_mse: 0.2329\n",
      "Epoch 12/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1543 - mse: 0.1543 - val_loss: 0.1837 - val_mse: 0.1837\n",
      "Epoch 13/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1217 - mse: 0.1217 - val_loss: 0.1445 - val_mse: 0.1445\n",
      "Epoch 14/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0960 - mse: 0.0960 - val_loss: 0.1135 - val_mse: 0.1135\n",
      "Epoch 15/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0752 - mse: 0.0752 - val_loss: 0.0887 - val_mse: 0.0887\n",
      "Epoch 16/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0590 - mse: 0.0590 - val_loss: 0.0699 - val_mse: 0.0699\n",
      "Epoch 17/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0464 - mse: 0.0464 - val_loss: 0.0549 - val_mse: 0.0549\n",
      "Epoch 18/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0365 - mse: 0.0365 - val_loss: 0.0432 - val_mse: 0.0432\n",
      "Epoch 19/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0287 - mse: 0.0287 - val_loss: 0.0340 - val_mse: 0.0340\n",
      "Epoch 20/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0226 - mse: 0.0226 - val_loss: 0.0265 - val_mse: 0.0265\n",
      "Epoch 21/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0206 - val_mse: 0.0206\n",
      "Epoch 22/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 23/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0107 - mse: 0.0107 - val_loss: 0.0125 - val_mse: 0.0125\n",
      "Epoch 24/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0084 - mse: 0.0084 - val_loss: 0.0098 - val_mse: 0.0098\n",
      "Epoch 25/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0077 - val_mse: 0.0077\n",
      "Epoch 26/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0061 - val_mse: 0.0061\n",
      "Epoch 27/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0047 - val_mse: 0.0047\n",
      "Epoch 28/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0032 - mse: 0.0032 - val_loss: 0.0037 - val_mse: 0.0037\n",
      "Epoch 29/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 0.0029 - val_mse: 0.0029\n",
      "Epoch 30/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0023 - val_mse: 0.0023\n",
      "Epoch 31/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0018 - val_mse: 0.0018\n",
      "Epoch 32/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 33/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 9.2733e-04 - mse: 9.2733e-04 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 34/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 7.2859e-04 - mse: 7.2859e-04 - val_loss: 8.5150e-04 - val_mse: 8.5150e-04\n",
      "Epoch 35/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 5.6709e-04 - mse: 5.6709e-04 - val_loss: 6.6777e-04 - val_mse: 6.6777e-04\n",
      "Epoch 36/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 4.4515e-04 - mse: 4.4515e-04 - val_loss: 5.2316e-04 - val_mse: 5.2316e-04\n",
      "Epoch 37/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 3.4839e-04 - mse: 3.4839e-04 - val_loss: 4.0978e-04 - val_mse: 4.0978e-04\n",
      "Epoch 38/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.7260e-04 - mse: 2.7260e-04 - val_loss: 3.2204e-04 - val_mse: 3.2204e-04\n",
      "Epoch 39/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 2.1436e-04 - mse: 2.1436e-04 - val_loss: 2.5137e-04 - val_mse: 2.5137e-04\n",
      "Epoch 40/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.6674e-04 - mse: 1.6674e-04 - val_loss: 1.9673e-04 - val_mse: 1.9673e-04\n",
      "Epoch 41/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.3057e-04 - mse: 1.3057e-04 - val_loss: 1.5348e-04 - val_mse: 1.5348e-04\n",
      "Epoch 42/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0198e-04 - mse: 1.0198e-04 - val_loss: 1.1981e-04 - val_mse: 1.1981e-04\n",
      "Epoch 43/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.9757e-05 - mse: 7.9757e-05 - val_loss: 9.4375e-05 - val_mse: 9.4375e-05\n",
      "Epoch 44/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 6.2809e-05 - mse: 6.2809e-05 - val_loss: 7.4286e-05 - val_mse: 7.4286e-05\n",
      "Epoch 45/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 4.9317e-05 - mse: 4.9317e-05 - val_loss: 5.8432e-05 - val_mse: 5.8432e-05\n",
      "Epoch 46/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 3.8771e-05 - mse: 3.8771e-05 - val_loss: 4.5592e-05 - val_mse: 4.5592e-05\n",
      "Epoch 47/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 3.0290e-05 - mse: 3.0290e-05 - val_loss: 3.5561e-05 - val_mse: 3.5561e-05\n",
      "Epoch 48/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.3599e-05 - mse: 2.3599e-05 - val_loss: 2.8059e-05 - val_mse: 2.8059e-05\n",
      "Epoch 49/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.8621e-05 - mse: 1.8621e-05 - val_loss: 2.1758e-05 - val_mse: 2.1758e-05\n",
      "Epoch 50/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.4480e-05 - mse: 1.4480e-05 - val_loss: 1.7095e-05 - val_mse: 1.7095e-05\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 1s 12ms/step - loss: 2.6126 - mse: 2.6126 - val_loss: 1.7315 - val_mse: 1.7315\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.4898 - mse: 1.4898 - val_loss: 1.0335 - val_mse: 1.0335\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9154 - mse: 0.9154 - val_loss: 0.6481 - val_mse: 0.6481\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5806 - mse: 0.5806 - val_loss: 0.4117 - val_mse: 0.4117\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.3710 - mse: 0.3710 - val_loss: 0.2665 - val_mse: 0.2665\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2407 - mse: 0.2407 - val_loss: 0.1724 - val_mse: 0.1724\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1558 - mse: 0.1558 - val_loss: 0.1110 - val_mse: 0.1110\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1003 - mse: 0.1003 - val_loss: 0.0721 - val_mse: 0.0721\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0652 - mse: 0.0652 - val_loss: 0.0468 - val_mse: 0.0468\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0423 - mse: 0.0423 - val_loss: 0.0302 - val_mse: 0.0302\n",
      "Epoch 1/30\n",
      "32/32 [==============================] - 1s 11ms/step - loss: 2.6126 - mse: 2.6126 - val_loss: 1.7315 - val_mse: 1.7315\n",
      "Epoch 2/30\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.4898 - mse: 1.4898 - val_loss: 1.0335 - val_mse: 1.0335\n",
      "Epoch 3/30\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9154 - mse: 0.9154 - val_loss: 0.6481 - val_mse: 0.6481\n",
      "Epoch 4/30\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5806 - mse: 0.5806 - val_loss: 0.4117 - val_mse: 0.4117\n",
      "Epoch 5/30\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.3710 - mse: 0.3710 - val_loss: 0.2665 - val_mse: 0.2665\n",
      "Epoch 6/30\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.2407 - mse: 0.2407 - val_loss: 0.1724 - val_mse: 0.1724\n",
      "Epoch 7/30\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1558 - mse: 0.1558 - val_loss: 0.1110 - val_mse: 0.1110\n",
      "Epoch 8/30\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1003 - mse: 0.1003 - val_loss: 0.0721 - val_mse: 0.0721\n",
      "Epoch 9/30\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0652 - mse: 0.0652 - val_loss: 0.0468 - val_mse: 0.0468\n",
      "Epoch 10/30\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0423 - mse: 0.0423 - val_loss: 0.0302 - val_mse: 0.0302\n",
      "Epoch 11/30\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0273 - mse: 0.0273 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 12/30\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0127 - val_mse: 0.0127\n",
      "Epoch 13/30\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0115 - mse: 0.0115 - val_loss: 0.0082 - val_mse: 0.0082\n",
      "Epoch 14/30\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0053 - val_mse: 0.0053\n",
      "Epoch 15/30\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0048 - mse: 0.0048 - val_loss: 0.0034 - val_mse: 0.0034\n",
      "Epoch 16/30\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0031 - mse: 0.0031 - val_loss: 0.0022 - val_mse: 0.0022\n",
      "Epoch 17/30\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 18/30\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 9.3781e-04 - val_mse: 9.3781e-04\n",
      "Epoch 19/30\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 8.4760e-04 - mse: 8.4760e-04 - val_loss: 6.0885e-04 - val_mse: 6.0885e-04\n",
      "Epoch 20/30\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.5051e-04 - mse: 5.5051e-04 - val_loss: 3.9533e-04 - val_mse: 3.9533e-04\n",
      "Epoch 21/30\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.5733e-04 - mse: 3.5733e-04 - val_loss: 2.5622e-04 - val_mse: 2.5622e-04\n",
      "Epoch 22/30\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 2.3164e-04 - mse: 2.3164e-04 - val_loss: 1.6604e-04 - val_mse: 1.6604e-04\n",
      "Epoch 23/30\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.5020e-04 - mse: 1.5020e-04 - val_loss: 1.0716e-04 - val_mse: 1.0716e-04\n",
      "Epoch 24/30\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 9.6877e-05 - mse: 9.6877e-05 - val_loss: 6.9497e-05 - val_mse: 6.9497e-05\n",
      "Epoch 25/30\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 6.2829e-05 - mse: 6.2829e-05 - val_loss: 4.5080e-05 - val_mse: 4.5080e-05\n",
      "Epoch 26/30\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 4.0765e-05 - mse: 4.0765e-05 - val_loss: 2.9155e-05 - val_mse: 2.9155e-05\n",
      "Epoch 27/30\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.6356e-05 - mse: 2.6356e-05 - val_loss: 1.8990e-05 - val_mse: 1.8990e-05\n",
      "Epoch 28/30\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.7174e-05 - mse: 1.7174e-05 - val_loss: 1.2326e-05 - val_mse: 1.2326e-05\n",
      "Epoch 29/30\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.1143e-05 - mse: 1.1143e-05 - val_loss: 7.9590e-06 - val_mse: 7.9590e-06\n",
      "Epoch 30/30\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 7.1953e-06 - mse: 7.1953e-06 - val_loss: 5.1532e-06 - val_mse: 5.1532e-06\n",
      "Epoch 1/50\n",
      "32/32 [==============================] - 1s 12ms/step - loss: 2.6126 - mse: 2.6126 - val_loss: 1.7315 - val_mse: 1.7315\n",
      "Epoch 2/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.4898 - mse: 1.4898 - val_loss: 1.0335 - val_mse: 1.0335\n",
      "Epoch 3/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.9154 - mse: 0.9154 - val_loss: 0.6481 - val_mse: 0.6481\n",
      "Epoch 4/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5806 - mse: 0.5806 - val_loss: 0.4117 - val_mse: 0.4117\n",
      "Epoch 5/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.3710 - mse: 0.3710 - val_loss: 0.2665 - val_mse: 0.2665\n",
      "Epoch 6/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2407 - mse: 0.2407 - val_loss: 0.1724 - val_mse: 0.1724\n",
      "Epoch 7/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1558 - mse: 0.1558 - val_loss: 0.1110 - val_mse: 0.1110\n",
      "Epoch 8/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1003 - mse: 0.1003 - val_loss: 0.0721 - val_mse: 0.0721\n",
      "Epoch 9/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0652 - mse: 0.0652 - val_loss: 0.0468 - val_mse: 0.0468\n",
      "Epoch 10/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0423 - mse: 0.0423 - val_loss: 0.0302 - val_mse: 0.0302\n",
      "Epoch 11/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0273 - mse: 0.0273 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 12/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0127 - val_mse: 0.0127\n",
      "Epoch 13/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0115 - mse: 0.0115 - val_loss: 0.0082 - val_mse: 0.0082\n",
      "Epoch 14/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0053 - val_mse: 0.0053\n",
      "Epoch 15/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0048 - mse: 0.0048 - val_loss: 0.0034 - val_mse: 0.0034\n",
      "Epoch 16/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0031 - mse: 0.0031 - val_loss: 0.0022 - val_mse: 0.0022\n",
      "Epoch 17/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 18/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 9.3781e-04 - val_mse: 9.3781e-04\n",
      "Epoch 19/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 8.4760e-04 - mse: 8.4760e-04 - val_loss: 6.0885e-04 - val_mse: 6.0885e-04\n",
      "Epoch 20/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 5.5051e-04 - mse: 5.5051e-04 - val_loss: 3.9533e-04 - val_mse: 3.9533e-04\n",
      "Epoch 21/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 3.5733e-04 - mse: 3.5733e-04 - val_loss: 2.5622e-04 - val_mse: 2.5622e-04\n",
      "Epoch 22/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 2.3164e-04 - mse: 2.3164e-04 - val_loss: 1.6604e-04 - val_mse: 1.6604e-04\n",
      "Epoch 23/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.5020e-04 - mse: 1.5020e-04 - val_loss: 1.0716e-04 - val_mse: 1.0716e-04\n",
      "Epoch 24/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 9.6877e-05 - mse: 9.6877e-05 - val_loss: 6.9497e-05 - val_mse: 6.9497e-05\n",
      "Epoch 25/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 6.2829e-05 - mse: 6.2829e-05 - val_loss: 4.5080e-05 - val_mse: 4.5080e-05\n",
      "Epoch 26/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 4.0765e-05 - mse: 4.0765e-05 - val_loss: 2.9155e-05 - val_mse: 2.9155e-05\n",
      "Epoch 27/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 6ms/step - loss: 2.6356e-05 - mse: 2.6356e-05 - val_loss: 1.8990e-05 - val_mse: 1.8990e-05\n",
      "Epoch 28/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.7174e-05 - mse: 1.7174e-05 - val_loss: 1.2326e-05 - val_mse: 1.2326e-05\n",
      "Epoch 29/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.1143e-05 - mse: 1.1143e-05 - val_loss: 7.9590e-06 - val_mse: 7.9590e-06\n",
      "Epoch 30/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 7.1953e-06 - mse: 7.1953e-06 - val_loss: 5.1532e-06 - val_mse: 5.1532e-06\n",
      "Epoch 31/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 4.6592e-06 - mse: 4.6592e-06 - val_loss: 3.3311e-06 - val_mse: 3.3311e-06\n",
      "Epoch 32/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 3.0118e-06 - mse: 3.0118e-06 - val_loss: 2.1637e-06 - val_mse: 2.1637e-06\n",
      "Epoch 33/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.9563e-06 - mse: 1.9563e-06 - val_loss: 1.4073e-06 - val_mse: 1.4073e-06\n",
      "Epoch 34/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.2720e-06 - mse: 1.2720e-06 - val_loss: 9.1012e-07 - val_mse: 9.1012e-07\n",
      "Epoch 35/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 8.2306e-07 - mse: 8.2306e-07 - val_loss: 5.9231e-07 - val_mse: 5.9231e-07\n",
      "Epoch 36/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 5.3560e-07 - mse: 5.3560e-07 - val_loss: 3.8587e-07 - val_mse: 3.8587e-07\n",
      "Epoch 37/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 3.4889e-07 - mse: 3.4889e-07 - val_loss: 2.4969e-07 - val_mse: 2.4969e-07\n",
      "Epoch 38/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 2.2568e-07 - mse: 2.2568e-07 - val_loss: 1.6177e-07 - val_mse: 1.6177e-07\n",
      "Epoch 39/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.4622e-07 - mse: 1.4622e-07 - val_loss: 1.0457e-07 - val_mse: 1.0457e-07\n",
      "Epoch 40/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 9.4565e-08 - mse: 9.4565e-08 - val_loss: 6.8036e-08 - val_mse: 6.8036e-08\n",
      "Epoch 41/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 6.1510e-08 - mse: 6.1510e-08 - val_loss: 4.4180e-08 - val_mse: 4.4180e-08\n",
      "Epoch 42/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 3.9872e-08 - mse: 3.9872e-08 - val_loss: 2.8518e-08 - val_mse: 2.8518e-08\n",
      "Epoch 43/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.5771e-08 - mse: 2.5771e-08 - val_loss: 1.8396e-08 - val_mse: 1.8396e-08\n",
      "Epoch 44/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.6624e-08 - mse: 1.6624e-08 - val_loss: 1.1901e-08 - val_mse: 1.1901e-08\n",
      "Epoch 45/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.0782e-08 - mse: 1.0782e-08 - val_loss: 7.7361e-09 - val_mse: 7.7361e-09\n",
      "Epoch 46/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 6.9854e-09 - mse: 6.9854e-09 - val_loss: 4.9829e-09 - val_mse: 4.9829e-09\n",
      "Epoch 47/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 4.5074e-09 - mse: 4.5074e-09 - val_loss: 3.2164e-09 - val_mse: 3.2164e-09\n",
      "Epoch 48/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.9064e-09 - mse: 2.9064e-09 - val_loss: 2.0822e-09 - val_mse: 2.0822e-09\n",
      "Epoch 49/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.8814e-09 - mse: 1.8814e-09 - val_loss: 1.3529e-09 - val_mse: 1.3529e-09\n",
      "Epoch 50/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.2231e-09 - mse: 1.2231e-09 - val_loss: 8.7467e-10 - val_mse: 8.7467e-10\n",
      "Epoch 1/10\n",
      "4/4 [==============================] - 1s 87ms/step - loss: 3.1615 - mse: 3.1615 - val_loss: 1.4828 - val_mse: 1.4828\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 2.8883 - mse: 2.8883 - val_loss: 1.3879 - val_mse: 1.3879\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 2.6959 - mse: 2.6959 - val_loss: 1.2888 - val_mse: 1.2888\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 2.4928 - mse: 2.4928 - val_loss: 1.2193 - val_mse: 1.2193\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 2.3480 - mse: 2.3480 - val_loss: 1.1624 - val_mse: 1.1624\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 2.2276 - mse: 2.2276 - val_loss: 1.1025 - val_mse: 1.1025\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 2.1036 - mse: 2.1036 - val_loss: 1.0222 - val_mse: 1.0222\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.9300 - mse: 1.9300 - val_loss: 0.9705 - val_mse: 0.9705\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.8162 - mse: 1.8162 - val_loss: 0.9234 - val_mse: 0.9234\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.7184 - mse: 1.7184 - val_loss: 0.8738 - val_mse: 0.8738\n",
      "Epoch 1/30\n",
      "4/4 [==============================] - 1s 87ms/step - loss: 3.1615 - mse: 3.1615 - val_loss: 1.4828 - val_mse: 1.4828\n",
      "Epoch 2/30\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 2.8883 - mse: 2.8883 - val_loss: 1.3879 - val_mse: 1.3879\n",
      "Epoch 3/30\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 2.6959 - mse: 2.6959 - val_loss: 1.2888 - val_mse: 1.2888\n",
      "Epoch 4/30\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 2.4928 - mse: 2.4928 - val_loss: 1.2193 - val_mse: 1.2193\n",
      "Epoch 5/30\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 2.3480 - mse: 2.3480 - val_loss: 1.1624 - val_mse: 1.1624\n",
      "Epoch 6/30\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 2.2276 - mse: 2.2276 - val_loss: 1.1025 - val_mse: 1.1025\n",
      "Epoch 7/30\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 2.1036 - mse: 2.1036 - val_loss: 1.0222 - val_mse: 1.0222\n",
      "Epoch 8/30\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1.9300 - mse: 1.9300 - val_loss: 0.9705 - val_mse: 0.9705\n",
      "Epoch 9/30\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 1.8162 - mse: 1.8162 - val_loss: 0.9234 - val_mse: 0.9234\n",
      "Epoch 10/30\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.7184 - mse: 1.7184 - val_loss: 0.8738 - val_mse: 0.8738\n",
      "Epoch 11/30\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.6125 - mse: 1.6125 - val_loss: 0.8338 - val_mse: 0.8338\n",
      "Epoch 12/30\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.5223 - mse: 1.5223 - val_loss: 0.7799 - val_mse: 0.7799\n",
      "Epoch 13/30\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 1.3989 - mse: 1.3989 - val_loss: 0.7426 - val_mse: 0.7426\n",
      "Epoch 14/30\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 1.3260 - mse: 1.3260 - val_loss: 0.7091 - val_mse: 0.7091\n",
      "Epoch 15/30\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.2654 - mse: 1.2654 - val_loss: 0.6741 - val_mse: 0.6741\n",
      "Epoch 16/30\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.1979 - mse: 1.1979 - val_loss: 0.6424 - val_mse: 0.6424\n",
      "Epoch 17/30\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.1386 - mse: 1.1386 - val_loss: 0.6094 - val_mse: 0.6094\n",
      "Epoch 18/30\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.0737 - mse: 1.0737 - val_loss: 0.5842 - val_mse: 0.5842\n",
      "Epoch 19/30\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1.0199 - mse: 1.0199 - val_loss: 0.5534 - val_mse: 0.5534\n",
      "Epoch 20/30\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.9579 - mse: 0.9579 - val_loss: 0.5254 - val_mse: 0.5254\n",
      "Epoch 21/30\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.9019 - mse: 0.9019 - val_loss: 0.5011 - val_mse: 0.5011\n",
      "Epoch 22/30\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.8567 - mse: 0.8567 - val_loss: 0.4821 - val_mse: 0.4821\n",
      "Epoch 23/30\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.8186 - mse: 0.8186 - val_loss: 0.4611 - val_mse: 0.4611\n",
      "Epoch 24/30\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7790 - mse: 0.7790 - val_loss: 0.4361 - val_mse: 0.4361\n",
      "Epoch 25/30\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.7353 - mse: 0.7353 - val_loss: 0.4165 - val_mse: 0.4165\n",
      "Epoch 26/30\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.6971 - mse: 0.6971 - val_loss: 0.3941 - val_mse: 0.3941\n",
      "Epoch 27/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 26ms/step - loss: 0.6523 - mse: 0.6523 - val_loss: 0.3739 - val_mse: 0.3739\n",
      "Epoch 28/30\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.6164 - mse: 0.6164 - val_loss: 0.3590 - val_mse: 0.3590\n",
      "Epoch 29/30\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.5856 - mse: 0.5856 - val_loss: 0.3402 - val_mse: 0.3402\n",
      "Epoch 30/30\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.5498 - mse: 0.5498 - val_loss: 0.3203 - val_mse: 0.3203\n",
      "Epoch 1/50\n",
      "4/4 [==============================] - 1s 88ms/step - loss: 3.1615 - mse: 3.1615 - val_loss: 1.4828 - val_mse: 1.4828\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 2.8883 - mse: 2.8883 - val_loss: 1.3879 - val_mse: 1.3879\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 2.6959 - mse: 2.6959 - val_loss: 1.2888 - val_mse: 1.2888\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 2.4928 - mse: 2.4928 - val_loss: 1.2193 - val_mse: 1.2193\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 2.3480 - mse: 2.3480 - val_loss: 1.1624 - val_mse: 1.1624\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 2.2276 - mse: 2.2276 - val_loss: 1.1025 - val_mse: 1.1025\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 2.1036 - mse: 2.1036 - val_loss: 1.0222 - val_mse: 1.0222\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.9300 - mse: 1.9300 - val_loss: 0.9705 - val_mse: 0.9705\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1.8162 - mse: 1.8162 - val_loss: 0.9234 - val_mse: 0.9234\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.7184 - mse: 1.7184 - val_loss: 0.8738 - val_mse: 0.8738\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.6125 - mse: 1.6125 - val_loss: 0.8338 - val_mse: 0.8338\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.5223 - mse: 1.5223 - val_loss: 0.7799 - val_mse: 0.7799\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.3989 - mse: 1.3989 - val_loss: 0.7426 - val_mse: 0.7426\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.3260 - mse: 1.3260 - val_loss: 0.7091 - val_mse: 0.7091\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.2654 - mse: 1.2654 - val_loss: 0.6741 - val_mse: 0.6741\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.1979 - mse: 1.1979 - val_loss: 0.6424 - val_mse: 0.6424\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.1386 - mse: 1.1386 - val_loss: 0.6094 - val_mse: 0.6094\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1.0737 - mse: 1.0737 - val_loss: 0.5842 - val_mse: 0.5842\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.0199 - mse: 1.0199 - val_loss: 0.5534 - val_mse: 0.5534\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.9579 - mse: 0.9579 - val_loss: 0.5254 - val_mse: 0.5254\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.9019 - mse: 0.9019 - val_loss: 0.5011 - val_mse: 0.5011\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.8567 - mse: 0.8567 - val_loss: 0.4821 - val_mse: 0.4821\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.8186 - mse: 0.8186 - val_loss: 0.4611 - val_mse: 0.4611\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.7790 - mse: 0.7790 - val_loss: 0.4361 - val_mse: 0.4361\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.7353 - mse: 0.7353 - val_loss: 0.4165 - val_mse: 0.4165\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.6971 - mse: 0.6971 - val_loss: 0.3941 - val_mse: 0.3941\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.6523 - mse: 0.6523 - val_loss: 0.3739 - val_mse: 0.3739\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.6164 - mse: 0.6164 - val_loss: 0.3590 - val_mse: 0.3590\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.5856 - mse: 0.5856 - val_loss: 0.3402 - val_mse: 0.3402\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.5498 - mse: 0.5498 - val_loss: 0.3203 - val_mse: 0.3203\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.5180 - mse: 0.5180 - val_loss: 0.3088 - val_mse: 0.3088\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4934 - mse: 0.4934 - val_loss: 0.2952 - val_mse: 0.2952\n",
      "Epoch 33/50\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.4673 - mse: 0.4673 - val_loss: 0.2820 - val_mse: 0.2820\n",
      "Epoch 34/50\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.4458 - mse: 0.4458 - val_loss: 0.2668 - val_mse: 0.2668\n",
      "Epoch 35/50\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.4248 - mse: 0.4248 - val_loss: 0.2575 - val_mse: 0.2575\n",
      "Epoch 36/50\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.4074 - mse: 0.4074 - val_loss: 0.2459 - val_mse: 0.2459\n",
      "Epoch 37/50\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.3882 - mse: 0.3882 - val_loss: 0.2372 - val_mse: 0.2372\n",
      "Epoch 38/50\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.3703 - mse: 0.3703 - val_loss: 0.2275 - val_mse: 0.2275\n",
      "Epoch 39/50\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.3485 - mse: 0.3485 - val_loss: 0.2175 - val_mse: 0.2175\n",
      "Epoch 40/50\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.3298 - mse: 0.3298 - val_loss: 0.2086 - val_mse: 0.2086\n",
      "Epoch 41/50\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.3147 - mse: 0.3147 - val_loss: 0.1977 - val_mse: 0.1977\n",
      "Epoch 42/50\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.2962 - mse: 0.2962 - val_loss: 0.1888 - val_mse: 0.1888\n",
      "Epoch 43/50\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.2794 - mse: 0.2794 - val_loss: 0.1820 - val_mse: 0.1820\n",
      "Epoch 44/50\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.2656 - mse: 0.2656 - val_loss: 0.1721 - val_mse: 0.1721\n",
      "Epoch 45/50\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.2510 - mse: 0.2510 - val_loss: 0.1636 - val_mse: 0.1636\n",
      "Epoch 46/50\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.2384 - mse: 0.2384 - val_loss: 0.1560 - val_mse: 0.1560\n",
      "Epoch 47/50\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.2268 - mse: 0.2268 - val_loss: 0.1467 - val_mse: 0.1467\n",
      "Epoch 48/50\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.2154 - mse: 0.2154 - val_loss: 0.1391 - val_mse: 0.1391\n",
      "Epoch 49/50\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.2041 - mse: 0.2041 - val_loss: 0.1328 - val_mse: 0.1328\n",
      "Epoch 50/50\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.1948 - mse: 0.1948 - val_loss: 0.1256 - val_mse: 0.1256\n",
      "Epoch 1/10\n",
      "18/18 [==============================] - 1s 19ms/step - loss: 2.9641 - mse: 2.9641 - val_loss: 3.2918 - val_mse: 3.2918\n",
      "Epoch 2/10\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 2.1250 - mse: 2.1250 - val_loss: 2.3878 - val_mse: 2.3878\n",
      "Epoch 3/10\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.5585 - mse: 1.5585 - val_loss: 1.7879 - val_mse: 1.7879\n",
      "Epoch 4/10\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.1812 - mse: 1.1812 - val_loss: 1.3605 - val_mse: 1.3605\n",
      "Epoch 5/10\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.9084 - mse: 0.9084 - val_loss: 1.0462 - val_mse: 1.0462\n",
      "Epoch 6/10\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.7067 - mse: 0.7067 - val_loss: 0.8004 - val_mse: 0.8004\n",
      "Epoch 7/10\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5483 - mse: 0.5483 - val_loss: 0.6120 - val_mse: 0.6120\n",
      "Epoch 8/10\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4249 - mse: 0.4249 - val_loss: 0.4777 - val_mse: 0.4777\n",
      "Epoch 9/10\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.3356 - mse: 0.3356 - val_loss: 0.3731 - val_mse: 0.3731\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 6ms/step - loss: 0.2655 - mse: 0.2655 - val_loss: 0.2905 - val_mse: 0.2905\n",
      "Epoch 1/30\n",
      "18/18 [==============================] - 1s 17ms/step - loss: 2.9641 - mse: 2.9641 - val_loss: 3.2918 - val_mse: 3.2918\n",
      "Epoch 2/30\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.1250 - mse: 2.1250 - val_loss: 2.3878 - val_mse: 2.3878\n",
      "Epoch 3/30\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.5585 - mse: 1.5585 - val_loss: 1.7879 - val_mse: 1.7879\n",
      "Epoch 4/30\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.1812 - mse: 1.1812 - val_loss: 1.3605 - val_mse: 1.3605\n",
      "Epoch 5/30\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.9084 - mse: 0.9084 - val_loss: 1.0462 - val_mse: 1.0462\n",
      "Epoch 6/30\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.7067 - mse: 0.7067 - val_loss: 0.8004 - val_mse: 0.8004\n",
      "Epoch 7/30\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5483 - mse: 0.5483 - val_loss: 0.6120 - val_mse: 0.6120\n",
      "Epoch 8/30\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4249 - mse: 0.4249 - val_loss: 0.4777 - val_mse: 0.4777\n",
      "Epoch 9/30\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3356 - mse: 0.3356 - val_loss: 0.3731 - val_mse: 0.3731\n",
      "Epoch 10/30\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.2655 - mse: 0.2655 - val_loss: 0.2905 - val_mse: 0.2905\n",
      "Epoch 11/30\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.2093 - mse: 0.2093 - val_loss: 0.2273 - val_mse: 0.2273\n",
      "Epoch 12/30\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.1662 - mse: 0.1662 - val_loss: 0.1797 - val_mse: 0.1797\n",
      "Epoch 13/30\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1332 - mse: 0.1332 - val_loss: 0.1426 - val_mse: 0.1426\n",
      "Epoch 14/30\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.1073 - mse: 0.1073 - val_loss: 0.1130 - val_mse: 0.1130\n",
      "Epoch 15/30\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0861 - mse: 0.0861 - val_loss: 0.0896 - val_mse: 0.0896\n",
      "Epoch 16/30\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0696 - mse: 0.0696 - val_loss: 0.0722 - val_mse: 0.0722\n",
      "Epoch 17/30\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0570 - mse: 0.0570 - val_loss: 0.0581 - val_mse: 0.0581\n",
      "Epoch 18/30\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0469 - mse: 0.0469 - val_loss: 0.0474 - val_mse: 0.0474\n",
      "Epoch 19/30\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0388 - mse: 0.0388 - val_loss: 0.0395 - val_mse: 0.0395\n",
      "Epoch 20/30\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0328 - mse: 0.0328 - val_loss: 0.0327 - val_mse: 0.0327\n",
      "Epoch 21/30\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0277 - mse: 0.0277 - val_loss: 0.0276 - val_mse: 0.0276\n",
      "Epoch 22/30\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0237 - mse: 0.0237 - val_loss: 0.0239 - val_mse: 0.0239\n",
      "Epoch 23/30\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0211 - val_mse: 0.0211\n",
      "Epoch 24/30\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0188 - val_mse: 0.0188\n",
      "Epoch 25/30\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 26/30\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 27/30\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 28/30\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 29/30\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 30/30\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0118 - mse: 0.0118 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 1/50\n",
      "18/18 [==============================] - 1s 19ms/step - loss: 2.9641 - mse: 2.9641 - val_loss: 3.2918 - val_mse: 3.2918\n",
      "Epoch 2/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1250 - mse: 2.1250 - val_loss: 2.3878 - val_mse: 2.3878\n",
      "Epoch 3/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.5585 - mse: 1.5585 - val_loss: 1.7879 - val_mse: 1.7879\n",
      "Epoch 4/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.1812 - mse: 1.1812 - val_loss: 1.3605 - val_mse: 1.3605\n",
      "Epoch 5/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.9084 - mse: 0.9084 - val_loss: 1.0462 - val_mse: 1.0462\n",
      "Epoch 6/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.7067 - mse: 0.7067 - val_loss: 0.8004 - val_mse: 0.8004\n",
      "Epoch 7/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5483 - mse: 0.5483 - val_loss: 0.6120 - val_mse: 0.6120\n",
      "Epoch 8/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4249 - mse: 0.4249 - val_loss: 0.4777 - val_mse: 0.4777\n",
      "Epoch 9/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3356 - mse: 0.3356 - val_loss: 0.3731 - val_mse: 0.3731\n",
      "Epoch 10/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.2655 - mse: 0.2655 - val_loss: 0.2905 - val_mse: 0.2905\n",
      "Epoch 11/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.2093 - mse: 0.2093 - val_loss: 0.2273 - val_mse: 0.2273\n",
      "Epoch 12/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1662 - mse: 0.1662 - val_loss: 0.1797 - val_mse: 0.1797\n",
      "Epoch 13/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.1332 - mse: 0.1332 - val_loss: 0.1426 - val_mse: 0.1426\n",
      "Epoch 14/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.1073 - mse: 0.1073 - val_loss: 0.1130 - val_mse: 0.1130\n",
      "Epoch 15/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0861 - mse: 0.0861 - val_loss: 0.0896 - val_mse: 0.0896\n",
      "Epoch 16/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0696 - mse: 0.0696 - val_loss: 0.0722 - val_mse: 0.0722\n",
      "Epoch 17/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0570 - mse: 0.0570 - val_loss: 0.0581 - val_mse: 0.0581\n",
      "Epoch 18/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0469 - mse: 0.0469 - val_loss: 0.0474 - val_mse: 0.0474\n",
      "Epoch 19/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0388 - mse: 0.0388 - val_loss: 0.0395 - val_mse: 0.0395\n",
      "Epoch 20/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0328 - mse: 0.0328 - val_loss: 0.0327 - val_mse: 0.0327\n",
      "Epoch 21/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0277 - mse: 0.0277 - val_loss: 0.0276 - val_mse: 0.0276\n",
      "Epoch 22/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0237 - mse: 0.0237 - val_loss: 0.0239 - val_mse: 0.0239\n",
      "Epoch 23/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0211 - val_mse: 0.0211\n",
      "Epoch 24/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0188 - val_mse: 0.0188\n",
      "Epoch 25/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 26/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 27/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 28/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 29/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 30/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0118 - mse: 0.0118 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 31/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0114 - mse: 0.0114 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 32/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0111 - mse: 0.0111 - val_loss: 0.0133 - val_mse: 0.0133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0108 - mse: 0.0108 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 34/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0106 - mse: 0.0106 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 35/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0105 - mse: 0.0105 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 36/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 37/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 38/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 39/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 40/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 41/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 42/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 43/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 44/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 45/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 46/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 47/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 48/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 49/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 50/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 1s 11ms/step - loss: 2.6177 - mse: 2.6177 - val_loss: 1.7402 - val_mse: 1.7402\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.4950 - mse: 1.4950 - val_loss: 1.0416 - val_mse: 1.0416\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.9216 - mse: 0.9216 - val_loss: 0.6563 - val_mse: 0.6563\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5878 - mse: 0.5878 - val_loss: 0.4200 - val_mse: 0.4200\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.3789 - mse: 0.3789 - val_loss: 0.2748 - val_mse: 0.2748\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2490 - mse: 0.2490 - val_loss: 0.1810 - val_mse: 0.1810\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1646 - mse: 0.1646 - val_loss: 0.1197 - val_mse: 0.1197\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.1094 - mse: 0.1094 - val_loss: 0.0808 - val_mse: 0.0808\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0744 - mse: 0.0744 - val_loss: 0.0553 - val_mse: 0.0553\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0514 - mse: 0.0514 - val_loss: 0.0387 - val_mse: 0.0387\n",
      "Epoch 1/30\n",
      "32/32 [==============================] - 1s 11ms/step - loss: 2.6177 - mse: 2.6177 - val_loss: 1.7402 - val_mse: 1.7402\n",
      "Epoch 2/30\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.4950 - mse: 1.4950 - val_loss: 1.0416 - val_mse: 1.0416\n",
      "Epoch 3/30\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9216 - mse: 0.9216 - val_loss: 0.6563 - val_mse: 0.6563\n",
      "Epoch 4/30\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5878 - mse: 0.5878 - val_loss: 0.4200 - val_mse: 0.4200\n",
      "Epoch 5/30\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.3789 - mse: 0.3789 - val_loss: 0.2748 - val_mse: 0.2748\n",
      "Epoch 6/30\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.2490 - mse: 0.2490 - val_loss: 0.1810 - val_mse: 0.1810\n",
      "Epoch 7/30\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1646 - mse: 0.1646 - val_loss: 0.1197 - val_mse: 0.1197\n",
      "Epoch 8/30\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.1094 - mse: 0.1094 - val_loss: 0.0808 - val_mse: 0.0808\n",
      "Epoch 9/30\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0744 - mse: 0.0744 - val_loss: 0.0553 - val_mse: 0.0553\n",
      "Epoch 10/30\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0514 - mse: 0.0514 - val_loss: 0.0387 - val_mse: 0.0387\n",
      "Epoch 11/30\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0366 - mse: 0.0366 - val_loss: 0.0281 - val_mse: 0.0281\n",
      "Epoch 12/30\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0270 - mse: 0.0270 - val_loss: 0.0212 - val_mse: 0.0212\n",
      "Epoch 13/30\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 14/30\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 15/30\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0119 - val_mse: 0.0119\n",
      "Epoch 16/30\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0106 - val_mse: 0.0106\n",
      "Epoch 17/30\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0114 - mse: 0.0114 - val_loss: 0.0098 - val_mse: 0.0098\n",
      "Epoch 18/30\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0107 - mse: 0.0107 - val_loss: 0.0093 - val_mse: 0.0093\n",
      "Epoch 19/30\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0090 - val_mse: 0.0090\n",
      "Epoch 20/30\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 21/30\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 22/30\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0085 - val_mse: 0.0085\n",
      "Epoch 23/30\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 24/30\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0083 - val_mse: 0.0083\n",
      "Epoch 25/30\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0083 - val_mse: 0.0083\n",
      "Epoch 26/30\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0083 - val_mse: 0.0083\n",
      "Epoch 27/30\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0083 - val_mse: 0.0083\n",
      "Epoch 28/30\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0083 - val_mse: 0.0083\n",
      "Epoch 29/30\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0083 - val_mse: 0.0083\n",
      "Epoch 30/30\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0083 - val_mse: 0.0083\n",
      "Epoch 1/50\n",
      "32/32 [==============================] - 1s 13ms/step - loss: 2.6177 - mse: 2.6177 - val_loss: 1.7402 - val_mse: 1.7402\n",
      "Epoch 2/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.4950 - mse: 1.4950 - val_loss: 1.0416 - val_mse: 1.0416\n",
      "Epoch 3/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9216 - mse: 0.9216 - val_loss: 0.6563 - val_mse: 0.6563\n",
      "Epoch 4/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5878 - mse: 0.5878 - val_loss: 0.4200 - val_mse: 0.4200\n",
      "Epoch 5/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.3789 - mse: 0.3789 - val_loss: 0.2748 - val_mse: 0.2748\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.2490 - mse: 0.2490 - val_loss: 0.1810 - val_mse: 0.1810\n",
      "Epoch 7/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.1646 - mse: 0.1646 - val_loss: 0.1197 - val_mse: 0.1197\n",
      "Epoch 8/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.1094 - mse: 0.1094 - val_loss: 0.0808 - val_mse: 0.0808\n",
      "Epoch 9/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0744 - mse: 0.0744 - val_loss: 0.0553 - val_mse: 0.0553\n",
      "Epoch 10/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0514 - mse: 0.0514 - val_loss: 0.0387 - val_mse: 0.0387\n",
      "Epoch 11/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0366 - mse: 0.0366 - val_loss: 0.0281 - val_mse: 0.0281\n",
      "Epoch 12/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0270 - mse: 0.0270 - val_loss: 0.0212 - val_mse: 0.0212\n",
      "Epoch 13/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 14/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 15/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0119 - val_mse: 0.0119\n",
      "Epoch 16/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0106 - val_mse: 0.0106\n",
      "Epoch 17/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0114 - mse: 0.0114 - val_loss: 0.0098 - val_mse: 0.0098\n",
      "Epoch 18/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0107 - mse: 0.0107 - val_loss: 0.0093 - val_mse: 0.0093\n",
      "Epoch 19/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0090 - val_mse: 0.0090\n",
      "Epoch 20/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 21/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 22/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0085 - val_mse: 0.0085\n",
      "Epoch 23/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 24/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0083 - val_mse: 0.0083\n",
      "Epoch 25/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0083 - val_mse: 0.0083\n",
      "Epoch 26/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0083 - val_mse: 0.0083\n",
      "Epoch 27/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0083 - val_mse: 0.0083\n",
      "Epoch 28/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0083 - val_mse: 0.0083\n",
      "Epoch 29/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0083 - val_mse: 0.0083\n",
      "Epoch 30/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0083 - val_mse: 0.0083\n",
      "Epoch 31/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0083 - val_mse: 0.0083\n",
      "Epoch 32/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0083 - val_mse: 0.0083\n",
      "Epoch 33/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0083 - val_mse: 0.0083\n",
      "Epoch 34/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0083 - val_mse: 0.0083\n",
      "Epoch 35/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0083 - val_mse: 0.0083\n",
      "Epoch 36/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0083 - val_mse: 0.0083\n",
      "Epoch 37/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0083 - val_mse: 0.0083\n",
      "Epoch 38/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0083 - val_mse: 0.0083\n",
      "Epoch 39/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0083 - val_mse: 0.0083\n",
      "Epoch 40/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0083 - val_mse: 0.0083\n",
      "Epoch 41/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0083 - val_mse: 0.0083\n",
      "Epoch 42/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0083 - val_mse: 0.0083\n",
      "Epoch 43/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0083 - val_mse: 0.0083\n",
      "Epoch 44/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0083 - val_mse: 0.0083\n",
      "Epoch 45/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0083 - val_mse: 0.0083\n",
      "Epoch 46/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0083 - val_mse: 0.0083\n",
      "Epoch 47/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0083 - val_mse: 0.0083\n",
      "Epoch 48/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0083 - val_mse: 0.0083\n",
      "Epoch 49/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0083 - val_mse: 0.0083\n",
      "Epoch 50/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0083 - val_mse: 0.0083\n",
      "Epoch 1/10\n",
      "4/4 [==============================] - 1s 80ms/step - loss: 4.4106 - mse: 4.4106 - val_loss: 2.4331 - val_mse: 2.4331\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 4.0906 - mse: 4.0906 - val_loss: 2.3302 - val_mse: 2.3302\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 3.8788 - mse: 3.8788 - val_loss: 2.2234 - val_mse: 2.2234\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 3.6481 - mse: 3.6481 - val_loss: 2.1423 - val_mse: 2.1423\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 3.4697 - mse: 3.4697 - val_loss: 2.0821 - val_mse: 2.0821\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 3.3367 - mse: 3.3367 - val_loss: 2.0216 - val_mse: 2.0216\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 3.2030 - mse: 3.2030 - val_loss: 1.9356 - val_mse: 1.9356\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 3.0031 - mse: 3.0031 - val_loss: 1.8802 - val_mse: 1.8802\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 2.8648 - mse: 2.8648 - val_loss: 1.8255 - val_mse: 1.8255\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 2.7524 - mse: 2.7524 - val_loss: 1.7744 - val_mse: 1.7744\n",
      "Epoch 1/30\n",
      "4/4 [==============================] - 1s 104ms/step - loss: 4.4106 - mse: 4.4106 - val_loss: 2.4331 - val_mse: 2.4331\n",
      "Epoch 2/30\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 4.0906 - mse: 4.0906 - val_loss: 2.3302 - val_mse: 2.3302\n",
      "Epoch 3/30\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 3.8788 - mse: 3.8788 - val_loss: 2.2234 - val_mse: 2.2234\n",
      "Epoch 4/30\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 3.6481 - mse: 3.6481 - val_loss: 2.1423 - val_mse: 2.1423\n",
      "Epoch 5/30\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 3.4697 - mse: 3.4697 - val_loss: 2.0821 - val_mse: 2.0821\n",
      "Epoch 6/30\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 3.3367 - mse: 3.3367 - val_loss: 2.0216 - val_mse: 2.0216\n",
      "Epoch 7/30\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 3.2030 - mse: 3.2030 - val_loss: 1.9356 - val_mse: 1.9356\n",
      "Epoch 8/30\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 3.0031 - mse: 3.0031 - val_loss: 1.8802 - val_mse: 1.8802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 2.8648 - mse: 2.8648 - val_loss: 1.8255 - val_mse: 1.8255\n",
      "Epoch 10/30\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 2.7524 - mse: 2.7524 - val_loss: 1.7744 - val_mse: 1.7744\n",
      "Epoch 11/30\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 2.6365 - mse: 2.6365 - val_loss: 1.7370 - val_mse: 1.7370\n",
      "Epoch 12/30\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 2.5453 - mse: 2.5453 - val_loss: 1.6851 - val_mse: 1.6851\n",
      "Epoch 13/30\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 2.4132 - mse: 2.4132 - val_loss: 1.6439 - val_mse: 1.6439\n",
      "Epoch 14/30\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 2.3379 - mse: 2.3379 - val_loss: 1.5990 - val_mse: 1.5990\n",
      "Epoch 15/30\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 2.2772 - mse: 2.2772 - val_loss: 1.5591 - val_mse: 1.5591\n",
      "Epoch 16/30\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 2.1992 - mse: 2.1992 - val_loss: 1.5293 - val_mse: 1.5293\n",
      "Epoch 17/30\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 2.1403 - mse: 2.1403 - val_loss: 1.5020 - val_mse: 1.5020\n",
      "Epoch 18/30\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 2.0816 - mse: 2.0816 - val_loss: 1.4772 - val_mse: 1.4772\n",
      "Epoch 19/30\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 2.0292 - mse: 2.0292 - val_loss: 1.4455 - val_mse: 1.4455\n",
      "Epoch 20/30\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.9683 - mse: 1.9683 - val_loss: 1.4182 - val_mse: 1.4182\n",
      "Epoch 21/30\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.9048 - mse: 1.9048 - val_loss: 1.3899 - val_mse: 1.3899\n",
      "Epoch 22/30\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.8588 - mse: 1.8588 - val_loss: 1.3736 - val_mse: 1.3736\n",
      "Epoch 23/30\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.8185 - mse: 1.8185 - val_loss: 1.3567 - val_mse: 1.3567\n",
      "Epoch 24/30\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1.7717 - mse: 1.7717 - val_loss: 1.3401 - val_mse: 1.3401\n",
      "Epoch 25/30\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.7292 - mse: 1.7292 - val_loss: 1.3163 - val_mse: 1.3163\n",
      "Epoch 26/30\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1.6891 - mse: 1.6891 - val_loss: 1.2932 - val_mse: 1.2932\n",
      "Epoch 27/30\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 1.6484 - mse: 1.6484 - val_loss: 1.2669 - val_mse: 1.2669\n",
      "Epoch 28/30\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.6064 - mse: 1.6064 - val_loss: 1.2536 - val_mse: 1.2536\n",
      "Epoch 29/30\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1.5720 - mse: 1.5720 - val_loss: 1.2323 - val_mse: 1.2323\n",
      "Epoch 30/30\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.5435 - mse: 1.5435 - val_loss: 1.2027 - val_mse: 1.2027\n",
      "Epoch 1/50\n",
      "4/4 [==============================] - 1s 92ms/step - loss: 4.4106 - mse: 4.4106 - val_loss: 2.4331 - val_mse: 2.4331\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 4.0906 - mse: 4.0906 - val_loss: 2.3302 - val_mse: 2.3302\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 3.8788 - mse: 3.8788 - val_loss: 2.2234 - val_mse: 2.2234\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 3.6481 - mse: 3.6481 - val_loss: 2.1423 - val_mse: 2.1423\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 3.4697 - mse: 3.4697 - val_loss: 2.0821 - val_mse: 2.0821\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 3.3367 - mse: 3.3367 - val_loss: 2.0216 - val_mse: 2.0216\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 3.2030 - mse: 3.2030 - val_loss: 1.9356 - val_mse: 1.9356\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 3.0031 - mse: 3.0031 - val_loss: 1.8802 - val_mse: 1.8802\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 2.8648 - mse: 2.8648 - val_loss: 1.8255 - val_mse: 1.8255\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 2.7524 - mse: 2.7524 - val_loss: 1.7744 - val_mse: 1.7744\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 2.6365 - mse: 2.6365 - val_loss: 1.7370 - val_mse: 1.7370\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 2.5453 - mse: 2.5453 - val_loss: 1.6851 - val_mse: 1.6851\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 2.4132 - mse: 2.4132 - val_loss: 1.6439 - val_mse: 1.6439\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 2.3379 - mse: 2.3379 - val_loss: 1.5990 - val_mse: 1.5990\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 2.2772 - mse: 2.2772 - val_loss: 1.5591 - val_mse: 1.5591\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 2.1992 - mse: 2.1992 - val_loss: 1.5293 - val_mse: 1.5293\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 2.1403 - mse: 2.1403 - val_loss: 1.5020 - val_mse: 1.5020\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 2.0816 - mse: 2.0816 - val_loss: 1.4772 - val_mse: 1.4772\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 2.0292 - mse: 2.0292 - val_loss: 1.4455 - val_mse: 1.4455\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.9683 - mse: 1.9683 - val_loss: 1.4182 - val_mse: 1.4182\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.9048 - mse: 1.9048 - val_loss: 1.3899 - val_mse: 1.3899\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.8588 - mse: 1.8588 - val_loss: 1.3736 - val_mse: 1.3736\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 1.8185 - mse: 1.8185 - val_loss: 1.3567 - val_mse: 1.3567\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.7717 - mse: 1.7717 - val_loss: 1.3401 - val_mse: 1.3401\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1.7292 - mse: 1.7292 - val_loss: 1.3163 - val_mse: 1.3163\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 1.6891 - mse: 1.6891 - val_loss: 1.2932 - val_mse: 1.2932\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1.6484 - mse: 1.6484 - val_loss: 1.2669 - val_mse: 1.2669\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.6064 - mse: 1.6064 - val_loss: 1.2536 - val_mse: 1.2536\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1.5720 - mse: 1.5720 - val_loss: 1.2323 - val_mse: 1.2323\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.5435 - mse: 1.5435 - val_loss: 1.2027 - val_mse: 1.2027\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.5136 - mse: 1.5136 - val_loss: 1.1974 - val_mse: 1.1974\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.4850 - mse: 1.4850 - val_loss: 1.1842 - val_mse: 1.1842\n",
      "Epoch 33/50\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1.4515 - mse: 1.4515 - val_loss: 1.1730 - val_mse: 1.1730\n",
      "Epoch 34/50\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1.4288 - mse: 1.4288 - val_loss: 1.1628 - val_mse: 1.1628\n",
      "Epoch 35/50\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.4094 - mse: 1.4094 - val_loss: 1.1485 - val_mse: 1.1485\n",
      "Epoch 36/50\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.3936 - mse: 1.3936 - val_loss: 1.1315 - val_mse: 1.1315\n",
      "Epoch 37/50\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1.3714 - mse: 1.3714 - val_loss: 1.1236 - val_mse: 1.1236\n",
      "Epoch 38/50\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.3546 - mse: 1.3546 - val_loss: 1.1134 - val_mse: 1.1134\n",
      "Epoch 39/50\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.3349 - mse: 1.3349 - val_loss: 1.1120 - val_mse: 1.1120\n",
      "Epoch 40/50\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.3192 - mse: 1.3192 - val_loss: 1.0972 - val_mse: 1.0972\n",
      "Epoch 41/50\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 1.3007 - mse: 1.3007 - val_loss: 1.0786 - val_mse: 1.0786\n",
      "Epoch 42/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 34ms/step - loss: 1.2788 - mse: 1.2788 - val_loss: 1.0637 - val_mse: 1.0637\n",
      "Epoch 43/50\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.2646 - mse: 1.2646 - val_loss: 1.0625 - val_mse: 1.0625\n",
      "Epoch 44/50\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.2531 - mse: 1.2531 - val_loss: 1.0443 - val_mse: 1.0443\n",
      "Epoch 45/50\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.2369 - mse: 1.2369 - val_loss: 1.0378 - val_mse: 1.0378\n",
      "Epoch 46/50\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.2225 - mse: 1.2225 - val_loss: 1.0322 - val_mse: 1.0322\n",
      "Epoch 47/50\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.2146 - mse: 1.2146 - val_loss: 1.0253 - val_mse: 1.0253\n",
      "Epoch 48/50\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.2036 - mse: 1.2036 - val_loss: 1.0141 - val_mse: 1.0141\n",
      "Epoch 49/50\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.1944 - mse: 1.1944 - val_loss: 1.0047 - val_mse: 1.0047\n",
      "Epoch 50/50\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.1820 - mse: 1.1820 - val_loss: 0.9896 - val_mse: 0.9896\n",
      "Epoch 1/10\n",
      "18/18 [==============================] - 1s 19ms/step - loss: 4.0356 - mse: 4.0356 - val_loss: 4.1757 - val_mse: 4.1757\n",
      "Epoch 2/10\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 3.1911 - mse: 3.1911 - val_loss: 3.3219 - val_mse: 3.3219\n",
      "Epoch 3/10\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 2.6249 - mse: 2.6249 - val_loss: 2.7592 - val_mse: 2.7592\n",
      "Epoch 4/10\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 2.2403 - mse: 2.2403 - val_loss: 2.3611 - val_mse: 2.3611\n",
      "Epoch 5/10\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 1.9543 - mse: 1.9543 - val_loss: 2.0720 - val_mse: 2.0720\n",
      "Epoch 6/10\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1.7429 - mse: 1.7429 - val_loss: 1.8529 - val_mse: 1.8529\n",
      "Epoch 7/10\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.5722 - mse: 1.5722 - val_loss: 1.6880 - val_mse: 1.6880\n",
      "Epoch 8/10\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.4380 - mse: 1.4380 - val_loss: 1.5789 - val_mse: 1.5789\n",
      "Epoch 9/10\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1.3403 - mse: 1.3403 - val_loss: 1.4960 - val_mse: 1.4960\n",
      "Epoch 10/10\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.2648 - mse: 1.2648 - val_loss: 1.4472 - val_mse: 1.4472\n",
      "Epoch 1/30\n",
      "18/18 [==============================] - 1s 27ms/step - loss: 4.0356 - mse: 4.0356 - val_loss: 4.1757 - val_mse: 4.1757\n",
      "Epoch 2/30\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 3.1911 - mse: 3.1911 - val_loss: 3.3219 - val_mse: 3.3219\n",
      "Epoch 3/30\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.6249 - mse: 2.6249 - val_loss: 2.7592 - val_mse: 2.7592\n",
      "Epoch 4/30\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2403 - mse: 2.2403 - val_loss: 2.3611 - val_mse: 2.3611\n",
      "Epoch 5/30\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.9543 - mse: 1.9543 - val_loss: 2.0720 - val_mse: 2.0720\n",
      "Epoch 6/30\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.7429 - mse: 1.7429 - val_loss: 1.8529 - val_mse: 1.8529\n",
      "Epoch 7/30\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 1.5722 - mse: 1.5722 - val_loss: 1.6880 - val_mse: 1.6880\n",
      "Epoch 8/30\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 1.4380 - mse: 1.4380 - val_loss: 1.5789 - val_mse: 1.5789\n",
      "Epoch 9/30\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.3403 - mse: 1.3403 - val_loss: 1.4960 - val_mse: 1.4960\n",
      "Epoch 10/30\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.2648 - mse: 1.2648 - val_loss: 1.4472 - val_mse: 1.4472\n",
      "Epoch 11/30\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.2088 - mse: 1.2088 - val_loss: 1.4054 - val_mse: 1.4054\n",
      "Epoch 12/30\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1.1635 - mse: 1.1635 - val_loss: 1.3709 - val_mse: 1.3709\n",
      "Epoch 13/30\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.1257 - mse: 1.1257 - val_loss: 1.3542 - val_mse: 1.3542\n",
      "Epoch 14/30\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1.0987 - mse: 1.0987 - val_loss: 1.3413 - val_mse: 1.3413\n",
      "Epoch 15/30\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0738 - mse: 1.0738 - val_loss: 1.3293 - val_mse: 1.3293\n",
      "Epoch 16/30\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0547 - mse: 1.0547 - val_loss: 1.3234 - val_mse: 1.3234\n",
      "Epoch 17/30\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0418 - mse: 1.0418 - val_loss: 1.3149 - val_mse: 1.3149\n",
      "Epoch 18/30\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0295 - mse: 1.0295 - val_loss: 1.3160 - val_mse: 1.3160\n",
      "Epoch 19/30\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0195 - mse: 1.0195 - val_loss: 1.3198 - val_mse: 1.3198\n",
      "Epoch 20/30\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0142 - mse: 1.0142 - val_loss: 1.3197 - val_mse: 1.3197\n",
      "Epoch 21/30\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0076 - mse: 1.0076 - val_loss: 1.3240 - val_mse: 1.3240\n",
      "Epoch 22/30\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0032 - mse: 1.0032 - val_loss: 1.3269 - val_mse: 1.3269\n",
      "Epoch 23/30\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0003 - mse: 1.0003 - val_loss: 1.3303 - val_mse: 1.3303\n",
      "Epoch 24/30\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.9980 - mse: 0.9980 - val_loss: 1.3331 - val_mse: 1.3331\n",
      "Epoch 25/30\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.9959 - mse: 0.9959 - val_loss: 1.3333 - val_mse: 1.3333\n",
      "Epoch 26/30\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.9945 - mse: 0.9945 - val_loss: 1.3408 - val_mse: 1.3408\n",
      "Epoch 27/30\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.9927 - mse: 0.9927 - val_loss: 1.3434 - val_mse: 1.3434\n",
      "Epoch 28/30\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.9915 - mse: 0.9915 - val_loss: 1.3472 - val_mse: 1.3472\n",
      "Epoch 29/30\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.9903 - mse: 0.9903 - val_loss: 1.3538 - val_mse: 1.3538\n",
      "Epoch 30/30\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.9895 - mse: 0.9895 - val_loss: 1.3540 - val_mse: 1.3540\n",
      "Epoch 1/50\n",
      "18/18 [==============================] - 1s 18ms/step - loss: 4.0356 - mse: 4.0356 - val_loss: 4.1757 - val_mse: 4.1757\n",
      "Epoch 2/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 3.1911 - mse: 3.1911 - val_loss: 3.3219 - val_mse: 3.3219\n",
      "Epoch 3/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 2.6249 - mse: 2.6249 - val_loss: 2.7592 - val_mse: 2.7592\n",
      "Epoch 4/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 2.2403 - mse: 2.2403 - val_loss: 2.3611 - val_mse: 2.3611\n",
      "Epoch 5/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.9543 - mse: 1.9543 - val_loss: 2.0720 - val_mse: 2.0720\n",
      "Epoch 6/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.7429 - mse: 1.7429 - val_loss: 1.8529 - val_mse: 1.8529\n",
      "Epoch 7/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.5722 - mse: 1.5722 - val_loss: 1.6880 - val_mse: 1.6880\n",
      "Epoch 8/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1.4380 - mse: 1.4380 - val_loss: 1.5789 - val_mse: 1.5789\n",
      "Epoch 9/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.3403 - mse: 1.3403 - val_loss: 1.4960 - val_mse: 1.4960\n",
      "Epoch 10/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.2648 - mse: 1.2648 - val_loss: 1.4472 - val_mse: 1.4472\n",
      "Epoch 11/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.2088 - mse: 1.2088 - val_loss: 1.4054 - val_mse: 1.4054\n",
      "Epoch 12/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.1635 - mse: 1.1635 - val_loss: 1.3709 - val_mse: 1.3709\n",
      "Epoch 13/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.1257 - mse: 1.1257 - val_loss: 1.3542 - val_mse: 1.3542\n",
      "Epoch 14/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0987 - mse: 1.0987 - val_loss: 1.3413 - val_mse: 1.3413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.0738 - mse: 1.0738 - val_loss: 1.3293 - val_mse: 1.3293\n",
      "Epoch 16/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0547 - mse: 1.0547 - val_loss: 1.3234 - val_mse: 1.3234\n",
      "Epoch 17/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0418 - mse: 1.0418 - val_loss: 1.3149 - val_mse: 1.3149\n",
      "Epoch 18/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0295 - mse: 1.0295 - val_loss: 1.3160 - val_mse: 1.3160\n",
      "Epoch 19/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0195 - mse: 1.0195 - val_loss: 1.3198 - val_mse: 1.3198\n",
      "Epoch 20/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0142 - mse: 1.0142 - val_loss: 1.3197 - val_mse: 1.3197\n",
      "Epoch 21/50\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1.0076 - mse: 1.0076 - val_loss: 1.3240 - val_mse: 1.3240\n",
      "Epoch 22/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0032 - mse: 1.0032 - val_loss: 1.3269 - val_mse: 1.3269\n",
      "Epoch 23/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0003 - mse: 1.0003 - val_loss: 1.3303 - val_mse: 1.3303\n",
      "Epoch 24/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.9980 - mse: 0.9980 - val_loss: 1.3331 - val_mse: 1.3331\n",
      "Epoch 25/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.9959 - mse: 0.9959 - val_loss: 1.3333 - val_mse: 1.3333\n",
      "Epoch 26/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.9945 - mse: 0.9945 - val_loss: 1.3408 - val_mse: 1.3408\n",
      "Epoch 27/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.9927 - mse: 0.9927 - val_loss: 1.3434 - val_mse: 1.3434\n",
      "Epoch 28/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.9915 - mse: 0.9915 - val_loss: 1.3472 - val_mse: 1.3472\n",
      "Epoch 29/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.9903 - mse: 0.9903 - val_loss: 1.3538 - val_mse: 1.3538\n",
      "Epoch 30/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.9895 - mse: 0.9895 - val_loss: 1.3540 - val_mse: 1.3540\n",
      "Epoch 31/50\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.9892 - mse: 0.9892 - val_loss: 1.3531 - val_mse: 1.3531\n",
      "Epoch 32/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.9892 - mse: 0.9892 - val_loss: 1.3580 - val_mse: 1.3580\n",
      "Epoch 33/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.9888 - mse: 0.9888 - val_loss: 1.3611 - val_mse: 1.3611\n",
      "Epoch 34/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.9882 - mse: 0.9882 - val_loss: 1.3616 - val_mse: 1.3616\n",
      "Epoch 35/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.9884 - mse: 0.9884 - val_loss: 1.3599 - val_mse: 1.3599\n",
      "Epoch 36/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.9888 - mse: 0.9888 - val_loss: 1.3609 - val_mse: 1.3609\n",
      "Epoch 37/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.9884 - mse: 0.9884 - val_loss: 1.3613 - val_mse: 1.3613\n",
      "Epoch 38/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.9883 - mse: 0.9883 - val_loss: 1.3603 - val_mse: 1.3603\n",
      "Epoch 39/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.9885 - mse: 0.9885 - val_loss: 1.3644 - val_mse: 1.3644\n",
      "Epoch 40/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.9880 - mse: 0.9880 - val_loss: 1.3661 - val_mse: 1.3661\n",
      "Epoch 41/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.9880 - mse: 0.9880 - val_loss: 1.3688 - val_mse: 1.3688\n",
      "Epoch 42/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.9885 - mse: 0.9885 - val_loss: 1.3692 - val_mse: 1.3692\n",
      "Epoch 43/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.9883 - mse: 0.9883 - val_loss: 1.3713 - val_mse: 1.3713\n",
      "Epoch 44/50\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.9880 - mse: 0.9880 - val_loss: 1.3695 - val_mse: 1.3695\n",
      "Epoch 45/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.9880 - mse: 0.9880 - val_loss: 1.3707 - val_mse: 1.3707\n",
      "Epoch 46/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.9878 - mse: 0.9878 - val_loss: 1.3742 - val_mse: 1.3742\n",
      "Epoch 47/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.9878 - mse: 0.9878 - val_loss: 1.3731 - val_mse: 1.3731\n",
      "Epoch 48/50\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.9876 - mse: 0.9876 - val_loss: 1.3745 - val_mse: 1.3745\n",
      "Epoch 49/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.9878 - mse: 0.9878 - val_loss: 1.3743 - val_mse: 1.3743\n",
      "Epoch 50/50\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.9880 - mse: 0.9880 - val_loss: 1.3714 - val_mse: 1.3714\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 1s 12ms/step - loss: 3.5051 - mse: 3.5051 - val_loss: 2.5620 - val_mse: 2.5620\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.3817 - mse: 2.3817 - val_loss: 1.8581 - val_mse: 1.8581\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.8169 - mse: 1.8169 - val_loss: 1.4731 - val_mse: 1.4731\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.4933 - mse: 1.4933 - val_loss: 1.2381 - val_mse: 1.2381\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.2910 - mse: 1.2910 - val_loss: 1.0931 - val_mse: 1.0931\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.1643 - mse: 1.1643 - val_loss: 1.0023 - val_mse: 1.0023\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.0837 - mse: 1.0837 - val_loss: 0.9417 - val_mse: 0.9417\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0316 - mse: 1.0316 - val_loss: 0.9020 - val_mse: 0.9020\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9970 - mse: 0.9970 - val_loss: 0.8750 - val_mse: 0.8750\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9738 - mse: 0.9738 - val_loss: 0.8589 - val_mse: 0.8589\n",
      "Epoch 1/30\n",
      "32/32 [==============================] - 1s 11ms/step - loss: 3.5051 - mse: 3.5051 - val_loss: 2.5620 - val_mse: 2.5620\n",
      "Epoch 2/30\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 2.3817 - mse: 2.3817 - val_loss: 1.8581 - val_mse: 1.8581\n",
      "Epoch 3/30\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.8169 - mse: 1.8169 - val_loss: 1.4731 - val_mse: 1.4731\n",
      "Epoch 4/30\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.4933 - mse: 1.4933 - val_loss: 1.2381 - val_mse: 1.2381\n",
      "Epoch 5/30\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.2910 - mse: 1.2910 - val_loss: 1.0931 - val_mse: 1.0931\n",
      "Epoch 6/30\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.1643 - mse: 1.1643 - val_loss: 1.0023 - val_mse: 1.0023\n",
      "Epoch 7/30\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 1.0837 - mse: 1.0837 - val_loss: 0.9417 - val_mse: 0.9417\n",
      "Epoch 8/30\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0316 - mse: 1.0316 - val_loss: 0.9020 - val_mse: 0.9020\n",
      "Epoch 9/30\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9970 - mse: 0.9970 - val_loss: 0.8750 - val_mse: 0.8750\n",
      "Epoch 10/30\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9738 - mse: 0.9738 - val_loss: 0.8589 - val_mse: 0.8589\n",
      "Epoch 11/30\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9596 - mse: 0.9596 - val_loss: 0.8486 - val_mse: 0.8486\n",
      "Epoch 12/30\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9508 - mse: 0.9508 - val_loss: 0.8410 - val_mse: 0.8410\n",
      "Epoch 13/30\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9446 - mse: 0.9446 - val_loss: 0.8364 - val_mse: 0.8364\n",
      "Epoch 14/30\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9408 - mse: 0.9408 - val_loss: 0.8331 - val_mse: 0.8331\n",
      "Epoch 15/30\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9382 - mse: 0.9382 - val_loss: 0.8314 - val_mse: 0.8314\n",
      "Epoch 16/30\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.9368 - mse: 0.9368 - val_loss: 0.8299 - val_mse: 0.8299\n",
      "Epoch 17/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 6ms/step - loss: 0.9355 - mse: 0.9355 - val_loss: 0.8288 - val_mse: 0.8288\n",
      "Epoch 18/30\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9347 - mse: 0.9347 - val_loss: 0.8288 - val_mse: 0.8288\n",
      "Epoch 19/30\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9350 - mse: 0.9350 - val_loss: 0.8281 - val_mse: 0.8281\n",
      "Epoch 20/30\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9343 - mse: 0.9343 - val_loss: 0.8277 - val_mse: 0.8277\n",
      "Epoch 21/30\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.9342 - mse: 0.9342 - val_loss: 0.8269 - val_mse: 0.8269\n",
      "Epoch 22/30\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9337 - mse: 0.9337 - val_loss: 0.8266 - val_mse: 0.8266\n",
      "Epoch 23/30\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9336 - mse: 0.9336 - val_loss: 0.8265 - val_mse: 0.8265\n",
      "Epoch 24/30\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.9334 - mse: 0.9334 - val_loss: 0.8261 - val_mse: 0.8261\n",
      "Epoch 25/30\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9333 - mse: 0.9333 - val_loss: 0.8268 - val_mse: 0.8268\n",
      "Epoch 26/30\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9338 - mse: 0.9338 - val_loss: 0.8262 - val_mse: 0.8262\n",
      "Epoch 27/30\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9335 - mse: 0.9335 - val_loss: 0.8260 - val_mse: 0.8260\n",
      "Epoch 28/30\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9336 - mse: 0.9336 - val_loss: 0.8262 - val_mse: 0.8262\n",
      "Epoch 29/30\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9335 - mse: 0.9335 - val_loss: 0.8263 - val_mse: 0.8263\n",
      "Epoch 30/30\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9334 - mse: 0.9334 - val_loss: 0.8261 - val_mse: 0.8261\n",
      "Epoch 1/50\n",
      "32/32 [==============================] - 1s 11ms/step - loss: 3.5051 - mse: 3.5051 - val_loss: 2.5620 - val_mse: 2.5620\n",
      "Epoch 2/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 2.3817 - mse: 2.3817 - val_loss: 1.8581 - val_mse: 1.8581\n",
      "Epoch 3/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.8169 - mse: 1.8169 - val_loss: 1.4731 - val_mse: 1.4731\n",
      "Epoch 4/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.4933 - mse: 1.4933 - val_loss: 1.2381 - val_mse: 1.2381\n",
      "Epoch 5/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.2910 - mse: 1.2910 - val_loss: 1.0931 - val_mse: 1.0931\n",
      "Epoch 6/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 1.1643 - mse: 1.1643 - val_loss: 1.0023 - val_mse: 1.0023\n",
      "Epoch 7/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0837 - mse: 1.0837 - val_loss: 0.9417 - val_mse: 0.9417\n",
      "Epoch 8/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.0316 - mse: 1.0316 - val_loss: 0.9020 - val_mse: 0.9020\n",
      "Epoch 9/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9970 - mse: 0.9970 - val_loss: 0.8750 - val_mse: 0.8750\n",
      "Epoch 10/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9738 - mse: 0.9738 - val_loss: 0.8589 - val_mse: 0.8589\n",
      "Epoch 11/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9596 - mse: 0.9596 - val_loss: 0.8486 - val_mse: 0.8486\n",
      "Epoch 12/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.9508 - mse: 0.9508 - val_loss: 0.8410 - val_mse: 0.8410\n",
      "Epoch 13/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9446 - mse: 0.9446 - val_loss: 0.8364 - val_mse: 0.8364\n",
      "Epoch 14/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9408 - mse: 0.9408 - val_loss: 0.8331 - val_mse: 0.8331\n",
      "Epoch 15/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9382 - mse: 0.9382 - val_loss: 0.8314 - val_mse: 0.8314\n",
      "Epoch 16/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9368 - mse: 0.9368 - val_loss: 0.8299 - val_mse: 0.8299\n",
      "Epoch 17/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9355 - mse: 0.9355 - val_loss: 0.8288 - val_mse: 0.8288\n",
      "Epoch 18/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9347 - mse: 0.9347 - val_loss: 0.8288 - val_mse: 0.8288\n",
      "Epoch 19/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9350 - mse: 0.9350 - val_loss: 0.8281 - val_mse: 0.8281\n",
      "Epoch 20/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9343 - mse: 0.9343 - val_loss: 0.8277 - val_mse: 0.8277\n",
      "Epoch 21/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9342 - mse: 0.9342 - val_loss: 0.8269 - val_mse: 0.8269\n",
      "Epoch 22/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9337 - mse: 0.9337 - val_loss: 0.8266 - val_mse: 0.8266\n",
      "Epoch 23/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9336 - mse: 0.9336 - val_loss: 0.8265 - val_mse: 0.8265\n",
      "Epoch 24/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9334 - mse: 0.9334 - val_loss: 0.8261 - val_mse: 0.8261\n",
      "Epoch 25/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9333 - mse: 0.9333 - val_loss: 0.8268 - val_mse: 0.8268\n",
      "Epoch 26/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9338 - mse: 0.9338 - val_loss: 0.8262 - val_mse: 0.8262\n",
      "Epoch 27/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.9335 - mse: 0.9335 - val_loss: 0.8260 - val_mse: 0.8260\n",
      "Epoch 28/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9336 - mse: 0.9336 - val_loss: 0.8262 - val_mse: 0.8262\n",
      "Epoch 29/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9335 - mse: 0.9335 - val_loss: 0.8263 - val_mse: 0.8263\n",
      "Epoch 30/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9334 - mse: 0.9334 - val_loss: 0.8261 - val_mse: 0.8261\n",
      "Epoch 31/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.9332 - mse: 0.9332 - val_loss: 0.8262 - val_mse: 0.8262\n",
      "Epoch 32/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.9334 - mse: 0.9334 - val_loss: 0.8262 - val_mse: 0.8262\n",
      "Epoch 33/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.9335 - mse: 0.9335 - val_loss: 0.8262 - val_mse: 0.8262\n",
      "Epoch 34/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9333 - mse: 0.9333 - val_loss: 0.8261 - val_mse: 0.8261\n",
      "Epoch 35/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.9332 - mse: 0.9332 - val_loss: 0.8264 - val_mse: 0.8264\n",
      "Epoch 36/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9335 - mse: 0.9335 - val_loss: 0.8262 - val_mse: 0.8262\n",
      "Epoch 37/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9334 - mse: 0.9334 - val_loss: 0.8259 - val_mse: 0.8259\n",
      "Epoch 38/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9333 - mse: 0.9333 - val_loss: 0.8261 - val_mse: 0.8261\n",
      "Epoch 39/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.9334 - mse: 0.9334 - val_loss: 0.8267 - val_mse: 0.8267\n",
      "Epoch 40/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.9336 - mse: 0.9336 - val_loss: 0.8269 - val_mse: 0.8269\n",
      "Epoch 41/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9335 - mse: 0.9335 - val_loss: 0.8262 - val_mse: 0.8262\n",
      "Epoch 42/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9334 - mse: 0.9334 - val_loss: 0.8267 - val_mse: 0.8267\n",
      "Epoch 43/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9337 - mse: 0.9337 - val_loss: 0.8264 - val_mse: 0.8264\n",
      "Epoch 44/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9333 - mse: 0.9333 - val_loss: 0.8265 - val_mse: 0.8265\n",
      "Epoch 45/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.9333 - mse: 0.9333 - val_loss: 0.8264 - val_mse: 0.8264\n",
      "Epoch 46/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.9332 - mse: 0.9332 - val_loss: 0.8260 - val_mse: 0.8260\n",
      "Epoch 47/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9334 - mse: 0.9334 - val_loss: 0.8260 - val_mse: 0.8260\n",
      "Epoch 48/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9333 - mse: 0.9333 - val_loss: 0.8261 - val_mse: 0.8261\n",
      "Epoch 49/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.9335 - mse: 0.9335 - val_loss: 0.8266 - val_mse: 0.8266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.9334 - mse: 0.9334 - val_loss: 0.8263 - val_mse: 0.8263\n"
     ]
    }
   ],
   "source": [
    "for sigma in sigmas:\n",
    "    for Ntrain in Ntrains:\n",
    "        Nvalid = Ntrain // 10\n",
    "        for Nepochs in Nepochss:\n",
    "            #Reset rangen\n",
    "            np.random.seed(0)\n",
    "            tf.random.set_seed(0)\n",
    "            #creating training and validation datasets\n",
    "            x_train = np.random.uniform(-1, 1, Ntrain)\n",
    "            x_valid.sort()\n",
    "            y_train = np.random.normal(m * x_train + b, sigma)\n",
    "            \n",
    "            x_valid = np.random.uniform(-1, 1, Nvalid)\n",
    "            y_valid = np.random.normal(m * x_valid + b, sigma) \n",
    "            \n",
    "            y_target = m * x_valid + b\n",
    "            #creating and compiling the model\n",
    "            model = tf.keras.Sequential()\n",
    "            model.add(Dense(1, input_shape=(1,)))\n",
    "            model.compile(optimizer='sgd', loss='mse', metrics=['mse'])\n",
    "            #optimizing the model\n",
    "            history = model.fit(x=x_train, y=y_train, batch_size=32, \n",
    "                                epochs=Nepochs,shuffle=True, \n",
    "                                validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec119596",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f3ef8a50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(x_valid, y_target, label='target')\n",
    "plt.scatter(x_valid, y_valid, color='r', label='validation data')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a30d0a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import get_custom_objects\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(Dense(1, input_shape=(1,)))\n",
    "\n",
    "# compile the model choosing optimizer, loss and metrics objects\n",
    "model.compile(optimizer='sgd', loss='mse', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cedbc149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "32/32 [==============================] - 1s 12ms/step - loss: 4.1913 - mse: 4.1913 - val_loss: 3.6822 - val_mse: 3.6822\n",
      "Epoch 2/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 2.5888 - mse: 2.5888 - val_loss: 2.4248 - val_mse: 2.4248\n",
      "Epoch 3/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.7104 - mse: 1.7104 - val_loss: 1.6584 - val_mse: 1.6584\n",
      "Epoch 4/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 1.1792 - mse: 1.1792 - val_loss: 1.1715 - val_mse: 1.1715\n",
      "Epoch 5/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.8473 - mse: 0.8473 - val_loss: 0.8475 - val_mse: 0.8475\n",
      "Epoch 6/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6300 - mse: 0.6300 - val_loss: 0.6389 - val_mse: 0.6389\n",
      "Epoch 7/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.4929 - mse: 0.4929 - val_loss: 0.5004 - val_mse: 0.5004\n",
      "Epoch 8/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.4038 - mse: 0.4038 - val_loss: 0.4076 - val_mse: 0.4076\n",
      "Epoch 9/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.3457 - mse: 0.3457 - val_loss: 0.3438 - val_mse: 0.3438\n",
      "Epoch 10/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.3073 - mse: 0.3073 - val_loss: 0.3023 - val_mse: 0.3023\n",
      "Epoch 11/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.2830 - mse: 0.2830 - val_loss: 0.2729 - val_mse: 0.2729\n",
      "Epoch 12/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.2667 - mse: 0.2667 - val_loss: 0.2530 - val_mse: 0.2530\n",
      "Epoch 13/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.2561 - mse: 0.2561 - val_loss: 0.2390 - val_mse: 0.2390\n",
      "Epoch 14/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.2491 - mse: 0.2491 - val_loss: 0.2293 - val_mse: 0.2293\n",
      "Epoch 15/50\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2448 - mse: 0.2448 - val_loss: 0.2234 - val_mse: 0.2234\n",
      "Epoch 16/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.2423 - mse: 0.2423 - val_loss: 0.2192 - val_mse: 0.2192\n",
      "Epoch 17/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.2406 - mse: 0.2406 - val_loss: 0.2157 - val_mse: 0.2157\n",
      "Epoch 18/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.2394 - mse: 0.2394 - val_loss: 0.2132 - val_mse: 0.2132\n",
      "Epoch 19/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.2386 - mse: 0.2386 - val_loss: 0.2113 - val_mse: 0.2113\n",
      "Epoch 20/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.2381 - mse: 0.2381 - val_loss: 0.2096 - val_mse: 0.2096\n",
      "Epoch 21/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.2377 - mse: 0.2377 - val_loss: 0.2086 - val_mse: 0.2086\n",
      "Epoch 22/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.2375 - mse: 0.2375 - val_loss: 0.2080 - val_mse: 0.2080\n",
      "Epoch 23/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.2373 - mse: 0.2373 - val_loss: 0.2074 - val_mse: 0.2074\n",
      "Epoch 24/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.2373 - mse: 0.2373 - val_loss: 0.2071 - val_mse: 0.2071\n",
      "Epoch 25/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.2372 - mse: 0.2372 - val_loss: 0.2065 - val_mse: 0.2065\n",
      "Epoch 26/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.2371 - mse: 0.2371 - val_loss: 0.2064 - val_mse: 0.2064\n",
      "Epoch 27/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.2372 - mse: 0.2372 - val_loss: 0.2062 - val_mse: 0.2062\n",
      "Epoch 28/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.2371 - mse: 0.2371 - val_loss: 0.2056 - val_mse: 0.2056\n",
      "Epoch 29/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.2371 - mse: 0.2371 - val_loss: 0.2058 - val_mse: 0.2058\n",
      "Epoch 30/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.2372 - mse: 0.2372 - val_loss: 0.2057 - val_mse: 0.2057\n",
      "Epoch 31/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.2372 - mse: 0.2372 - val_loss: 0.2059 - val_mse: 0.2059\n",
      "Epoch 32/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.2372 - mse: 0.2372 - val_loss: 0.2058 - val_mse: 0.2058\n",
      "Epoch 33/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.2371 - mse: 0.2371 - val_loss: 0.2060 - val_mse: 0.2060\n",
      "Epoch 34/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.2371 - mse: 0.2371 - val_loss: 0.2055 - val_mse: 0.2055\n",
      "Epoch 35/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.2371 - mse: 0.2371 - val_loss: 0.2055 - val_mse: 0.2055\n",
      "Epoch 36/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.2371 - mse: 0.2371 - val_loss: 0.2053 - val_mse: 0.2053\n",
      "Epoch 37/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.2371 - mse: 0.2371 - val_loss: 0.2053 - val_mse: 0.2053\n",
      "Epoch 38/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.2371 - mse: 0.2371 - val_loss: 0.2054 - val_mse: 0.2054\n",
      "Epoch 39/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.2371 - mse: 0.2371 - val_loss: 0.2055 - val_mse: 0.2055\n",
      "Epoch 40/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.2371 - mse: 0.2371 - val_loss: 0.2055 - val_mse: 0.2055\n",
      "Epoch 41/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.2371 - mse: 0.2371 - val_loss: 0.2053 - val_mse: 0.2053\n",
      "Epoch 42/50\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.2371 - mse: 0.2371 - val_loss: 0.2051 - val_mse: 0.2051\n",
      "Epoch 43/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.2371 - mse: 0.2371 - val_loss: 0.2052 - val_mse: 0.2052\n",
      "Epoch 44/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.2371 - mse: 0.2371 - val_loss: 0.2050 - val_mse: 0.2050\n",
      "Epoch 45/50\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.2372 - mse: 0.2372 - val_loss: 0.2052 - val_mse: 0.2052\n",
      "Epoch 46/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.2372 - mse: 0.2372 - val_loss: 0.2047 - val_mse: 0.2047\n",
      "Epoch 47/50\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.2371 - mse: 0.2371 - val_loss: 0.2048 - val_mse: 0.2048\n",
      "Epoch 48/50\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2371 - mse: 0.2371 - val_loss: 0.2048 - val_mse: 0.2048\n",
      "Epoch 49/50\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.2371 - mse: 0.2371 - val_loss: 0.2047 - val_mse: 0.2047\n",
      "Epoch 50/50\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2371 - mse: 0.2371 - val_loss: 0.2047 - val_mse: 0.2047\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=x_train, y=y_train, \n",
    "          batch_size=32, epochs=Nepochs,\n",
    "          shuffle=True, # a good idea is to shuffle input before at each epoch\n",
    "          validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "07785d84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[2.0099585]], dtype=float32), array([1.0108371], dtype=float32)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6be57681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2047 - mse: 0.2047\n",
      "\n",
      "Test loss: 0.20470203459262848\n",
      "Test accuracy: 0.20470203459262848\n"
     ]
    }
   ],
   "source": [
    "# evaluate model\n",
    "score = model.evaluate(x_valid, y_valid, batch_size=32, verbose=1)\n",
    "\n",
    "# print performance\n",
    "print()\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb9cc752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2047 - mse: 0.2047\n",
      "\n",
      "Test loss: 0.20470203459262848\n",
      "Test accuracy: 0.20470203459262848\n"
     ]
    }
   ],
   "source": [
    "# evaluate model\n",
    "score = model.evaluate(x_valid, y_valid, batch_size=32, verbose=1)\n",
    "\n",
    "# print performance\n",
    "print()\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f973923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# look into training history\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "86989921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_predicted = np.random.uniform(-1, 1, 100)\n",
    "y_predicted = model.predict(x_predicted)\n",
    "plt.scatter(x_predicted, y_predicted,color='r')\n",
    "plt.plot(x_valid, y_target)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01ae222",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
